{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mipSoOVlavkb",
    "lines_to_next_cell": 0
   },
   "source": [
    "# IVADO/MILA ÉCOLE D'APPRENTISSAGE PROFOND\n",
    "\n",
    "# 4e édition (automne 2019)\n",
    "\n",
    "# Tutoriel sur les données catégorielles avec perceptron multicouche (MLP)\n",
    "\n",
    "## Auteurs :\n",
    "\n",
    "Arsène Fansi Tchango <arsene.fansi.tchango@mila.quebec>\n",
    "\n",
    "Gaétan Marceau Caron <gaetan.marceau.caron@mila.quebec>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sLHwvggEZERd",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Préface\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JKNGtQkkohiM",
    "lines_to_next_cell": 0
   },
   "source": [
    "Ce tutoriel présente les aspects pratiques de l'apprentissage profond par la réalisation d'un projet simple de bout en bout. Nous utiliserons la bibliothèque d'apprentissage profond <a href=\"https://pytorch.org/\"> `PyTorch`</a>, qui est bien connue pour sa facilité d'utilisation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NOD70vdvvtin",
    "lines_to_next_cell": 0
   },
   "source": [
    "# Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nq9FwFVnQihX",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Chargement de bibliothèques et utilisation de GPU\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "reCpBfp1Qcrt",
    "lines_to_next_cell": 0
   },
   "source": [
    "Avant de commencer, nous installons les bibliothèques nécessaires pour le tutoriel à l'aide de pip. Pour ce faire, exécutez la cellule suivante en la sélectionnant et en utilisant `shift+Enter`. Cette étape peut prendre quelques minutes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "colab_type": "code",
    "id": "c5AlBPjnvzNh",
    "outputId": "48285c9a-dbd0-4585-e493-c089116ae91e"
   },
   "outputs": [],
   "source": [
    "!pip3 install 'torch==1.1.0' 'torchvision==0.3.0' 'Pillow==4.3.0' 'matplotlib==3.0.3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "djF9gjzLwsDB",
    "lines_to_next_cell": 0
   },
   "source": [
    "Maintenant, importez tous les modules que nous allons utiliser pour ce tutoriel en exécutant la cellule suivante :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "w9LnNnxBw0wC",
    "outputId": "2423e91f-ab6a-4ad2-db83-948e14bf0f89"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f0c239aac128>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "seed = 1234\n",
    "np.random.seed(seed) # Définissez la graine aléatoire de numpy pour la partition des données.\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_gpu else \"cpu\")\n",
    "\n",
    "\n",
    "print(\"Version de torch: \", torch.__version__)\n",
    "print(\"GPU disponible: {}\".format(use_gpu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZKzgFV9Favkt",
    "lines_to_next_cell": 0
   },
   "source": [
    "## PyTorch en quelques mots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vrus_-F0avkt",
    "lines_to_next_cell": 0
   },
   "source": [
    "*PyTorch* est une bibliothèque Python qui soutien un écosystème dynamique d'outils et de bibliothèques pour l’AA en vision, TLN, et plus encore. Il offre deux fonctionnalités de haut niveau :\n",
    "\n",
    "<ul>\n",
    "<li> operations on <a href=\"https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#sphx-glr-beginner-blitz-tensor-tutorial-py\">tensors</a> (such as NumPy) with GPU support,</li>\n",
    "<li> operations for creating and optimizing computational graphs with an automatic differentiation system called <a href=\"https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html#sphx-glr-beginner-blitz-autograd-tutorial-py\">Autograd</a>.</li>\n",
    "</ul>\n",
    "<a href=\"https://pytorch.org/docs/stable/torch.html\">Les documents PyTorch</a> contiennent la documentation API et <a href=\"https://pytorch.org/tutorials/\">de nombreux tutoriels</a>. De plus, PyTorch offre plusieurs fonctionnalités de traitement de données. L'une de ces fonctionnalités est la classe <a href=\"http://pytorch.org/docs/master/data.html#\"> `torch.utils.data.Dataset`</a> qui offre une interface facile à utiliser pour gérer un ensemble de données. Pour plus d'informations, référez-vous aux url suivantes :\n",
    "\n",
    "<ul>\n",
    "<li>PyTorch data sets: <a href=\"http://pytorch.org/docs/master/data.html\"> PyTorch - datasets</a>.</li>\n",
    "<li>A tutorial for loading data: <a href=\"http://pytorch.org/tutorials/beginner/data_loading_tutorial.html\"> PyTorch - data loading tutorial</a>.</li>\n",
    "</ul>\n",
    "<a href=\"http://pytorch.org/docs/master/cuda.html#module-torch.cuda\">`torch.cuda`</a> Est une bibliothèque qui fournit les mêmes fonctions que les tenseurs de CPU mais pour les tenseurs CUDA, qui sont utilisés pour le calcul sur GPU. <a href=\"http://pytorch.org/docs/master/cuda.html#torch.cuda.is_available\">`torch.cuda.is_available()`</a> Retourne une valeur booléenne indiquant si CUDA est actuellement disponible. Enfin, nous vous recommandons d'utiliser une variable `device` qui identifie le périphérique sur lequel vous souhaitez effectuer des calculs. Nous pouvons affecter un tenseur à un périphérique avec la méthode `.to(device)`. Par défaut, les tenseurs sont des tenseurs de CPU.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qm122vNmq92L",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Ingrédients pour une preuve de concept (POC)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nqvhR0ebavmE",
    "lines_to_next_cell": 0
   },
   "source": [
    "Pour réaliser un POC en AA, vous avez besoin de :\n",
    "\n",
    "<ul>\n",
    "<li>a task description as well as data to support it,</li>\n",
    "<li>an evaluation metric to assess the performance of a model,</li>\n",
    "<li>a model description,</li>\n",
    "<li>a cost function to be optimized,</li>\n",
    "<li>an optimizer that adjusts the parameters of the model.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y8_pfpu2f6AO",
    "lines_to_next_cell": 0
   },
   "source": [
    "# Comment préparer l’ensemble de données ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B5piZxYUhSzq",
    "lines_to_next_cell": 0
   },
   "source": [
    "Notre tâche est de prédire si un passager a survécu ou non au naufrage du Titanic seulement en fonction de la base des données des passagers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y4GuYNDFavlU",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Ensemble de données Titanic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NiOJx2ytavlU",
    "lines_to_next_cell": 0
   },
   "source": [
    "Nous pouvons télécharger le jeu de données Titanic à l'adresse suivante : https://github.com/afansi/winterschool18/blob/master/titanic3.csv?raw=true.<br/> Cet ensemble de données fournit des informations sur le sort de 1309 passagers du premier et unique voyage du bateau \"RMS Titanic\", résumé par le statut économique (classe), sexe, âge, informations familiales et survie. La plate-forme Kaggle utilise également cet ensemble de données comme une introduction à l'apprentissage automatique classique. Ici, nous l'utilisons pour introduire des concepts plus avancés liés à PyTorch et à l'apprentissage profond.\n",
    "\n",
    "Nous utilisons la bibliothèque <a href=\"https://pandas.pydata.org/\">Pandas</a> pour stocker le jeu de données en mémoire.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 271
    },
    "colab_type": "code",
    "id": "bX_RSiffavlW",
    "outputId": "65feb3e0-c4e7-4812-e918-3767946f865d"
   },
   "outputs": [],
   "source": [
    "titanic_df = pd.read_csv(\n",
    "    'https://github.com/afansi/winterschool18/blob/master/titanic3.csv?raw=true', \n",
    "    sep='\\t', \n",
    "    index_col=None, \n",
    "    na_values=['NA']\n",
    ")\n",
    "\n",
    "# un aperçu des 5 premiers points de données\n",
    "titanic_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yj88WmCmavlf",
    "lines_to_next_cell": 0
   },
   "source": [
    "**La signification des différentes colonnes (caractéristiques) est la suivante**:\n",
    "\n",
    "<ol>\n",
    "  <li> <b>pclass</b>: Classe du passager (1 = première; 2 = deuxième; 3 = troisième) </li>\n",
    "  <li> <b>survived</b>: Survécu? (0 = non; 1 = oui) </li>\n",
    "  <li> <b>name</b>: Nom </li>\n",
    "  <li> <b>sex</b>: Sexe </li>\n",
    "  <li> <b>age</b>: Âge </li>\n",
    "  <li> <b>sibsp</b>: Nombre de frères, soeurs, ou conjoints à bord </li>\n",
    "  <li> <b>parch</b>: Nombre de parents ou d'enfants à bord </li>\n",
    "  <li> <b>ticket</b>: Numéro de ticket </li>\n",
    "  <li> <b>fare</b>: Tarif du passager </li>\n",
    "  <li> <b>cabin</b>: Numéro de cabine </li>\n",
    "  <li> <b>embarked</b>: Port d'embarquement (C = Cherbourg; Q = Queenstown; S = Southampton) </li>\n",
    "  <li> <b>boat</b>: Bateau de sauvetage (si le passager a survécu) </li>\n",
    "  <li> <b>body</b>: Numéro du corps (si le passager n'a pas survécu et que le corps a été retrouvé) </li>\n",
    "  <li> <b>home.dest</b>: Destination du passager </li>\n",
    " </ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u2ed5fozqjce",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Pré-traitement des données\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "__vcZhPnavlg",
    "lines_to_next_cell": 0
   },
   "source": [
    "### Sélection de caractéristique\n",
    "\n",
    "Certaines caractéristiques ne sont pas pertinentes pour la tâche, par exemple :\n",
    "\n",
    "<ol>\n",
    "  <li> <b>name</b>: Nom </li>\n",
    "  <li> <b>ticket</b>: Numéro du ticket </li>\n",
    "  <li> <b>cabin</b>: Numéro de cabine </li>\n",
    "  <li> <b>home.dest</b>: Destination du passager </li>\n",
    " </ol>\n",
    " \n",
    "D'autres caractéristiques dévoilent la cible à prédire et les inclure serait de la triche:\n",
    "<ol>\n",
    "  <li> <b>boat</b>: Bateau de sauvetage (si le passager a survécu) </li>\n",
    "  <li> <b>body</b>: Numéro du corps (si le passager n'a pas survécu et que le corps a été retrouvé)  </li>\n",
    " </ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "JJ0--SDpavlg",
    "outputId": "bb15e866-2779-4e6f-9deb-4eedf70248ad"
   },
   "outputs": [],
   "source": [
    "titanic_preprocess_df = pd.read_csv(\n",
    "    'https://github.com/afansi/winterschool18/blob/master/titanic_prepocess.csv?raw=true', \n",
    "    sep=',', \n",
    "    index_col=None\n",
    ")\n",
    "\n",
    "titanic_preprocess_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4MckYm0M_xhR",
    "lines_to_next_cell": 0
   },
   "source": [
    "### Encodage de Caractéristiques\n",
    "\n",
    "Certaines caractéristiques sont **des variables catégorielles**, ce qui signifie qu'elles peuvent prendre un nombre fini de valeurs.\n",
    "\n",
    " <ol>\n",
    "  <li> <b>pclass</b>: Classe du passager </li>\n",
    "  <li> <b>sex</b>: Sexe </li>\n",
    "  <li> <b>embarked</b>: Port d'embarquement </li>\n",
    " </ol>\n",
    "Pour traiter les variables catégorielles, nous devons les encoder d'une manière qui n'implique pas un ordre arbitraire, comme l'utilisation de nombres naturels (par exemple, 1, 2, 3). <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">L’ encodage one-hot</a> est un moyen de le réaliser. Nous pouvons télécharger le jeu de données pré-traité à l'adresse suivante : https://github.com/afansi/winterschool18/blob/master/titanic\\_prepocess.csv?raw=true. <br>La signification des variables encodées est la suivante :\n",
    "\n",
    "<ol>\n",
    "  <li> <b>survived</b>: Survécu? (0 = non; 1 = oui) </li>\n",
    "  <li> <b>pclass_1</b>: (1 si passager en première classe; 0 sinon) </li>\n",
    "  <li> <b>pclass_2</b>: (1 si passager en deuxième classe; 0 sinon) </li>\n",
    "  <li> <b>pclass_3</b>: (1 si passager en troisième classe; 0 sinon) </li>\n",
    "  <li> <b>sex_female</b>: (1 si passager est une femme; 0 sinon) </li>\n",
    "  <li> <b>sex_male</b>: (1 si passager est un homme ; 0 sinon) </li>\n",
    "  <li> <b>age</b>: Âge </li>\n",
    "  <li> <b>sibsp</b>: Nombre de frères, soeurs, ou conjoints à bord </li>\n",
    "  <li> <b>parch</b>: Nombre de parents ou d'enfants à bord </li>\n",
    "  <li> <b>fare</b>: Tarif du passager </li>\n",
    "  <li> <b>embarked_C</b>: (1 si Port d'embarquement = Cherbourg (C); 0 sinon) </li> \n",
    "  <li> <b>embarked_Q</b>: (1 si Port d'embarquement = Queenstown (Q); 0 sinon) </li> \n",
    "  <li> <b>embarked_S</b>: (1 si Port d'embarquement = Southampton (S); 0 sinon)</li> \n",
    " </ol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QJcs6PUTavlm",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Partition Entraînement / validation / évaluation \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bjbgvffmavlo",
    "lines_to_next_cell": 0
   },
   "source": [
    "À ce stade, nous devons diviser l'ensemble de données en trois sous-ensembles :\n",
    "\n",
    "<ol>\n",
    "<li> <b> Train</b> (généralement 60% de l'ensemble de données): utilisé pour entraîner le modèle de classification. </li>   \n",
    "<li> <b> Validation</b> (généralement 20% de l'ensemble de données): utilisé pour évaluer les hyper-paramètres sur un ensemble de données différent. </li>   \n",
    "<li> <b> Test</b> (généralement 20% de l'ensemble de données): utilisé pour évaluer la performance de généralisation du modèle choisi sur un ensemble de données différent. </li>\n",
    "</ol>\n",
    "Nous utilisons la <a href=\"https://docs.scipy.org/doc/numpy-1.15.1/reference/generated/numpy.split.html\">fonction numpy.split</a> pour séparer notre ensemble de données en sous-ensembles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GBmL8VBOavlo"
   },
   "outputs": [],
   "source": [
    "train, validate, test = np.split(\n",
    "    titanic_preprocess_df.sample(frac=1, random_state=seed), \n",
    "    [int(.6*len(titanic_preprocess_df)), int(.8*len(titanic_preprocess_df))])\n",
    "\n",
    "# Retirez la colonne d'étiquettes de X et créez un vecteur d'étiquettes.\n",
    "X_train = train.drop(['survived'], axis=1).values\n",
    "y_train = train['survived'].values\n",
    "\n",
    "X_val = ... # À compléter.\n",
    "y_val = ... # À compléter.\n",
    "\n",
    "X_test = ... # À compléter.\n",
    "y_test = ... # À compléter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wv74TbIWavlr",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Ensemble de données dans PyTorch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9_LJtG-Xavlt",
    "lines_to_next_cell": 0
   },
   "source": [
    "Nous utiliserons la sous-classe <b><a href=\"http://pytorch.org/docs/master/data.html#\"> `torch.utils.data.TensorDataset`</a> </b> pour manipuler ensemble les caractéristiques et les cibles d'un ensemble de données.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1JtT4tV7avlt"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "train_dataset = TensorDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train).long())\n",
    "\n",
    "val_dataset = ... # À compléter.\n",
    "\n",
    "test_dataset = ... # À compléter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "obEPHnlTavkc",
    "lines_to_next_cell": 0
   },
   "source": [
    "# Comment définir l'algorithme d'apprentissage ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qhN5GL6Gavks",
    "lines_to_next_cell": 0
   },
   "source": [
    "Un perceptron multicouche (MLP) est un simple graphe de calcul composé de \"couches cachées\", qui sont définies par deux modules: Une *transformation linéaire* suivie d'une *non-linéarité*. Le résultat d'une couche cachée est un vecteur appelé *représentation distribuée* où chaque composant est associé à une unité cachée.\n",
    "\n",
    "Pour entraîner ce modèle, nous devons définir :\n",
    "\n",
    "<ul>\n",
    "<li>l'architecture du réseau en choisissant la fonction non linéaire et le nombre d'unités cachées par couche, </li>\n",
    "<li>la fonction de coût et l'optimiseur.  </li>\n",
    "</ul>\n",
    "Pour résoudre notre tâche, nous allons utiliser un MLP avec les propriétés suivantes :\n",
    "\n",
    " <ul>\n",
    " <li> la dimension d'entrée du modèle est de 12,</li>\n",
    " <li> la dimension de sortie du modèle est de 2,</li>\n",
    " <li> la première dimension de la sortie est la probabilité de décès et la deuxième dimension est la probabilité de survie,</li>\n",
    "  <li> le nombre de couches cachées est de 3, </li>\n",
    " <li> les dimensions des couches cachées sont respectivement de 20, 40, 20, </li>\n",
    " <li> la fonction d'activation est un ReLu pour toutes les couches cachées. </li>\n",
    " </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "701t0e-ravkr",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Comment définir un modèle dans PyTorch?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m4F5cyijavkv",
    "lines_to_next_cell": 0
   },
   "source": [
    "La <a href=\"https://pytorch.org/docs/stable/nn.html\">bibliothèque PyTorch NN</a> contient de nombreuses classes utiles pour la création de graphes de calcul.\n",
    "\n",
    "<ul>\n",
    "<li> La classe <a href=\"http://pytorch.org/docs/master/nn.html#module\">torch.nn.Module</a>: \n",
    "tout nouveau module doit hériter de cette classe ou de ses descendants (sous-classes).\n",
    "</li>   \n",
    "<li> La méthode `forward` : toute classe définissant un module doit implémenter la méthode `forward(...)`, qui définit la transformation des entrées en sorties.</li>  \n",
    "<li> La classe <a href=\"http://pytorch.org/docs/master/nn.html#torch.nn.Linear\">`torch.nn.Linear(in_features, out_features)`</a>: cette classe implémente une transformation linéaire. Par défaut, elle prend deux paramètres : \n",
    "    <ul>\n",
    "    <li>`in_features`: la taille des données à l'entrée du module. </li>\n",
    "    <li>`out_features`: la taille des données à la sortie du module. </li>\n",
    "    </ul>\n",
    "</li>\n",
    "<li> Le module <a href=\"http://pytorch.org/docs/master/nn.html#torch-nn-functional\">`torch.nn.functional`</a>: \n",
    "elle définit un ensemble de fonctions qui peuvent être appliquées directement à n'importe quel tenseur. À titre d'exemple, nous avons :\n",
    "    <ul>\n",
    "    <li> les fonctions non-linéaires: sigmoid(...), tanh(...), relu(...), etc...</li> \n",
    "    <li> les fonctions de coût : mse_loss(...), nll(...., cross_entropy(...), etc ...</li> \n",
    "    <li> les fonctions de régularisation: droupout(...), etc ... </li> \n",
    "    <li> ...</li> \n",
    "    </ul>\n",
    "</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tscha6S-KIBB",
    "lines_to_next_cell": 0
   },
   "source": [
    "Vous devez compléter les méthodes suivantes :\n",
    "\n",
    "<ul>\n",
    "<li>La méthode `__init__` qui définit les couches. </li>\n",
    "<li>La méthode `forward(input)` qui retourne le `output`. </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8NyQGwC-avkw"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "seed = 1234\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xR5eBfIbavk0"
   },
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(12, 20)\n",
    "        ... # À compléter.\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        ... # À compléter.\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OvLnHRZ5avk2",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Faire des prédictions avec un réseau de neurones\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uEXgJMDDavk3",
    "lines_to_next_cell": 0
   },
   "source": [
    "Maintenant, nous sommes prêts à tester notre réseau de neurones sur des données choisies au hasard.\n",
    "\n",
    "Dans PyTorch, un modèle a deux modes différents : <ul> <li> <b>train</b>: utilisé pendant l’entraînement, </li> <li> <b>eval</b>: utilisé pendant l'inférence pour l'évaluation du modèle. </li> </ul> La distinction est importante car certains modules se comportent différemment selon ce mode. Nous utiliserons le mode <b>évaluation</b> dans cette section.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "gzcABMezavk6",
    "outputId": "d65d2777-ee2a-4f9d-9259-edb76428ad6f"
   },
   "outputs": [],
   "source": [
    "# Définition du modèle\n",
    "neural_net = NeuralNet()\n",
    "neural_net = neural_net.to(device)\n",
    "\n",
    "# Activation du mode d'évaluation\n",
    "neural_net = neural_net.eval()\n",
    "\n",
    "# Sélectionner les 5 premiers points de données\n",
    "data, target = val_dataset[0:5]\n",
    "data = data.to(device)\n",
    "target = target.to(device)\n",
    "\n",
    "# Propagation avant des données à travers le modèle\n",
    "output = neural_net(data)   # équivalent à neural_net.forward(data)\n",
    "\n",
    "# Convertir les logits en probabilités avec la fonction softmax\n",
    "output_proba = ... # À compléter.\n",
    "\n",
    "# Imprimer la probabilité\n",
    "print(output_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fVep0BElavlS",
    "lines_to_next_cell": 0
   },
   "source": [
    "Les rangées définissent la sortie du réseau, en termes de probabilités sur deux classes : <b>deceased</b> (première colonne) ou <b>survived</b> (deuxième colonne), pour chacun des cinq points de données d'entrée. Prenons l'étiquette avec la probabilité maximale comme étiquette prédite et comparons-la à l'étiquette correcte.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "_jV4No36qjdU",
    "outputId": "995f5958-ab4d-4c8a-e486-f303405e1e88"
   },
   "outputs": [],
   "source": [
    "# Impression des prédictions (classe avec la plus grande probabilité)\n",
    "_, prediction = torch.max(output_proba, dim=1)\n",
    "\n",
    "print('Prédiction du modèle')\n",
    "print(prediction)\n",
    "\n",
    "# Impression des vraies étiquettes\n",
    "print(\"Données réelles\")\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SEIIjqOuqjdc",
    "lines_to_next_cell": 0
   },
   "source": [
    "**Questions**\n",
    "\n",
    "1. Quelle serait une bonne façon de mesurer la performance du modèle ?\n",
    "2. Comment notre modèle fonctionne-t-il ?\n",
    "3. Étant donné que le modèle n'est pas entraîné sur l’ensemble de données, constatez-vous un problème avec la mesure sélectionnée ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iTTlBikYwb-w",
    "lines_to_next_cell": 0
   },
   "source": [
    "... \\# à compléter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0uySA2TCavmD",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Définissez la fonction de coût et l'optimiseur\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EkoobCLMavmE",
    "lines_to_next_cell": 0
   },
   "source": [
    "### Fonction de coût\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qkX7uSXQavmF",
    "lines_to_next_cell": 0
   },
   "source": [
    "Nous définissons la fonction de coût en fonction de la tâche que nous voulons réaliser.\n",
    "\n",
    "PyTorch offre <a href=\"https://pytorch.org/docs/stable/nn.html#loss-functions\">de nombreuses fonctions de coût prêtes à utiliser</a>.\n",
    "\n",
    "Pour les problèmes de classification, la fonction de coût habituelle est <b>l'entropie croisée</b>, et c'est celle que nous utiliserons dans ce tutoriel. Dans PyTorch, elle est définie par la fonction <a href=\"https://pytorch.org/docs/master/nn.functional.html#cross-entropy\">`torch.nn.functional.cross_entropy`</a>.  L'entropie croisée permet de comparer une distribution $p$ avec une distribution de référence $t$. Elle atteint son minimum lorsque $t=p$. La formule pour la calculer avec la prédiction et la cible est la suivante : $-\\sum_j t_{ij} \\log(p_{ij})$ où $p$ est la prédiction, $t$ la cible, $i$ les exemples et $j$ les classes de la cible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FHnfYeS5avmF"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def cost_function(prediction, target):\n",
    "    loss = ... # À compléter.\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vsx_cv9Wqjdj",
    "lines_to_next_cell": 0
   },
   "source": [
    "### Rétropropagation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0hcZaIKtavmH",
    "lines_to_next_cell": 0
   },
   "source": [
    "Dans PyTorch, grâce au mécanisme de dérivation automatique <a href=\"http://pytorch.org/docs/master/notes/autograd.html\">Autograd</a>, il est possible de calculer automatiquement le gradient de la fonction de coût et de la rétropropager à travers le graphe de calcul.\n",
    "\n",
    "Pour ce faire, il suffit d'appeler la méthode `backward()` sur la variable retournée par la fonction de coût, par exemple, avec\n",
    "\n",
    "`loss = cost_function(....)` <br> `loss.backward()`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8YNo_ymYavmH",
    "lines_to_next_cell": 0
   },
   "source": [
    "### Optimisation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y4AlX9TwavmH",
    "lines_to_next_cell": 0
   },
   "source": [
    "PyTorch fournit un <a href=\"http://pytorch.org/docs/master/optim.html#algorithms\">ensemble de méthodes d'optimisation (`torch.optim`)</a> couramment utilisées par la communauté d'apprentissage profond. Ces méthodes incluent les suivantes :\n",
    "\n",
    "<ul>\n",
    "<li><b>SGD</b> (Descente de gradient stochastique) <a href=\"http://pytorch.org/docs/master/optim.html#torch.optim.SGD\">`torch.optim.SGD(net.parameters(), lr=learning_rate)`</a></li>\n",
    "<li><b>Adam</b> (Adaptive Moment Estimation) : une variante de la méthode de descente de gradient dans laquelle le taux d'apprentissage est ajusté pour chaque paramètre. Cet ajustement est basé sur l'estimation des premier et deuxième moments des gradients. Cet optimiseur a démontré d'excellentes performances par rapport à la méthode SGD sur de nombreuses tâches de référence. </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Uam-a0_0qjdl",
    "lines_to_next_cell": 0
   },
   "source": [
    "Pour pouvoir utiliser un optimiseur dans PyTorch, nous devons l'instancier en passant les éléments suivants :\n",
    "\n",
    "<ul>\n",
    "<li><b>Les paramètres du modèle</b> : ils sont obtenus en utilisant la méthode <b>parameters()</b> sur le modèle instancié.</li>\n",
    "<li><b>Le taux d'apprentissage / learning rate (lr)</b>: c'est le taux d'apprentissage qui doit être utilisé pour mettre à jour les paramètres pendant le processus d'optimisation. </li>\n",
    "<li>Il peut y avoir d'autres paramètres spécifiques à l'optimiseur choisi.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jt6_Qr6ravmI",
    "lines_to_next_cell": 0
   },
   "source": [
    "PyTorch offre une interface simplifiée pour interagir avec n'importe quel optimiseur :\n",
    "\n",
    "<ul>\n",
    "<li><b>zero_grad()</b>: Permet de réinitialiser les gradients à zéro au début d'une étape d'optimisation.</li>\n",
    "<li><b>step()</b>: Permet d'effectuer une étape d'optimisation après une étape de rétropropagation de gradient.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fZ-lKExqavmI",
    "lines_to_next_cell": 0
   },
   "source": [
    "Nous utiliserons Adam avec un taux d’apprentissage (lr) de 0.001.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WDMOziJTavmI"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = ... # À compléter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OnFOAfdGqjdr",
    "lines_to_next_cell": 0
   },
   "source": [
    "# Comment entraîner un modèle?\n",
    "\n",
    "Tout d'abord, nous avons besoin de définitions :\n",
    "\n",
    "<ol>\n",
    "<li>\n",
    "<b>Époque / Epoch</b>:  un passage complet sur l'ensemble des données d'entraînement.\n",
    "</li>\n",
    "<li>\n",
    "<b>Itération / Iteration</b>: une mise à jour des paramètres du modèle. De nombreuses itérations peuvent se produire avant la fin d'une époque.\n",
    "</li>\n",
    "<li>\n",
    "<b>Mini-lot / Mini-batch</b>:  Un sous-ensemble de données d'entraînement utilisé pour estimer la moyenne des gradients. En d'autres termes, à chaque itération, un mini-lot est utilisé.\n",
    "</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LLXjNiDTavmK",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Création des mini-lots\n",
    "\n",
    "PyTorch offre une fonction appelée <b><a href=\"http://pytorch.org/docs/master/data.html\"> torch.utils.data.DataLoader </a></b> pour charger n'importe quel ensemble de données et le diviser automatiquement en mini-lots. Pendant l’entraînement, les données présentées au réseau doivent apparaître dans un ordre différent d'une époque à l'autre. Nous préparerons le `DataLoader` pour nos trois ensembles de données (entraînement, validation et évaluation).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RGoQZSdqavmM"
   },
   "outputs": [],
   "source": [
    "train_batch_size = 32  # nombre de données dans un lot d'entraînement.\n",
    "eval_batch_size = 32   # nombre de données dans un lot d'évaluation.\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
    "\n",
    "val_loader   = ... # À compléter.\n",
    "test_loader  = ... # À compléter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ia3ai-GvavmP",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Boucle d'entraînement simple\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v9wNZrTnavmQ",
    "lines_to_next_cell": 0
   },
   "source": [
    "Nous définissons ici notre procédure d’entraînement pour une époque.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZyK9xCsZavmR"
   },
   "outputs": [],
   "source": [
    "def train(epoch, model, train_loader, optimizer, device):\n",
    "    \n",
    "    # activer le mode d'entraînement\n",
    "    model.train()\n",
    "    \n",
    "    torch.set_grad_enabled(True)\n",
    "    \n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    # itération sur les mini-lots\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        \n",
    "        # transférer les données sur l'appareil choisi\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # réinitialiser les gradients à zéro\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # propagation avant sur les données\n",
    "        prediction = model(data)\n",
    "        \n",
    "        # calculer la fonction de coût en fonction des objectifs\n",
    "        loss = cost_function(prediction, target)\n",
    "        \n",
    "        # exécuter la rétropropagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # exécuter une étape d'optimisation\n",
    "        optimizer.step()\n",
    "        \n",
    "        # accumuler les pertes\n",
    "        total_loss += loss.item()*len(data)\n",
    "        \n",
    "        # calculer le nombre de prédictions correctes\n",
    "        _, pred_classes = torch.max(prediction, dim=1)        \n",
    "        correct += pred_classes.eq(target.view_as(pred_classes)).sum().item()\n",
    "         \n",
    "        \n",
    "    # calculer le coût moyen par époque\n",
    "    mean_loss = total_loss/len(train_loader.dataset)\n",
    "    \n",
    "    # calculer l'exactitude\n",
    "    acc = correct / len(train_loader.dataset)\n",
    "        \n",
    "    print(\"Époque d'entraînement: {}   Perte moyenne: {:.5f}   Acc: {}/{} ({:.3f}%)\".format(\n",
    "        epoch, mean_loss, correct, len(train_loader.dataset),\n",
    "        100. * acc))   \n",
    "    \n",
    "    # retourner la perte moyenne et l'exactitude\n",
    "    return mean_loss, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PxG666rmavmU",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Procédure d'évaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vGexbWaHavmU",
    "lines_to_next_cell": 0
   },
   "source": [
    "Nous définissons ici notre procédure d'évaluation du modèle. <br/> Outre le passage du modèle en mode **eval**, il est essentiel de désactiver le calcul du gradient. <br/> Pour ce faire, PyTorch offre un ensemble de gestionnaires de contexte pour <a href=\"https://pytorch.org/docs/0.4.0/torch.html#locally-disabling-gradient-computation\">désactiver/activer localement le calcul de gradient </a>:\n",
    "\n",
    "<ol>\n",
    "<li>\n",
    "`torch.no_grad()`: désactiver le calcul du gradient.\n",
    "</li>\n",
    "<li>\n",
    "`torch.enable_grad()`: activer le calcul du gradient.\n",
    "</li>\n",
    "<li>\n",
    "`torch.set_grad_enabled(bool)`: activer/désactiver le calcul du gradient.\n",
    "</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8gQj9W5LavmU"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, eval_loader, device):\n",
    "    \n",
    "    # activer le mode d'évaluation\n",
    "    model.eval()\n",
    "    \n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        # itération sur les lots\n",
    "        for batch_idx, (data, target) in enumerate(eval_loader):\n",
    "\n",
    "            # transférer les données sur l'appareil choisi\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            # propagation avant sur les données\n",
    "            prediction = model(data)\n",
    "\n",
    "            # calculer la fonction de coût en fonction des objectifs\n",
    "            loss = cost_function(prediction, target)           \n",
    "\n",
    "\n",
    "            # accumuler les pertes\n",
    "            total_loss += loss.item()*len(data)\n",
    "\n",
    "            # calculer le nombre de prédictions correctes\n",
    "            _, pred_classes = torch.max(prediction, dim=1) \n",
    "            correct += pred_classes.eq(target.view_as(pred_classes)).sum().item()         \n",
    "          \n",
    "    \n",
    "    # calculer le coût moyen par époque\n",
    "    mean_loss = total_loss/len(eval_loader.dataset)\n",
    "    \n",
    "    # calculer l'exactitude\n",
    "    acc = correct / len(eval_loader.dataset)\n",
    "        \n",
    "    print('Eval:  Perte moyenne: {:.5f}   Exac: {}/{} ({:.3f}%)'.format(\n",
    "        mean_loss, correct, len(eval_loader.dataset),\n",
    "        100. * acc)) \n",
    "    \n",
    "    # retourner la perte moyenne et l'exactitude\n",
    "    return mean_loss, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fMUyZNxdavmW",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Attribution de points de contrôle (checkpointing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lQLklQXAavmW",
    "lines_to_next_cell": 0
   },
   "source": [
    "Pour les phases d’entraînement qui nécessitent beaucoup de temps, il est recommandé d'enregistrer périodiquement les paramètres du modèle. Cette étape est communément appelée <b>attribution de points de contrôle (checkpointing)</b>.\n",
    "\n",
    "PyTorch offre <a href=\"http://pytorch.org/docs/master/notes/serialization.html\">un mécanisme simple</a> pour effectuer cette opération.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ld-Y2gF-avmX",
    "lines_to_next_cell": 0
   },
   "source": [
    "Nous implémentons deux méthodes ici :\n",
    "\n",
    "<ul>\n",
    "<li> la première pour <b> sauvegarder </b> un modèle,</li>\n",
    "<li> la deuxième pour <b> charger </b> un point de contrôle d'un modèle.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dMmNpma2avmX"
   },
   "outputs": [],
   "source": [
    "def save_model(epoch, model, path='./'):\n",
    "    \n",
    "    # créer le nom du fichier indexé par la valeur d'époque\n",
    "    filename = path + 'neural_network_{}.pt'.format(epoch)\n",
    "    \n",
    "    # sauvegarder les paramètres du modèle\n",
    "    torch.save(model.state_dict(), filename)\n",
    "    \n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2ZptgqQRavmZ"
   },
   "outputs": [],
   "source": [
    "def load_model(epoch, model, path='./'):\n",
    "    \n",
    "    # créer le nom du fichier indexé par la valeur d'époque\n",
    "    filename = path + 'neural_network_{}.pt'.format(epoch)\n",
    "    \n",
    "    # charger les paramètres du modèle sauvegardé\n",
    "    model.load_state_dict(torch.load(filename))\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ve8sOocWavma",
    "lines_to_next_cell": 0
   },
   "source": [
    "Il est également possible d'enregistrer l'état de l'optimiseur dans PyTorch, ce qui est très important lorsque nous voulons reprendre l’entraînement du modèle à partir d'une certaine sauvegarde. Pour plus d'informations, veuillez consulter <a href='https://discuss.pytorch.org/t/saving-and-loading-a-model-in-pytorch/2610/3'>l'URL suivant</a>.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8lcAP8-1avma",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Rassembler le tout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "keMpyePsavmb",
    "outputId": "638ef04a-0f0e-4e8a-8b50-23884324a79b"
   },
   "outputs": [],
   "source": [
    "# Maximum d'époques\n",
    "numEpochs = 200\n",
    "\n",
    "# Fréquence de sauvegarde\n",
    "checkpoint_freq = 10\n",
    "\n",
    "# Répertoire pour la sauvegarde des données\n",
    "path = './'\n",
    "\n",
    "# Accumulateurs de coûts moyens obtenus par époque\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# Accumulateurs de performance par époque\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "# Définition du modèle\n",
    "neural_net = NeuralNet()\n",
    "\n",
    "# Charger le modèle sur l'appareil choisi\n",
    "neural_net = neural_net.to(device)\n",
    "\n",
    "# Définition de l'optimiseur\n",
    "optimizer = optim.Adam(neural_net.parameters(), lr=0.001) \n",
    "# optimizer = optim.SGD(neural_net.parameters(), lr=0.001) \n",
    "\n",
    "\n",
    "# Boucle d'apprentissage\n",
    "for epoch in range(1, numEpochs + 1):\n",
    "    \n",
    "    # entraîner le modèle avec l'ensemble des données d'entraînement\n",
    "    train_loss, train_acc = train(epoch, neural_net, train_loader, optimizer, device)   \n",
    "    \n",
    "    # évaluer le modèle avec l'ensemble des données de validation\n",
    "    val_loss, val_acc = evaluate(neural_net, val_loader, device)       \n",
    "    \n",
    "    # Sauvegarder les coûts obtenus\n",
    "    train_losses.append(train_loss)    \n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    # Sauvegarder les performances\n",
    "    train_accuracies.append(train_acc)    \n",
    "    val_accuracies.append(val_acc)\n",
    "    \n",
    "    # Point de contrôle\n",
    "    if epoch % checkpoint_freq ==0:\n",
    "        save_model(epoch, neural_net, path)\n",
    "\n",
    "# Sauvegarder le modèle à la fin de l'entraînement\n",
    "save_model(numEpochs, neural_net, path)\n",
    "    \n",
    "print(\"\\n\\n\\nOptimisation finie.\\n\")    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "86OZRLrjavmd",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Interpréter la sortie du réseau de neurones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "id": "mklvQruYavme",
    "outputId": "193eeca0-db5e-477b-818d-7b5e6d883848"
   },
   "outputs": [],
   "source": [
    "# Activer le mode d'évaluation\n",
    "neural_net = neural_net.eval()\n",
    "\n",
    "# Sélectionner les 10 premiers points de données de l'ensemble de validation\n",
    "data, target = val_dataset[0:10]\n",
    "data = data.to(device)\n",
    "\n",
    "# Exécution du réseau de neurones\n",
    "output = neural_net(data)   # équivalent à neural_net.forward(data)\n",
    "\n",
    "# Transformer la sortie en une distribution de probabilité avec une fonction softmax\n",
    "output_proba = ... # À compléter.\n",
    "\n",
    "# Imprimer la probabilité\n",
    "print(output_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "RvIEqKt0qjeT",
    "outputId": "f1c4e779-e9e1-4873-be1e-1366fb515836"
   },
   "outputs": [],
   "source": [
    "# Pour chaque exemple, récupérez la classe avec la plus grande probabilité.\n",
    "_, prediction = torch.max(output_proba, dim=1)\n",
    "\n",
    "print(\"Model predictions\")\n",
    "print(prediction)\n",
    "\n",
    "print(\"Targets\")\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V11J3Jihavmy",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Visualisation de la courbe d'apprentissage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j9_9C_tXavmz",
    "lines_to_next_cell": 0
   },
   "source": [
    "La visualisation de la courbe d'apprentissage permet de détecter des problèmes potentiels qui se sont produits pendant l'apprentissage, par exemple, du surapprentissage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "iNcbpl0tavm0",
    "outputId": "fa201aa2-5e25-4701-c0a9-33415773d68b"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "x = list(range(len(train_losses)))\n",
    "\n",
    "ax = plt.subplot(111)\n",
    "plt.plot(x, train_losses, 'r', label=\"Entraînement\")\n",
    "plt.plot(x, val_losses, 'g', label=\"Validation\")\n",
    "plt.xlabel('Époque')\n",
    "plt.ylabel('Perte entropie croisée')\n",
    "plt.grid()\n",
    "leg = plt.legend(loc='best', ncol=2, mode=\"expand\", shadow=False, fancybox=False)\n",
    "leg.get_frame().set_alpha(0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "g-VGQ2pMavm4",
    "outputId": "267e91d4-48e3-413d-e2e2-0feac7335035"
   },
   "outputs": [],
   "source": [
    "x = list(range(len(train_accuracies)))\n",
    "\n",
    "ax = plt.subplot(111)\n",
    "plt.plot(x, train_accuracies, 'r', label=\"Entraînement\")\n",
    "plt.plot(x, val_accuracies, 'g', label=\"Validation\")\n",
    "plt.xlabel('Époque')\n",
    "plt.ylabel('Exactitude')\n",
    "plt.grid()\n",
    "leg = plt.legend(loc='best', ncol=2, mode=\"expand\", shadow=False, fancybox=False)\n",
    "leg.get_frame().set_alpha(0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8oktkpkuqjet",
    "lines_to_next_cell": 0
   },
   "source": [
    "**Questions**:\n",
    "\n",
    "* Qu'observez-vous dans les graphiques précédents ?\n",
    "* À quelle époque est-il intéressant d'extraire les paramètres du modèle pour l'inférence ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qwhRt39yzug-",
    "lines_to_next_cell": 0
   },
   "source": [
    "... \\# à compléter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XK_eUsq3avm8",
    "lines_to_next_cell": 0
   },
   "source": [
    "# Comment évaluer un modèle sur l'ensemble d’évaluation?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4UREO5elavm8",
    "lines_to_next_cell": 0
   },
   "source": [
    "Nous pouvons enfin évaluer notre modèle sur notre ensemble de données d'évaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "pPWvDM-qavm8",
    "outputId": "b39e294a-47fb-401a-ffa4-5d2a407f0980"
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc = evaluate(neural_net, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EvP_-KUwqjez",
    "lines_to_next_cell": 0
   },
   "source": [
    "**Questions**:\n",
    "\n",
    "A) Comparer les métriques de validation et d’évaluation. <br/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ov4CKUFh5tun",
    "lines_to_next_cell": 0
   },
   "source": [
    "... \\# à compléter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SfykotIrJV0Y"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "id,colab_type,outputId,colab,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
