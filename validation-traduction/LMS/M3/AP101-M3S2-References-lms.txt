<ul>
<li>IVADO-Mila Summer School Presentation (Original Slides)<br /><a href="/static/CNN_2.pdf" target="_blank">Introduction to Convolutional Neural Networks - Part II.pdf</a></li>
<li><a href="https://arxiv.org/pdf/1603.07285.pdf" target="_blank">A Guide to Convolution Arithmetic for Deep Learning<br /></a>(<a href="https://arxiv.org/pdf/1603.07285.pdf" target="_blank">https://arxiv.org/pdf/1603.07285.pdf</a>)</li>
<li><a href="https://medium.com/@2017csm1006/forward-and-backpropagation-in-convolutional-neural-network-4dfa96d7b37e" target="_blank">Forward And Backpropagation in Convolutional Neural Network<br /></a>(<a href="https://medium.com/@2017csm1006/forward-and-backpropagation-in-convolutional-neural-network-4dfa96d7b37e" target="_blank">https://medium.com/@2017csm1006/forward-and-backpropagation-in-convolutional-neural-network-4dfa96d7b37e</a>)</li>
<li><a href="https://www.jefkine.com/general/2016/09/05/backpropagation-in-convolutional-neural-networks/" target="_blank">Backpropagation In Convolutional Neural Networks<br /></a>(<a href="https://www.jefkine.com/general/2016/09/05/backpropagation-in-convolutional-neural-networks/" target="_blank">https://www.jefkine.com/general/2016/09/05/backpropagation-in-convolutional-neural-networks/</a>)</li>
<li><a href="https://becominghuman.ai/back-propagation-in-convolutional-neural-networks-intuition-and-code-714ef1c38199" target="_blank">Back Propagation in Convolutional Neural Networks — Intuition and Code<br /></a>(<a href="https://becominghuman.ai/back-propagation-in-convolutional-neural-networks-intuition-and-code-714ef1c38199" target="_blank">https://becominghuman.ai/back-propagation-in-convolutional-neural-networks-intuition-and-code-714ef1c38199</a>)</li>
<li><a href="https://github.com/matterport/Mask_RCNN" target="_blank">Mask R-CNN Github Repository<br /></a>(<a href="https://github.com/matterport/Mask_RCNN" target="_blank">https://github.com/matterport/Mask_RCNN</a>) (p.1)</li>
<li><a href="https://arxiv.org/pdf/1703.06870.pdf" target="_blank">Mask R-CNN Architecture<br /></a>(<a href="https://arxiv.org/pdf/1703.06870.pdf" target="_blank">https://arxiv.org/pdf/1703.06870.pdf</a>)</li>
<li><a href="https://www.nature.com/articles/s41591-019-0539-7.epdf?author_access_token=BI9AOTsesmNoV2lSdpucn9RgN0jAjWel9jnR3ZoTv0PDGU3ZwysZtsN41a2fOgaoj4PRxjTvAHjSFrKF_S_mq4QNNV8dNoxAjytIQuVz9vdjplLQHUSEPiIo392MzIJY8fqxLKHC5vIwNpLLEoXMnA%3D%3D" target="_blank">An Augmented Reality Microscope with Real-Time Artificial Intelligence Integration for Cancer Diagnosis<br /></a>(<a href="https://www.nature.com/articles/s41591-019-0539-7.epdf?author_access_token=BI9AOTsesmNoV2lSdpucn9RgN0jAjWel9jnR3ZoTv0PDGU3ZwysZtsN41a2fOgaoj4PRxjTvAHjSFrKF_S_mq4QNNV8dNoxAjytIQuVz9vdjplLQHUSEPiIo392MzIJY8fqxLKHC5vIwNpLLEoXMnA%3D%3D" target="_blank">https://www.nature.com/articles/s41591-019-0539-7.epdf?author_access_token=BI9AOTsesmNoV2lSdpucn9RgN0jAjWel9jnR3ZoTv0PDGU3ZwysZtsN41a2fOgaoj4PRxjTvAHjSFrKF_S_mq4QNNV8dNoxAjytIQuVz9vdjplLQHUSEPiIo392MzIJY8fqxLKHC5vIwNpLLEoXMnA%3D%3D</a>)</li>
<li><a href="https://arxiv.org/pdf/1502.03044.pdf" target="_blank">Show, Attend and Tell: Neural Image Caption Generation with Visual Attention<br /></a>(<a href="https://arxiv.org/pdf/1502.03044.pdf" target="_blank">https://arxiv.org/pdf/1502.03044.pdf</a>)</li>
<li><a href="https://github.com/rachit2403/Open-Pose-Keras" target="_blank">Human Pose Estimation in Keras Github Repository<br /></a>(<a href="https://github.com/rachit2403/Open-Pose-Keras" target="_blank">https://github.com/rachit2403/Open-Pose-Keras</a>)</li>
<li><a href="https://github.com/facebookresearch/DensePose" target="_blank">DensePose Estimation<br /></a>(<a href="https://github.com/facebookresearch/DensePose" target="_blank">https://github.com/facebookresearch/DensePose</a>)</li>
<li><a href="http://openaccess.thecvf.com/content_cvpr_2018_workshops/papers/w4/Zhou_D-LinkNet_LinkNet_With_CVPR_2018_paper.pdf" target="_blank">D-LinkNet: LinkNet with Pretrained Encoder and Dilated Convolution for High Resolution Satellite Imagery Road Extraction<br /></a>(<a href="http://openaccess.thecvf.com/content_cvpr_2018_workshops/papers/w4/Zhou_D-LinkNet_LinkNet_With_CVPR_2018_paper.pdf" target="_blank">http://openaccess.thecvf.com/content_cvpr_2018_workshops/papers/w4/Zhou_D-LinkNet_LinkNet_With_CVPR_2018_paper.pdf</a>)</li>
<li><a href="https://ai.facebook.com/blog/mapping-roads-through-deep-learning-and-weakly-supervised-training/" target="_blank">Mapping Roads Through Deep Learning and Weakly Supervised Training<br /></a>(<a href="https://ai.facebook.com/blog/mapping-roads-through-deep-learning-and-weakly-supervised-training/" target="_blank">https://ai.facebook.com/blog/mapping-roads-through-deep-learning-and-weakly-supervised-training/</a>)</li>
<li><a href="https://librosa.github.io/librosa/generated/librosa.feature.melspectrogram.html" target="_blank">Librosa Mel-Scaled Spectrogram Documentation<br /></a>(<a href="https://librosa.github.io/librosa/generated/librosa.feature.melspectrogram.html" target="_blank">https://librosa.github.io/librosa/generated/librosa.feature.melspectrogram.html</a>)</li>
<li><a href="https://arxiv.org/pdf/1406.2661.pdf" target="_blank">Generative Adversarial Nets<br /></a>(<a href="https://arxiv.org/pdf/1406.2661.pdf" target="_blank">https://arxiv.org/pdf/1406.2661.pdf</a>)</li>
<li><a href="https://arxiv.org/pdf/1511.06434.pdf" target="_blank">Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks<br /></a>(<a href="https://arxiv.org/pdf/1511.06434.pdf" target="_blank">https://arxiv.org/pdf/1511.06434.pdf</a>)</li>
<li><a href="https://medium.com/syncedreview/gan-2-0-nvidias-hyperrealistic-face-generator-e3439d33ebaf" target="_blank">GAN 2.0: NVIDIA’s Hyperrealistic Face Generator<br /></a>(<a href="https://medium.com/syncedreview/gan-2-0-nvidias-hyperrealistic-face-generator-e3439d33ebaf" target="_blank">https://medium.com/syncedreview/gan-2-0-nvidias-hyperrealistic-face-generator-e3439d33ebaf</a>)</li>
<li><a href="https://arxiv.org/pdf/1812.04948.pdf" target="_blank">A Style-Based Generator Architecture for Generative Adversarial Networks<br /></a>(<a href="https://arxiv.org/pdf/1812.04948.pdf" target="_blank">https://arxiv.org/pdf/1812.04948.pdf</a>)</li>
<li><a href="https://arxiv.org/pdf/1703.10593.pdf) GitHub repository(https://junyanz.github.io/CycleGAN/" target="_blank">Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks<br /></a>(<a href="https://arxiv.org/pdf/1703.10593.pdf) GitHub repository(https://junyanz.github.io/CycleGAN/" target="_blank">https://arxiv.org/pdf/1703.10593.pdf) GitHub repository(https://junyanz.github.io/CycleGAN/</a>)</li>
<li><a href="https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix" target="_blank">Image-to-Image Translation in PyTorch (CycleGAN)<br /></a>(<a href="https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix" target="_blank">https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix</a>)</li>
<li><a href="https://vdalv.github.io/2018/12/04/ganfield.html" target="_blank">GANfield: Something, Something GAT Pun<br /></a>(<a href="https://vdalv.github.io/2018/12/04/ganfield.html" target="_blank">https://vdalv.github.io/2018/12/04/ganfield.html</a>)</li>
<li><a href="https://github.com/zalandoresearch/fashion-mnist" target="_blank">Fashion-MNIST<br /></a>(<a href="https://github.com/zalandoresearch/fashion-mnist" target="_blank">https://github.com/zalandoresearch/fashion-mnist</a>)</li>
<li><a href="https://www.cs.toronto.edu/~kriz/cifar.html" target="_blank">CIFAR-10 and CIFAR-100 Datasets<br /></a>(<a href="https://www.cs.toronto.edu/~kriz/cifar.html" target="_blank">https://www.cs.toronto.edu/~kriz/cifar.html</a>)</li>
<li><a href="http://ufldl.stanford.edu/housenumbers/" target="_blank">SVHN Dataset<br /></a>(<a href="http://ufldl.stanford.edu/housenumbers/" target="_blank">http://ufldl.stanford.edu/housenumbers/</a>)</li>
<li><a href="http://imagenet.stanford.edu/" target="_blank">ImageNet Dataset<br /></a>(<a href="http://imagenet.stanford.edu/" target="_blank">http://imagenet.stanford.edu/</a>)</li>
<li><a href="http://www.image-net.org/papers/ImageNet_VSS2009.pdf" target="_blank">Construction and Analysis of a Large Scale Image Ontology<br /></a>(<a href="http://www.image-net.org/papers/ImageNet_VSS2009.pdf" target="_blank">http://www.image-net.org/papers/ImageNet_VSS2009.pdf</a>)</li>
<li><a href="https://qz.com/1034972/the-data-that-changed-the-direction-of-ai-research-and-possibly-the-world/" target="_blank">The Data that Transformed AI Research—and Possibly the World<br /></a>(<a href="https://qz.com/1034972/the-data-that-changed-the-direction-of-ai-research-and-possibly-the-world/" target="_blank">https://qz.com/1034972/the-data-that-changed-the-direction-of-ai-research-and-possibly-the-world/</a>)</li>
<li><a href="http://cocodataset.org/#home" target="_blank">Microsoft COCO Dataset<br /></a>(<a href="http://cocodataset.org/#home" target="_blank">http://cocodataset.org/#home</a>)</li>
<li><a href="https://arxiv.org/pdf/1405.0312.pdf" target="_blank">Microsoft COCO: Common Objects in Context<br /></a>(<a href="https://arxiv.org/pdf/1405.0312.pdf" target="_blank">https://arxiv.org/pdf/1405.0312.pdf</a>)</li>
<li><a href="http://cocodataset.org/#keypoints-2019" target="_blank">COCO 2019 Keypoint Detection Task<br /></a>(<a href="http://cocodataset.org/#keypoints-2019" target="_blank">http://cocodataset.org/#keypoints-2019</a>)</li>
<li><a href="https://medium.com/s/story/no-happy-little-accidents-8663540763f8" target="_blank">My Data Science Horror Story<br /></a>(<a href="https://medium.com/s/story/no-happy-little-accidents-8663540763f8" target="_blank">https://medium.com/s/story/no-happy-little-accidents-8663540763f8</a>)</li>
</ul>
<p></p>