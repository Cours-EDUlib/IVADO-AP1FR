<p>Jeremy demonstrates how backpropagation is computed in CNNs using the chain rule and a computational graph. The gradient is computed with respect to kernel weights and inputs using a toy example. He wraps up by putting all the pieces together to give a global overview of how the weights are updated during backpropagation in a CNN. Understanding this math at least once is important to get an intuition as to what is actually taking place inside the models that deep learning frameworks already implement.</p>
<p>All reference materials can be viewed here:Â <a href="https://courses.edx.org/courses/course-v1:UMontrealX+IVADO-DL-101+1T2020/courseware/962e7495cf4c4614964f388750806f8f/df1e0e5f48ab483f80016f89204d9b35/6?activate_block_id=block-v1%3AUMontrealX%2BIVADO-DL-101%2B1T2020%2Btype%40vertical%2Bblock%40d97c9efd38c84a9d8e63a55370be87e2" target="_blank">3.2 - References</a></p>