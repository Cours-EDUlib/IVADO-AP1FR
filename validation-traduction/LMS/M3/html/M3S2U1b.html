Jeremy d&eacute;montre comment la r&eacute;tropropagation est calcul&eacute;e dans les RNC en utilisant la r&egrave;gle de cha&icirc;ne et un graphe de calcul. Le gradient est calcul&eacute; par rapport au poids du noyau et aux entr&eacute;es en utilisant un exemple jouet. Il conclut en rassemblant tous les &eacute;l&eacute;ments pour donner un aper&ccedil;u global de la mani&egrave;re dont les poids sont mis &agrave; jour pendant la r&eacute;tropropagation dans un RNC. Il est important de comprendre ce calcul au moins une fois pour avoir une intuition de ce qui se passe r&eacute;ellement dans les mod&egrave;les que les cadres d&apos;apprentissage profond mettent d&eacute;j&agrave; en &oelig;uvre.