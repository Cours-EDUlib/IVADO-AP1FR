<p>Mirko begins the part on word embeddings by first re-stating the limitation of one-hot vectors. He presents an alternative known as a distributed representation, which provides much more flexibility and can be used to create vector representations that expose useful properties. Among these, semantically similar tokens are close in the vector space, and the vector distribution in the space captures information about relationships between various tokens.</p>
<p>All reverence materials can be viewed here: <a href="https://courses.edx.org/courses/course-v1:UMontrealX+IVADO-DL-101+1T2020/courseware/695f1a4ca0ea464b9b898695473ab7c6/c11ca704a56c42a0a48e05a757d2a926/9?activate_block_id=block-v1%3AUMontrealX%2BIVADO-DL-101%2B1T2020%2Btype%40vertical%2Bblock%40aaf31cffb7804d3c96af09c31d29e81b" target="_blank">4.3 - References</a></p>
<p></p>