<p>Taking it a step further than ELMo, Mirko presents BERT, a transformer architecture that leverages the pre-training phase to crush the previous state of the art results. Considered by many to be the go-to baseline architecture for most NLP tasks, BERT is a foundational model in any NLP practitioner's toolbox.</p>
<p>All reverence materials can be viewed here: <a href="https://courses.edx.org/courses/course-v1:UMontrealX+IVADO-DL-101+1T2020/courseware/695f1a4ca0ea464b9b898695473ab7c6/c11ca704a56c42a0a48e05a757d2a926/9?activate_block_id=block-v1%3AUMontrealX%2BIVADO-DL-101%2B1T2020%2Btype%40vertical%2Bblock%40aaf31cffb7804d3c96af09c31d29e81b" target="_blank">4.3 - References</a></p>
<p></p>