<problem display_name="Question 6" markdown="&gt;&gt;Identify the right problem with the right solution in the following figures.&lt;&lt;&#10;&#10;( ) The model is overfitting; increase the model complexity. {{If the model is overfitting, you should increase regularization.}} &lt;img src=&quot;/static/Module_10_Question_13_overfitting_vs_underfitting_figure_1.png&quot; height=&quot;300&quot; alt=&quot;A graph representing the loss function's value as a curve on the vertical axis and the number of epochs of training on the horizontal axis.Initially, both training error and validation error decrease as the number of epochs of training increases. However, eventually, validation error starts increasing while training error continues to decrease slightly.&quot;/&gt; &lt;img src=&quot;/static/Module_1_Question_13_risk_vs_empirical_risk_figure_4.png&quot; height=&quot;50&quot;/&gt;&#10;&#10;(x) The model is underfitting; increase the model complexity. {{The training loss (i.e. empirical risk) should be lower and so, the model class has too much bias. }} &lt;img src=&quot;/static/Module_10_Question_13_overfitting_vs_underfitting_figure_2.png&quot; height=&quot;300&quot; alt=&quot;A graph representing the loss function's value as a curve on the vertical axis and the number of epochs of training on the horizontal axis.Initially, both training error and validation error decrease as the number of epochs of training increases.However, both the training error and the validation error plateau about halfway through the training, with no notable decrease for either error beyond that point. The training error is slightly lower than the validation error.&quot;/&gt; &lt;img src=&quot;/static/Module_1_Question_13_risk_vs_empirical_risk_figure_4.png&quot; height=&quot;50&quot;/&gt;&#10;( ) The model is underfitting; increase the model complexity. {{It can happen that the validation loss is lower than the training loss. Remember that these quantities are estimated from a finite number of examples. Thus, there are uncertainties around the curves.}} &lt;img src=&quot;/static/Module_10_Question_13_overfitting_vs_underfitting_figure_3.png&quot; height=&quot;300&quot; alt=&quot;A graph representing the loss function's value as a curve on the vertical axis and the number of epochs of training on the horizontal axis.Initially, both training error and validation error decrease as the number of epochs of training increases. Eventually, both the training and validation error reach very low values, with the validation error slightly below the training error.&quot;/&gt; &lt;img src=&quot;/static/Module_1_Question_13_risk_vs_empirical_risk_figure_4.png&quot; height=&quot;50&quot;/&gt;&#10;( ) The model is overfitting; the training set has a different data distribution than the test set. {{There is a problem with generalization. Since the validation loss is very high, it seems that the model captures features that are relevant only for the training set. The probability that it happens by chance is very low and so, probably there is a mismatch in the data distributions of the training and the validation set.}} &lt;img src=&quot;/static/Module_10_Question_13_overfitting_vs_underfitting_figure_4.png&quot; height=&quot;300&quot; alt=&quot;A graph representing the loss function's value as a curve on the vertical axis and the number of epochs of training on the horizontal axis.Initially, both training error and validation error decrease as the number of epochs of training increases. However, the validation error quickly begins increasing, while the training error continues to decrease. Compared to the first option, the validation error's curve is diverging from the training error's curve much faster.&quot;/&gt; &lt;img src=&quot;/static/Module_1_Question_13_risk_vs_empirical_risk_figure_4.png&quot; height=&quot;50&quot;/&gt;&#10;&#10;||If the model severely overfits, the iid assumption required when you split your data in a training and a validation set may not be respected.||" max_attempts="2">
  <multiplechoiceresponse>
    <label>Identifiez le bon problème associé à la bonne solution dans les figures suivantes.</label>
    <choicegroup type="MultipleChoice">
      <choice correct="false">Le modèle surapprend: il faut augmenter la complexité du modèle. <img src="/static/Module_10_Question_13_overfitting_vs_underfitting_figure_1.png" height="300" alt="A graph representing the loss function's value as a curve on the vertical axis and the number of epochs of training on the horizontal axis.Initially, both training error and validation error decrease as the number of epochs of training increases. However, eventually, validation error starts increasing while training error continues to decrease slightly."/> <img src="/static/Module_1_Question_13_risk_vs_empirical_risk_figure_4.png" height="50"/> <choicehint>Si le modèle surapprend, vous devriez augmenter la régularisation.</choicehint></choice>
      <choice correct="true">Le modèle sousapprend: il faut augmenter la complexité du modèle. <img src="/static/Module_10_Question_13_overfitting_vs_underfitting_figure_2.png" height="300" alt="A graph representing the loss function's value as a curve on the vertical axis and the number of epochs of training on the horizontal axis.Initially, both training error and validation error decrease as the number of epochs of training increases.However, both the training error and the validation error plateau about halfway through the training, with no notable decrease for either error beyond that point. The training error is slightly lower than the validation error."/> <img src="/static/Module_1_Question_13_risk_vs_empirical_risk_figure_4.png" height="50"/> <choicehint>La perte d’entraînement (c.-à-d. le risque empirique) devrait être plus petite et donc, l&apos;espace du modèle a trop de biais.</choicehint></choice>
      <choice correct="false">Le modèle sousapprend: il faut augmenter la complexité du modèle. <img src="/static/Module_10_Question_13_overfitting_vs_underfitting_figure_3.png" height="300" alt="A graph representing the loss function's value as a curve on the vertical axis and the number of epochs of training on the horizontal axis.Initially, both training error and validation error decrease as the number of epochs of training increases. Eventually, both the training and validation error reach very low values, with the validation error slightly below the training error."/> <img src="/static/Module_1_Question_13_risk_vs_empirical_risk_figure_4.png" height="50"/> <choicehint>Il peut arriver que la perte de validation soit inférieure à la perte d’entraînement. N&apos;oubliez pas que ces quantités sont estimées à partir d&apos;un nombre limité d&apos;exemples. Ainsi, il y a des incertitudes autour des courbes.</choicehint></choice>
      <choice correct="false">Le modèle surapprend; les ensembles d&apos;entraînement et d’évaluation ont des distributions de données différentes. <img src="/static/Module_10_Question_13_overfitting_vs_underfitting_figure_4.png" height="300" alt="A graph representing the loss function's value as a curve on the vertical axis and the number of epochs of training on the horizontal axis.Initially, both training error and validation error decrease as the number of epochs of training increases. However, the validation error quickly begins increasing, while the training error continues to decrease. Compared to the first option, the validation error's curve is diverging from the training error's curve much faster."/> <img src="/static/Module_1_Question_13_risk_vs_empirical_risk_figure_4.png" height="50"/> <choicehint>Il y a un problème de généralisation. Puisque la perte de validation est très élevée, il semble que le modèle saisit des caractéristiques qui ne sont pertinentes que pour l’ensemble d’entraînement. La probabilité que cela se produise par hasard est très faible et il y a probablement une différence entre les distributions de données des ensembles d’entraînement et de validation.</choicehint></choice>
    </choicegroup>
  </multiplechoiceresponse>
  <demandhint>
    <hint>Si le modèle surapprend gravement, l&apos;hypothèse iid requise lorsque vous divisez vos données en ensembles d’entraînement et de validation peut ne pas être respectée.</hint>
  </demandhint>
</problem>