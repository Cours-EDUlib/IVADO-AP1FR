<problem>
<choiceresponse>
  <label>Quelles sont les trois caractéristiques vraies du modèle BERT ?</label>
<checkboxgroup>
    <choice correct="true">A. BERT utilise une architecture basée sur les transformateurs, contrairement au modèle ELMO, qui utilise des RNR <choicehint selected="true">A. Correct. Cela rend l’entraînement beaucoup plus facile à paralléliser que les architectures basées sur les RNR.</choicehint></choice>
    <choice correct="true">B. BERT fait le pré-entraînement sur la modélisation du langage masquée au lieu de la modélisation du langage classique <choicehint selected="true">B. Correct. La modélisation du langage masquée est une forme d’entraînement autosupervisée, qui facilite l&apos;acquisition de données.</choicehint></choice>
    <choice correct="false">C. BERT utilise des réseaux de neurones récurrents bidirectionnels profonds <choicehint selected="true">C. Incorrect, l&apos;architecture de BERT est basée sur des transformateurs, et non des RNR</choicehint></choice>
    <choice correct="true">D. BERT peut accéder aux contextes du passé et du futur lorsqu&apos;il prédit un mot manquant <choicehint selected="true">D. Correct. Le mécanisme d&apos;attention dans les architectures à base de transformateurs peut accéder aux contextes du futur et du passé.</choicehint></choice>
    <compoundhint value="A B C D">Veuillez choisir 3 options.</compoundhint>
  </checkboxgroup>
</choiceresponse>
</problem>