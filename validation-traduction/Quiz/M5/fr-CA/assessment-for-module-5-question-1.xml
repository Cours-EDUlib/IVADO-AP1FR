<problem display_name="Question 1" markdown="&gt;&gt;Select the statements that apply to fairness in machine learning. || Please choose two options.|| &lt;&lt;&#10;&#10;[x] A. The impossibility theorem states that it is impossible to satisfy all definitions of fairness simultaneously. {{ selected: A. Correct, fairness is not a general concept, and it will often consist of many tradeoffs, such as between individual fairness and group fairness. Often times, a machine learning practitioner will have to choose, which definitions of fairness they are willing to satisfy. The important thing to remember is that these choices should be made explicitly, along with an explanation of how these choices were made. }}&#10;[ ] B. Fairness is a general concept that does not have a mathematical definition. {{selected: B. Incorrect, this statement is wrong. First, fairness is not a general concept. It is subjective, which is why there are many different concepts of fairness. Second, many concepts of fairness do have a mathematical definition, which makes it possible for a machine learning practitioner to include them directly into the machine learning pipeline. }}&#10;[ ] C. High overall model accuracy guarantees that the model is fair. {{selected: C. Incorrect, overall accuracy of a model does not ensure that all subsets of the data are being treated equally. A model could report a high overall accuracy, but report poor accuracies on subgroups. For example, a model could correctly classify images of men vs. women (gender classification) with high accuracy, but perform poorly on the African-American women subgroup (gender + race classification).}}&#10;[x] D. When fairness constraints are added to a Machine Learning task, it can become more difficult to solve. {{selected: D. Correct, fairness can often add additional constraints to the optimization portion of machine learning, making it more difficult for the parameter optimizer to find a good solution. The development of creative solutions regarding these additional constraints is an active field of research and a great opportunity.}}&#10;{{ ((A B C)) Please choose 2 options. }}&#10;{{ ((A B D)) Please choose 2 options. }}&#10;{{ ((A C D)) Please choose 2 options. }}&#10;{{ ((B C D)) Please choose 2 options. }}&#10;{{ ((A B C D)) Please choose 2 options. }}&#10;&#10;" max_attempts="2">
  <choiceresponse>
    <label>Sélectionnez les énoncés qui s&apos;appliquent à l&apos;équité en apprentissage automatique.</label>
    <description>Veuillez choisir deux options.</description>
    <checkboxgroup>
      <choice correct="true">A. Le théorème d&apos;impossibilité stipule qu&apos;il est impossible de satisfaire simultanément toutes les définitions de l&apos;équité. <choicehint selected="true">A. Correct, l&apos;équité n&apos;est pas un concept général, et elle implique souvent de nombreux compromis, par exemple, entre l&apos;équité individuelle et l&apos;équité de groupe. Souvent, un professionnel en apprentissage automatique devra choisir les définitions de l&apos;équité qu&apos;il est prêt à satisfaire. L&apos;important est de se rappeler que ces choix doivent être faits explicitement, avec une explication de la manière dont ils ont été faits.</choicehint></choice>
      <choice correct="false">B. L&apos;équité est un concept général qui n&apos;a pas de définition mathématique. <choicehint selected="true">B. Incorrect, cet énoncé est faux. Premièrement, l&apos;équité n&apos;est pas un concept général. L’équité est subjective, c&apos;est pourquoi il existe de nombreux concepts différents d&apos;équité. Deuxièmement, de nombreux concepts d&apos;équité ont une définition mathématique, ce qui permet à un professionnel apprentissage automatique de les inclure directement dans le pipeline de l&apos;apprentissage automatique. C. La précision élevée globale du modèle garantit que le modèle est juste.</choicehint></choice>
      <choice correct="false">C. Incorrect, l&apos;exactitude globale d&apos;un modèle ne garantit pas que tous les sous-ensembles de données sont traités de la même manière. <choicehint selected="true">C. Incorrect, overall accuracy of a model does not ensure that all subsets of the data are being treated equally. A model could report a high overall accuracy, but report poor accuracies on subgroups. Par exemple, un modèle pourrait classer correctement les images des hommes par rapport aux femmes (classification par sexe) avec une exactitude élevée, mais obtenir de mauvais résultats dans le sous-groupe des femmes afro-américaines (classification par sexe et race).</choicehint></choice>
      <choice correct="true">D. Lorsque des contraintes d&apos;équité sont ajoutées à une tâche d&apos;apprentissage automatique, celle-ci peut devenir plus difficile à résoudre. <choicehint selected="true">D. Correct, l’ajout de l’équité peut entraîner des contraintes supplémentaires à la partie optimisation de l&apos;apprentissage automatique. Il est donc plus difficile pour l&apos;optimiseur de paramètres de trouver une bonne solution. Le développement de solutions créatives concernant ces contraintes supplémentaires est un domaine de recherche actif et représente une belle occasion.</choicehint></choice>
      <compoundhint value="A B C">Veuillez choisir 2 options.</compoundhint>
      <compoundhint value="A B D">Veuillez choisir 2 options.</compoundhint>
      <compoundhint value="A C D">Veuillez choisir 2 options.</compoundhint>
      <compoundhint value="B C D">Veuillez choisir 2 options.</compoundhint>
      <compoundhint value="A B C D">Veuillez choisir 2 options.</compoundhint>
    </checkboxgroup>
  </choiceresponse>
</problem>