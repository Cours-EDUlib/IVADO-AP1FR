<problem display_name="Question 2" markdown="&gt;&gt;Only one of the following statements about bias and discrimination in machine learning is false. Please select it.&lt;&lt;&#10;&#10;( ) Data bias comes from a multitude of possible sources. {{Data bias can come from sources such as population bias, behavioural bias, content production bias, linking bias, and temporal bias.}}&#10;( ) Data cleaning methods, such as data massaging, do not solve the issue of data bias. {{ Data cleaning methods like data massaging are dangerous because they change the distribution of the data according to the method used. Most of these methods have prohibitive setbacks that make them dangerous to use and they should not be used without considerable expertise.}}&#10;( ) Data bias and data quality are not interchangeable terms. {{Although they are related, data bias is a systematic distortion in data that compromises its use for a task. It is a much more specific problem than that of data quality, which may be random. Data bias problems induce data quality problems, the inverse is not necessarily true.}}&#10;(x) Problems with fairness occur during the pre-processing and processing phases, but not during the post-processing phase. {{Since many machine learning systems are complex, it can be hard to justify their output, which can make it difficult to understand whether a model is being fair or not. Machine learning practitioners can resort to blackboxing methods: instead of trying to interpret a model's inner workings, they feed the model various examples to see if it discriminates based on sensitive attributes or not. }}" max_attempts="2">
  <multiplechoiceresponse>
    <label>Seul un des énoncés suivants sur le biais et la discrimination en apprentissage automatique est faux. Veuillez sélectionner l’énoncé.</label>
    <choicegroup type="MultipleChoice">
      <choice correct="false">Le biais dans les données provient d&apos;une multitude de sources possibles. <choicehint>Le biais dans les données peut provenir de sources telles que le biais de population, le biais comportemental, le biais de production de contenu, le biais de liaison et le biais temporel.</choicehint></choice>
      <choice correct="false">Les méthodes de nettoyage des données comme l’ajustement des données ne permettent pas de résoudre le problème du biais dans les données. <choicehint>Les méthodes de nettoyage des données comme l’ajustement des données sont dangereuses, car elles modifient la distribution des données en fonction de la méthode utilisée. La plupart de ces méthodes présentent des inconvénients limitatifs qui les rendent dangereuses à utiliser et elles ne devraient pas être utilisées sans une expertise considérable.</choicehint></choice>
      <choice correct="false">Le biais dans les données et la qualité des données ne sont pas des termes interchangeables. <choicehint>Bien que ces termes soient liés, le biais dans les données est une distorsion systématique des données qui compromet leur utilisation pour une tâche. Il s&apos;agit d&apos;un problème beaucoup plus spécifique que celui de la qualité des données, qui peut être de caractère aléatoire. Les problèmes de biais dans les données entraînent des problèmes de qualité des données, l&apos;inverse n&apos;est pas nécessairement vrai.</choicehint></choice>
      <choice correct="true">Les problèmes d&apos;équité surviennent pendant les phases de prétraitement et de traitement, mais pas pendant la phase de post-traitement. <choicehint>Comme de nombreux systèmes d&apos;apprentissage automatique sont complexes, il peut être difficile de justifier leurs sorties. Il peut donc être difficile de déterminer si un modèle est équitable ou non. Les professionnels en apprentissage automatique peuvent recourir à des méthodes de boîte noire : au lieu d&apos;analyser le fonctionnement interne d’un modèle, ils fournissent au modèle des exemples variés pour voir si celui-ci fait de la discrimination sur la base d&apos;attributs sensibles.</choicehint></choice>
    </choicegroup>
  </multiplechoiceresponse>
</problem>