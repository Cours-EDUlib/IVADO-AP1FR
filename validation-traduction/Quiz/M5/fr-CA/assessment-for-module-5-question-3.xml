<problem display_name="Question 3" markdown="&gt;&gt; Regarding challenging tasks in fairness for machine learning, which of the following are true? || Please choose two options.|| &lt;&lt;&#10;&#10;[x] A. The complexity of the real world can hinder the ML practitioner’s ability to make a machine learning pipeline fair. {{selected: A. Correct, ML systems are often used together, which means that bias in one system will propagate to the others, and making systems fair independently does not imply that they will be fair as a whole.}}&#10;[ ] B. Finding an all-encompassing definition of fairness in ML is recommended. {{selected: B. Incorrect, the impossibility theorem states, two separate definitions can often be irreconcilable. It is important to be aware of these differences and tradeoffs between definitions, not to attempt to come up with some super-definition of fairness that encompasses all other definitions.}}&#10;[ ] C. Finding fairness concepts that encompass many different fields is recommended. {{selected: C. Incorrect, it is important to remember that not all of the requirements of the various definitions of fairness can always be met by one model simultaneously. It is more important to choose the right definition of fairness for a given field, not to attempt to find definitions that supersede the nuances that different fields will bring.}}&#10;[x] D. Including sub-groups into definitions of fairness is recommended. {{selected: D. Correct, oftentimes, only one sensitive attribute will be accounted for when including fairness into an ML system. This can lead to various subgroups of the data being treated unfairly.}}&#10;&#10;&#10;{{ ((A B C)) Please choose 2 options. }}&#10;{{ ((A B D)) Please choose 2 options. }}&#10;{{ ((A C D)) Please choose 2 options. }}&#10;{{ ((B C D)) Please choose 2 options. }}&#10;{{ ((A B C D)) Please choose 2 options. }}" max_attempts="2">
  <choiceresponse>
    <label>Quels énoncés suivants concernant les tâches difficiles en matière d&apos;équité en apprentissage automatique sont vrais?</label>
    <description>Veuillez choisir deux options.</description>
    <checkboxgroup>
      <choice correct="true">A. La complexité de la vie réelle peut entraver la capacité du professionnel en apprentissage automatique à rendre équitable un pipeline d&apos;apprentissage automatique. <choicehint selected="true">A. Correct, les systèmes en apprentissage automatique sont souvent utilisés ensemble, ce qui signifie que le biais d&apos;un système se propage aux autres, et le fait de rendre les systèmes équitables indépendamment n&apos;implique pas qu&apos;ils seront équitables dans l’ensemble.</choicehint></choice>
      <choice correct="false">B. Il est recommandé de trouver une définition globale de l&apos;équité en matière d’apprentissage automatique. <choicehint selected="true">B. Incorrect, le théorème d&apos;impossibilité stipule que deux définitions distinctes sont souvent incompatibles. Il est important d&apos;être conscient de ces différences et de ces compromis entre les définitions, et de ne pas essayer de trouver une définition générale de l&apos;équité qui englobe toutes les autres définitions.</choicehint></choice>
      <choice correct="false">C. Il est recommandé de trouver des concepts d&apos;équité qui englobent de nombreux domaines différents. <choicehint selected="true">C. Incorrect, il est important de se rappeler que toutes les exigences des différentes définitions de l&apos;équité ne peuvent pas toujours être satisfaites simultanément par un seul modèle. Il est plus important de choisir la bonne définition de l&apos;équité pour un domaine donné, et non de tenter de trouver des définitions qui ne prennent pas en compte les nuances dans les différents domaines.</choicehint></choice>
      <choice correct="true">D. Il est recommandé d&apos;inclure des sous-groupes dans les définitions de l&apos;équité. <choicehint selected="true">D. Correct, il arrive souvent qu’un seul attribut sensible soit pris en compte lors de l&apos;inclusion de l&apos;équité dans un système d’apprentissage automatique. En conséquence, des sous-groupes de données peuvent être traités de manière inéquitable.</choicehint></choice>
      <compoundhint value="A B C">Veuillez choisir 2 options.</compoundhint>
      <compoundhint value="A B D">Veuillez choisir 2 options.</compoundhint>
      <compoundhint value="A C D">Veuillez choisir 2 options.</compoundhint>
      <compoundhint value="B C D">Veuillez choisir 2 options.</compoundhint>
      <compoundhint value="A B C D">Veuillez choisir 2 options.</compoundhint>
    </checkboxgroup>
  </choiceresponse>
</problem>