0
00:00:14,500 --> 00:00:21,620
Cette section porte sur les données, donc nous allons aller un peu plus dans les

1
00:00:21,620 --> 00:00:31,369
détails de comment nous transformons et prétraitons les données et comment apporter

2
00:00:31,369 --> 00:00:36,809
les données en tant qu'entrée pour les modèles d'apprentissage profond. Ceci est une

3
00:00:36,809 --> 00:00:45,280
version simplifiée du cycle de vie des données. Généralement, j'ai une réalité super

4
00:00:45,280 --> 00:00:49,590
complexe que nous ne pouvons pas comprendre dans son entièreté. Alors, nous utiliserons

5
00:00:49,590 --> 00:00:56,290
des capteurs pour extraire des informations partielles de la réalité et nous mesurerons

6
00:00:56,290 --> 00:01:02,230
certaines caractéristiques de la réalité. Ces

7
00:01:02,230 --> 00:01:06,870
caractéristiques seront organisées par exemplaire. Nous verrons la définition de ce

8
00:01:06,870 --> 00:01:11,700
concept dans la diapositive suivante. Ces caractéristiques seront prétraitées.

9
00:01:11,700 --> 00:01:16,360
J'obtiendrai une représentation que nous appelons "locale", je la donnerai à

10
00:01:16,360 --> 00:01:22,750
mon modèle et le modèle produira une autre représentation qui sera donnée à

11
00:01:22,750 --> 00:01:29,340
un décideur qui fera des actions en vraie vie, puis ensuite je récupère de

12
00:01:29,340 --> 00:01:39,440
nouvelles données. Vous pouvez voir l'image globale, alors qu'est-ce qu'un exemple?

13
00:01:39,440 --> 00:01:45,290
De façon concrète, un exemple est un ensemble de données qui est autonome,

14
00:01:45,290 --> 00:01:50,439
indépendant et distribué de manière identique. Prenons un exemple pour voir ces

15
00:01:50,439 --> 00:01:58,070
trois concepts: j'étudierai les fleurs,  cet ensemble de données sur les fleurs d'iris

16
00:01:58,070 --> 00:02:06,350
a été utilisé par le célèbre statisticien Ronald Fisher en 1936. Cet ensemble de

17
00:02:06,350 --> 00:02:13,860
données a été recueilli dans les Appalaches, je pense en Gaspésie et aussi près de la

18
00:02:13,860 --> 00:02:19,450
frontière des États-Unis. Nous étions donc déjà en train de recueillir des données en Gaspésie

19
00:02:19,450 --> 00:02:27,170
pour l'AA dans les années 1930. Pour cet exemple, on peut voir que si je demande à un

20
00:02:27,170 --> 00:02:32,230
biologiste, "quelles sont les caractéristiques nécessaires pour prédire l'espèce d'un iris?", j'ai

21
00:02:32,230 --> 00:02:37,170
trois différents espèces d'Iris. Je veux mesurer certaines caractéristiques, je ne

22
00:02:37,170 --> 00:02:42,750
veux pas utiliser toutes les informations de cette fleur mais seulement quelques caractéristiques

23
00:02:42,750 --> 00:02:47,790
pour prédire l'espèce de l'iris. Le biologiste peut me dire,  "vous avez juste

24
00:02:47,790 --> 00:02:53,730
besoin de quatre caractéristiques: la largeur et la hauteur du pétale et la largeur et

25
00:02:53,730 --> 00:03:00,209
la hauteur du sépale." Avec ces quatre mesures, vous pouvez déjà apprendre

26
00:03:00,209 --> 00:03:05,590
l'espèce de cette fleur. Donc, si je prends une fleur et je mesure ces quatre caractéristiques,

27
00:03:05,590 --> 00:03:11,540
cet exemple est autonome: j'ai toutes les informations nécessaires avec

28
00:03:11,540 --> 00:03:15,349
probablement un peu de bruit, mais j'ai assez d'informations pour prédire mon

29
00:03:15,349 --> 00:03:24,069
étiquette. Ici, j'ai aussi la notion d'indépendance: l'occurrence

30
00:03:24,069 --> 00:03:30,500
de cet exemple en réalité devrait être aussi

31
00:03:30,500 --> 00:03:35,740
indépendant que possible des autres exemples: vous ne devriez probablement pas

32
00:03:35,740 --> 00:03:41,260
mesurer et collecter toutes vos données de votre jardin, car il se peut que la

33
00:03:41,260 --> 00:03:46,380
sorte de terre que vous utilisez corrèle avec vos caractéristiques.

34
00:03:46,380 --> 00:03:51,620
La largeur et la hauteur des pétales auront la même

35
00:03:51,620 --> 00:03:56,299
distribution dans votre jardin, mais si vous allez à un autre endroit, la

36
00:03:56,299 --> 00:04:00,750
distribution sera peut-être différente: c'est le processus sous-jacent qui

37
00:04:00,750 --> 00:04:05,069
génère des fleurs qui n'ee sont pas indépendantes et

38
00:04:05,069 --> 00:04:11,480
distribuées de manière identique. Cela signifie que vous devez considérer toutes les

39
00:04:11,480 --> 00:04:15,770
fleurs d'iris possibles dans le monde. non seulement doivent-elles être indépendantes,

40
00:04:15,770 --> 00:04:19,970
mais encore devez-vous couvrir toute variation de la fleur d'iris où vous souhaitez

41
00:04:19,970 --> 00:04:26,370
utiliser votre modèle. Donc si vous allez dans un autre pays pour utiliser votre modèle,

42
00:04:26,370 --> 00:04:29,600
mais devriez probablement aller dans ce pays récupérer des données pour entraîner votre modèle.

43
00:04:29,600 --> 00:04:34,780
S'appuyer uniquement sur la capacité de généralisation de votre modèle et l'utiliser

44
00:04:34,780 --> 00:04:44,690
dans un autre pays où l'iris peut être très différent, c'est risqué. Nous

45
00:04:44,690 --> 00:04:50,930
allons structurer un exemple comme un couple de variables: nous aurons la caractéristique

46
00:04:50,930 --> 00:04:56,430
ici dénommée X et les étiquettes ou les cibles que nous voulons prédire dénommée Y.

47
00:04:56,430 --> 00:05:00,790
Alors là j'ai mes quatre traits, je peux les représenter comme un vecteur de quatre

48
00:05:00,790 --> 00:05:08,330
éléments et ici j'aurai une étiquette parmi trois pour définir l'espèce

49
00:05:08,330 --> 00:05:15,770
de la fleur. Il y a quelques difficultés d'indépendance: disons que j'ai une

50
00:05:15,770 --> 00:05:20,550
série chronologique durant une journée: ce sont des mesures durant la journée et je

51
00:05:20,550 --> 00:05:24,961
veux donner toute la série chronologique à mon modèle pour prédire si cette série

52
00:05:24,961 --> 00:05:34,169
chronologique est normale ou non. Si je n'ai pas beaucoup de données, je peux

53
00:05:34,169 --> 00:05:39,490
prendre des sous-parties de cette série chronologique. Donc, ma tâche utilisait des séries chronologiques

54
00:05:39,490 --> 00:05:44,190
d'une journée, mais parce que je n'ai pas assez de données, je vais tricher et utiliser cette

55
00:05:44,190 --> 00:05:48,680
sous-partie: j'utiliserai l'étiquette associée pour toute la journée, j'utiliserai

56
00:05:48,680 --> 00:05:52,570
la cible ici, je l'attribuerai à cette sous-partie et je la mettrai dans l'ensemble

57
00:05:52,570 --> 00:05:59,300
d'entraînement. Cette partie, je la mettrai dans mon ensemble d'évaluation. Il pourrait

58
00:05:59,300 --> 00:06:04,050
y avoir des corrélations temporelles entre ces deux. Si mon modèle utilise

59
00:06:04,050 --> 00:06:12,270
uniquement la corrélation temporelle durant la journée pour bien prédire, le

60
00:06:12,270 --> 00:06:16,710
résultat pour celle-ci sera bon sur l'ensemble de d'évaluation. En fait, le modèle

61
00:06:16,710 --> 00:06:21,069
utilise des caractéristiques qu'il ne devrait pas utiliser car cela se produit seulement

62
00:06:21,069 --> 00:06:26,880
durant la journée: j'ai une corrélation temporelle entre les deux exemples. Alors, ils

63
00:06:26,880 --> 00:06:30,580
ne sont pas indépendants. Ce que je peux faire si je n'ai vraiment pas

64
00:06:30,580 --> 00:06:35,440
beaucoup de données et que je veux utiliser cette technique, c'est d'ajouter un tampon entre

65
00:06:35,440 --> 00:06:40,330
les séries temporelles pour tenter de supprimer la corrélation temporelle dans cette série temporelle.

66
00:06:40,330 --> 00:06:45,590
Par contre, c'est risqué parce que je ne connais pas la longueur du tampon que je devrais

67
00:06:45,590 --> 00:06:51,600
utiliser: un expert en données pour cet ensemble particulier peut peut-être vous aider

68
00:06:51,600 --> 00:06:56,360
à décider de la longueur minimale à utiliser pour supprimer la corrélation

69
00:06:56,360 --> 00:07:02,080
temporelle, afin que le modèle ne triche pas en utilisant les corrélations durant la

70
00:07:02,080 --> 00:07:11,130
journée. Même chose pour les images: si je veux prédire quelque chose sur cette énorme

71
00:07:11,130 --> 00:07:18,190
image satellite et que je commence à en extraire des sous-parties et que je mets cette

72
00:07:18,190 --> 00:07:23,009
sous-partie dans l'ensemble d'entraînement et celle-ci dans l'ensemble d'évaluation, il peut

73
00:07:23,009 --> 00:07:29,280
y avoir une corrélation spatiale. C'est la même idée que tantôt, mais ça peut se produire en 2D

74
00:07:29,280 --> 00:07:33,960
ou en n'importe quelle dimension de vos données. Donc, dès que vous prenez un exemple et que vous

75
00:07:33,960 --> 00:07:38,400
extrayez des sous-parties pour créer des nouveaux exemples artificiels, il y a un risque

76
00:07:38,400 --> 00:07:47,479
dont vous devriez être conscient: le modèle peut tricher en utilisant ces corrélations.

77
00:07:47,479 --> 00:07:52,510
Vous pouvez à nouveau utiliser un tampon, mais assurez-vous que vous supprimez la

78
00:07:52,510 --> 00:07:57,949
corrélation spatiale. Ça dépend aussi de la tâche: si la tâche concerne seulement

79
00:07:57,949 --> 00:08:01,990
cette ville et que vous voulez apprendre quelque chose dessus, vous pouvez

80
00:08:01,990 --> 00:08:07,289
utiliser des sous-parties qui sont proches. Par contre, si je veux entraîner un modèle

81
00:08:07,289 --> 00:08:13,020
avec cette ville et l'utiliser pour une autre ville, utiliser des sous-parties dans une

82
00:08:13,020 --> 00:08:20,080
même ville est délicat: je ne suis pas sûr que les caractéristiques utilisées ici

83
00:08:20,080 --> 00:08:25,259
généraliseront à une nouvelle ville parce que j'évalue le modèle avec un ensemble d'évaluation contenant

84
00:08:25,259 --> 00:08:33,070
la même ville. Maintenant, la différence entre une distribution identique ou indépendante:

85
00:08:33,070 --> 00:08:39,860
disons que je veux reconnaître les objets dans les images. Si je n'utilise que des images de Montréal

86
00:08:39,860 --> 00:08:45,200
durant l'hiver, les données la distribution de mes pixels ressemblera à ceci. Si je veux utiliser

87
00:08:45,200 --> 00:08:49,890
ce modèle à l'année longue, vous pouvez voir que la distribution des données des

88
00:08:49,890 --> 00:08:55,200
pixels ici est très différente: ici, j'ai principalement des pixels blancs à cause

89
00:08:55,200 --> 00:09:01,740
de la neige. Ici j'ai des pixels colorés parce que c'est en automne. Si j'entraîne mon

90
00:09:01,740 --> 00:09:07,950
modèle seulement sur des images hivernales, il ne généralisera probablement pas

91
00:09:07,950 --> 00:09:17,820
aux autres saisons, car je n'entraîne mon modèle que sur une partie de la

92
00:09:17,820 --> 00:09:25,220
distribution globale des données. Si je veux que mes données soient identiquement distribuées,

93
00:09:25,220 --> 00:09:29,940
je dois collecter des images à l'année longue, car c'est la période de temps durant laquelle

94
00:09:29,940 --> 00:09:31,800
je veux prédire avec mon modèle.

