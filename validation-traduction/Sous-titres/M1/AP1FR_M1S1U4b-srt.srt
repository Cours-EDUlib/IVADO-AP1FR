0
00:00:14,690 --> 00:00:21,550
Tournons-nous maintenant vers les mesures et les caractéristiques. Comme je l'ai dit, l'apprentissage profond (AP)

1
00:00:21,550 --> 00:00:25,869
consiste à faire de l'apprentissage automatique sur un espace de grande dimension. Comme exemple

2
00:00:25,869 --> 00:00:31,450
d'espace de grande dimension, nous pouvons prendre du texte: je peux

3
00:00:31,450 --> 00:00:37,309
collecter l'intégralité du corpus Wikipédia et je vais prétraiter ces informations brutes,

4
00:00:37,309 --> 00:00:45,120
ces données HTML, pour qu'il ressemble à ma structure d'exemple (X,Y)

5
00:00:45,120 --> 00:00:50,519
que je viens de présenter. Alors votre tâche et la mesure de performance sont définies,

6
00:00:50,519 --> 00:00:54,899
et maintenant avec les données, vous définirez un exemple: que-ce que le X, l'entrée

7
00:00:54,899 --> 00:00:58,940
de mon modèle et la sortie. Vous devriez être en mesure de connaître le nombre

8
00:00:58,940 --> 00:01:03,649
d'exemples que vous avez dans vos données. Pour du texte, c'est le nombre de séquences.

9
00:01:03,649 --> 00:01:09,370
Vous devriez également être en mesure de dire la longueur minimale et maximale d'une

10
00:01:09,370 --> 00:01:14,340
séquence et peut-être quelques statistiques: en moyenne la longueur du texte que je

11
00:01:14,340 --> 00:01:20,970
donne en entrée sera d'environ 10 mots, par exemple. Il  y a d'autres statistiques

12
00:01:20,970 --> 00:01:26,941
comme la fréquence des termes ou l'encodage: est-il encodé en UTF-8 ou un autre?

13
00:01:26,941 --> 00:01:33,280
Pour les images, si votre tâche est, "le X est une image et je veux

14
00:01:33,280 --> 00:01:37,570
prédire quelque chose à propos de cette image", le nombre d'exemples sera le nombre

15
00:01:37,570 --> 00:01:44,040
d'images. Vous devriez également connaître la largeur et la hauteur de l'image, et le

16
00:01:44,040 --> 00:01:48,560
nombre de canaux: considérez-vous les canaux RVB de cette image?

17
00:01:48,560 --> 00:01:52,860
Vous devez également connaître l'encodage: le prétraitement de l'image pour la

18
00:01:52,860 --> 00:01:58,210
transformer en entrée du modèle dépendra également de l'encodage. Enfin, si vous avez

19
00:01:58,210 --> 00:02:03,210
une tâche où l'entrée est une vidéo et la sortie est quelque chose à propos de

20
00:02:03,210 --> 00:02:09,950
la vidéo, une vidéo est faite d'images. Vous pouvez voir que maintenant,

21
00:02:09,950 --> 00:02:15,950
une image n'est plus exemple: le nombre de vidéos

22
00:02:15,950 --> 00:02:20,489
que vous souhaitez utiliser pour l'apprentissage sera le nombre d'exemples,

23
00:02:20,489 --> 00:02:24,880
mais ici aussi, vous aurez la largeur et la hauteur d'une image dans la vidéo, le

24
00:02:24,880 --> 00:02:29,660
nombre de canaux. Peut-être même que vous souhaitez utiliser l'audio ou les sous-titres:

25
00:02:29,660 --> 00:02:35,490
vous devriez connaître le codec, afin que vous puissiez transformer la vidéo en

26
00:02:35,490 --> 00:02:44,060
données qui seront compatibles avec l'entrée d'un modèle. Il y a aussi des données de

27
00:02:44,060 --> 00:02:48,710
graphe qui peuvent être représentées de différentes manières, et aussi des dictionnaires

28
00:02:48,710 --> 00:02:56,209
avec des fichiers en JSON, afin que vous puissiez trouver les propriétés que vous souhaitez

29
00:02:56,209 --> 00:03:02,400
utiliser pour faire le prétraitement. Donc, lorsque vous rencontrez un expert qui vous aidera avec

30
00:03:02,400 --> 00:03:08,880
vos données, assurez-vous d'avoir au moins une partie de ces informations avec vous.

31
00:03:08,880 --> 00:03:14,060
ne dites pas "j'ai beaucoup de données", ce n'est pas assez précis: il faut la structure

32
00:03:14,060 --> 00:03:21,209
des données. Ensuite, regardons le concept de représentation. C'est un peu plus

33
00:03:21,209 --> 00:03:28,880
abstrait, nous allons utiliser le terme représentation encore et encore cette semaine,

34
00:03:28,880 --> 00:03:34,069
mais essayons de comprendre ce que nous entendons par représentation. Une représentation est

35
00:03:34,069 --> 00:03:39,050
une information que j'ai recueillie de la réalité que j'implémente dans un

36
00:03:39,050 --> 00:03:44,730
support favorisant la transformation de ces informations.  Un de ceux à comprendre

37
00:03:44,730 --> 00:03:51,660
cette définition était René Magritte: dans La Trahison des images, il a créé

38
00:03:51,660 --> 00:03:58,900
cette œuvre d'art où il dit "ceci n'est pas une pipe", et la

39
00:03:58,900 --> 00:04:04,370
raison est qu'il regardait l'objet réel en réalité et qu'il a eu une

40
00:04:04,370 --> 00:04:08,420
représentation dans sa tête, dans les neurones de son cerveau, et il a pu

41
00:04:08,420 --> 00:04:14,260
mettre la représentation sur papier. Le premier médium était donc le neurone dans sa tête,

42
00:04:14,260 --> 00:04:19,780
et le second médium était le papier. Maintenant, vous pouvez manipuler ces

43
00:04:19,780 --> 00:04:26,150
représentations comme vous le souhaitez: vous pourriez modifier la forme du tuyau,

44
00:04:26,150 --> 00:04:28,599
etc. pour obtenir de nouvelles représentations, mais la façon

45
00:04:28,599 --> 00:04:33,240
dont vous transformez ces représentations est indépendante de l'objet initial dans la

46
00:04:33,240 --> 00:04:39,810
réalité. Alors, gardez toujours à l'esprit que, même si vous utilisez des données représentées

47
00:04:39,810 --> 00:04:44,460
d'une manière ou d'une autre, les données représentent quelque chose en réalité,

48
00:04:44,460 --> 00:04:49,820
même si les deux ne sont pas identiques après un certain traitement. Les gens ont tendance à l'oublier,

49
00:04:49,820 --> 00:04:54,770
c'est comme si les données étaient la vérité dans l'univers. Non, les données peuvent

50
00:04:54,770 --> 00:05:01,449
être dépréciées après quelques temps et vous devez acquérir de nouvelles données parce que la

51
00:05:01,449 --> 00:05:10,721
réalité change. Une représentation locale a quelques

52
00:05:10,721 --> 00:05:19,100
informations et ces informations sont organisées d'une certaine manière. Donc, l'entrée

53
00:05:19,100 --> 00:05:24,150
d'un réseau de neurones aura ces petits cercles que nous appelons "unités de traitement" et

54
00:05:24,150 --> 00:05:29,000
chaque unité de traitement sera associée à une caractéristique spécifique avec une

55
00:05:29,000 --> 00:05:34,250
définition et peut-être une unité physique. nous l'appelons "local", car ici je peux

56
00:05:34,250 --> 00:05:39,490
voir que la caractéristique «largeur du pétale» exprimée en centimètres est associée à

57
00:05:39,490 --> 00:05:43,820
cette unité de traitement dans mon réseau de neurones artificiels.  C'est facile à

58
00:05:43,820 --> 00:05:50,540
interpréter: je peux dire que cette composante représente la largeur des pétales.

59
00:05:50,540 --> 00:05:56,490
Il existe aussi une représentation distribuée où vous perdez complètement ces informations:

60
00:05:56,490 --> 00:06:03,380
vous pouvez voir cette unité physique, mais cette unité de traitement fusionne des

61
00:06:03,380 --> 00:06:08,190
informations de ma représentation locale ici. Donc, le sens associé à cette unité de traitement

62
00:06:08,190 --> 00:06:13,410
est un mélange de la largeur du pétale, la largeur du sépale, la hauteur du pétale

63
00:06:13,410 --> 00:06:18,250
et hauteur du sépale. Si je vous donne une valeur numérique associée à cette

64
00:06:18,250 --> 00:06:23,509
unité de traitement ce n'est plus interprétable: la distribution locale a été

65
00:06:23,509 --> 00:06:31,790
distribué dans cette unité de traitement ici.

66
00:06:31,790 --> 00:06:34,300
Les représentations distribuées sont beaucoup plus efficaces

67
00:06:34,300 --> 00:06:36,710
que les représentations locales. Nous verrons

68
00:06:36,710 --> 00:06:40,850
un exemple, ils sont utilisés dans les réseaux de neurones artificiels.

69
00:06:40,850 --> 00:06:47,090
C'est pourquoi vous voyez beaucoup d'articles essayant d'interpréter les réseaux

70
00:06:47,090 --> 00:06:52,229
de neurones et essayant de savoir comment le modèle résout la tâche en regardant

71
00:06:52,229 --> 00:06:57,900
à l'intérieur du réseau. Par contre, avec des représentations distribuées, il est super

72
00:06:57,900 --> 00:07:03,340
difficile de savoir ce que la valeur numérique associée à ce nœud encode vraiment.

73
00:07:03,340 --> 00:07:09,690
En entrée et en sortie, la valeur devrait être interprétable. Pourquoi est-ce que

74
00:07:09,690 --> 00:07:14,470
j'utilise des termes comme "l'unité de traitement des données", et "comment est-elle

75
00:07:14,470 --> 00:07:20,830
implémentée"? C'est parce que le premier réseau de neurones artificiels était une machine.

76
00:07:20,830 --> 00:07:26,669
C'était cette machine nommé le "Mark 1 Perceptron" créée en 1958.

77
00:07:26,669 --> 00:07:29,810
La représentation locale a été donnée en entrée à

78
00:07:29,810 --> 00:07:34,699
cette machine avec quelques fils, puis les fils créaient la

79
00:07:34,699 --> 00:07:39,110
représentation distribuée en combinant différents fils de différentes

80
00:07:39,110 --> 00:07:43,870
représentations locales à une seule unité de traitement. Vous pouvez voir à

81
00:07:43,870 --> 00:07:49,530
quel point cette machine était complexe avec tous ces fils partout. De nos jours, nous

82
00:07:49,530 --> 00:07:54,600
simulons ce type de machine sur un ordinateur: nous utilisons toujours le

83
00:07:54,600 --> 00:08:01,319
vocabulaire qui lui est associé mais maintenant tout est simulé dans PyTorch ou

84
00:08:01,319 --> 00:08:04,319
Tensorflow. Par contre, il y avait de vraies machines au

85
00:08:04,319 --> 00:08:13,910
début de l'IA. Un exemple de façon de créer des représentations locales pour du texte:

86
00:08:13,910 --> 00:08:19,289
pour ce texte j'aurai un peu corpus de trois phrases: «nous vivons à Montréal»

87
00:08:19,289 --> 00:08:25,699
«nous vivons ensemble» et «nous aimons l'hiver». J'utiliserai ce qu'on appelle la tokénisation

88
00:08:25,699 --> 00:08:31,229
pour transformer le texte en représentation que je peux utiliser comme entrée pour mon

89
00:08:31,229 --> 00:08:37,509
modèle. La tokénisation peut supprimer les majuscules et également diviser les mots en fonction de

90
00:08:37,509 --> 00:08:42,709
l'espace entre les mots, donc j'obtiens cette représentation intermédiaire.

91
00:08:42,709 --> 00:08:48,270
La dernière étape: j'utiliserai un dictionnaire où pour chaque mot, j'aurai

92
00:08:48,270 --> 00:08:54,770
un identifiant. Donc,  '.' sera associé à 1, 'nous' à 2, 'hiver' à 3,

93
00:08:54,770 --> 00:09:00,830
'ensemble' à 4, etc. et je peux utiliser mon application(mapping) pour obtenir cette

94
00:09:00,830 --> 00:09:09,480
représentation, mais est-ce une bonne représentation? En fait, les entiers ont

95
00:09:09,480 --> 00:09:16,800
un ordre naturel, donc 7 est supérieur à 5. Si je regarde ici, je dirai que "à"

96
00:09:16,800 --> 00:09:22,440
est supérieur à "vis" et cela n'a aucun sens. Les mots ne peuvent pas être ordonnés comme

97
00:09:22,440 --> 00:09:29,950
les entiers peuvent être ordonnés. Donc, au lieu d'utiliser des entiers comme 2 5 7 0 1,

98
00:09:29,950 --> 00:09:33,970
j'utiliserai un autre type d'encodage appelé un encodage one-hot et

99
00:09:33,970 --> 00:09:39,360
un encodage one-hot est un vecteur binaire comme-ci où le nombre d'éléments

100
00:09:39,360 --> 00:09:44,410
de ce vecteur binaire est être le nombre d'éléments dans mon dictionnaire. Ici j'ai

101
00:09:44,410 --> 00:09:49,420
huit éléments à cause de ce jeton. Oh, et je suis désolé de ne pas avoir expliqué ce que c'est

102
00:09:49,420 --> 00:09:57,190
que ce jeton: si mon tokeniseur atteint un mot qui n'est pas dans mon dictionnaire, je peux

103
00:09:57,190 --> 00:10:03,300
toujours utiliser le jeton "inconnu" pour encoder qu'il y avait un mot, mais puisque

104
00:10:03,300 --> 00:10:10,740
mon dictionnaire n'est pas assez grand, je ne peux pas utiliser un identifiant. D'habitude, dans

105
00:10:10,740 --> 00:10:15,800
les langues naturelles, nous aurons des dictionnaires d'une taille entre

106
00:10:15,800 --> 00:10:23,360
50 000 et 100 000. Si nous utilisons la tokenisation sur des espaces, il y a d'autres

107
00:10:23,360 --> 00:10:30,640
façons de le faire plus efficacement. Si je reviens à mon encodage one-hot,

108
00:10:30,640 --> 00:10:34,321
le nombre d'éléments dans mon vecteur binaire est donc le nombre d'éléments dans mon

109
00:10:34,321 --> 00:10:40,450
dictionnaire. Ici, je veux encoder 2: nous irons à la position 2 qui sera

110
00:10:40,450 --> 00:10:48,300
0 1 2 et j'attribuerai ce bit à 1 et le reste sera 0. Je viens

111
00:10:48,300 --> 00:10:54,610
donc de changer de l'encodage en entier à l'encodage one-hot et cet encodage

112
00:10:54,610 --> 00:10:58,940
fonctionne mieux comme entrée pour un réseau de neurones parce que le réseau

113
00:10:58,940 --> 00:11:09,209
n'utilisera pas l'ordre de ces nombres comme caractéristique. Nous pouvons également

114
00:11:09,209 --> 00:11:13,360
faire d'autres transformations sur la représentation locale.

115
00:11:13,360 --> 00:11:22,459
Si j'utilise un vecteur pour représenter une représentation locale, je peux normaliser

116
00:11:22,459 --> 00:11:28,800
chaque composante de ce vecteur indépendamment en utilisant la mise à l'échelle min/max

117
00:11:28,800 --> 00:11:37,000
sur les caractéristiques: Si j'ai un pixel entre 0 et 255, son maximum sera 255, son minimum

118
00:11:37,000 --> 00:11:45,019
sera 0 et je pourrai redimensionner toutes les intensités de pixels entre 0 et 1. Cet

119
00:11:45,019 --> 00:11:50,440
ordre de grandeur entre 0 et 1 fonctionne mieux avec les réseaux de neurones qu'un ordre de

120
00:11:50,440 --> 00:11:59,040
grandeur entre 0 et 255. Il est préférable d'utiliser une petite plage de valeurs

121
00:11:59,040 --> 00:12:06,740
que des plages de valeurs allant à des centaines ou des milliers et la normalisation

122
00:12:06,740 --> 00:12:12,800
est très similaire pour chaque caractéristique: je peux estimer la moyenne empirique

123
00:12:12,800 --> 00:12:19,149
de cette caractéristique sur mon ensemble d'entraînement et je peux estimer l'écart type

124
00:12:19,149 --> 00:12:28,709
empirique sur mon ensemble d'entraînement, puis le normaliser comme-ci. Donc, le message à retenir

125
00:12:28,709 --> 00:12:32,231
de cette présentation est que, tout d'abord, l'apprentissage automatique est un

126
00:12:32,231 --> 00:12:37,160
sous-domaine de l'intelligence artificielle et l'apprentissage profond est un sous-ensemble de

127
00:12:37,160 --> 00:12:42,329
techniques en apprentissage automatique. Pour mettre en œuvre certaines idées que nous

128
00:12:42,329 --> 00:12:47,820
verrons demain, il existe une méthodologie qui empêche l'algorithme d'apprentissage

129
00:12:47,820 --> 00:12:53,240
de tricher et nous avons vu une étape essentielle à faire pour mieux évaluer le modèle,

130
00:12:53,240 --> 00:12:59,100
l'évaluation croisée. Cependant, il existe d'autres outils pour vérifier le

131
00:12:59,100 --> 00:13:04,500
modèle. Ce que nous avons vu tout à l'heure est que les données doivent être indépendantes

132
00:13:04,500 --> 00:13:09,030
et identiquement distribuées et nous verrons d'autres exemples

133
00:13:09,030 --> 00:13:38,300
très bientôt.

