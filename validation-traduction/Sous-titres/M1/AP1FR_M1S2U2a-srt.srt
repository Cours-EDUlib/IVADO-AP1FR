0
00:00:14,030 --> 00:00:19,090
Nous allons donc entrer dans les détails de l'apprentissage supervisé. Maintenant, je vais utiliser

1
00:00:19,090 --> 00:00:24,770
une notation mathématique. Nous ne faisons pas de mathématiques, c'est juste que je veux

2
00:00:24,770 --> 00:00:30,290
utiliser des symboles pour qu'il soit plus facile pour moi de référer à certains concepts, parce que

3
00:00:30,290 --> 00:00:35,450
sinon la diapositive serait pleine de texte. Il n'y a aucune preuve, aucune

4
00:00:35,450 --> 00:00:42,329
démonstration compliquée mathématiquement, c'est juste de la notation. Je vais donc

5
00:00:42,329 --> 00:00:45,610
définir le cadre d'apprentissage statistique et l'objectif

6
00:00:45,610 --> 00:00:50,300
ici est de comprendre plus en détail ce que ça signifie pour un modèle de

7
00:00:50,300 --> 00:00:56,879
tricher et faire du surapprentissage. À la fin, j'espère que vous comprendrez un

8
00:00:56,879 --> 00:01:02,249
peu plus d'où vient le surapprentissage, donc je noterai l'entrée de mon modèle

9
00:01:02,249 --> 00:01:09,140
 avec ce X, l'ensemble du domaine, et Y dénotera l'ensemble d'étiquettes.

10
00:01:09,140 --> 00:01:14,140
Ils doivent être fixés une fois pour toutes: cela signifie que si j'oublie de mettre un

11
00:01:14,140 --> 00:01:20,850
élément dans Y, le modèle ne pourra jamais apprendre cet élément: c'est

12
00:01:20,850 --> 00:01:25,240
l'univers des étiquettes possibles que mon modèle pourra apprendre.

13
00:01:25,240 --> 00:01:32,270
Ensuite je construirai mon ensemble de données étiquetées. Ce sera une liste d'éléments "m" et cette

14
00:01:32,270 --> 00:01:40,399
liste sera des paires d'entrées et sorties, mes "x_1" et "y_1" et ils

15
00:01:40,399 --> 00:01:48,260
viennent d'un ensemble:  X produit avec Y, et X et Y me fourniront les structures

16
00:01:48,260 --> 00:01:56,820
des données. Par exemple, X peut être toutes les images de forme 27 pixels par 27 pixels

17
00:01:56,820 --> 00:02:02,240
avec 3 canaux, c'est ainsi que je définis le X. Je ne peux donc pas recevoir une image

18
00:02:02,240 --> 00:02:07,299
différente de cette forme: je devrais remodeler mes données afin qu'elles respectent ma

19
00:02:07,299 --> 00:02:12,510
spécification de l'entrée de mon modèle, la spécification de X,

20
00:02:12,510 --> 00:02:16,950
et ce sont les mêmes règles pour l'ensemble d'étiquettes.

21
00:02:16,950 --> 00:02:23,629
Ce que nous voulons réussir, c'est d'avoir un algorithme qui prendra cet ensemble de données

22
00:02:23,629 --> 00:02:29,489
et me fournira un autre algorithme, ou ce que nous appelons un modèle, une règle de prédiction,

23
00:02:29,489 --> 00:02:33,819
un prédicteur, une hypothèse ou un classificateur: ce sont tous des termes faisant référence à la

24
00:02:33,819 --> 00:02:39,270
même fonction. L'algorithme d'apprentissage me donnera un modèle qui prendra une

25
00:02:39,270 --> 00:02:49,569
entrée et retournera une sortie, comme c'est illustré ici.

26
00:02:49,569 --> 00:02:52,739
Maintenant, nous reviendrons sur cette hypothèse de

27
00:02:52,739 --> 00:02:59,349
données indépendantes et identiquement distribuées. J'utiliserai un modèle probabiliste

28
00:02:59,349 --> 00:03:07,050
sur la génération de mes données, donc les données sont générées comme un couple d'une

29
00:03:07,050 --> 00:03:12,720
entrée et d'une sortie. Je peux modéliser n'importe quelle distribution de probabilité P sur ces deux espaces

30
00:03:12,720 --> 00:03:21,900
et vraiment, la distribution réelle de mes données est ce D dans l'univers

31
00:03:21,900 --> 00:03:28,090
de toutes les distributions de probabilité de X et Y, et j'en montrerai

32
00:03:28,090 --> 00:03:32,790
un exemple clair après. Donc, pour l'ensemble de données, l'hypothèse est qu'il a

33
00:03:32,790 --> 00:03:40,879
été échantillonné "m" fois de cette distribution de probabilité sur l'entrée et la sortie.

34
00:03:40,879 --> 00:03:45,489
Puisque l'échantillonnage est indépendant et identique, chaque exemple a été

35
00:03:45,489 --> 00:03:50,680
généré par ce "D" et la probabilité de mon ensemble de données est exprimée

36
00:03:50,680 --> 00:03:56,430
ici comme un produit, et nous verrons pourquoi c'est important, restez présents un peu

37
00:03:56,430 --> 00:04:02,420
plus. Alors, cette probabilité de (x_i, y_i) est une façon pour moi de voir un peu si le

38
00:04:02,420 --> 00:04:07,110
point de données que je transfère est une valeur aberrante, est-ce quelque chose de commun, est-ce quelque chose

39
00:04:07,110 --> 00:04:12,519
que je vais voir en production, etc. Nous utilisons les mathématiques pour

40
00:04:12,519 --> 00:04:18,090
caractériser ce modèle, pour faire un lien entre l'ensemble d'entraînement et ce qui

41
00:04:18,090 --> 00:04:24,450
arrivera en production, donc si vous voyez une image d'un chat sur l'internet

42
00:04:24,450 --> 00:04:27,430
et que vous pensez que c'est un chat très drôle à cause des

43
00:04:27,430 --> 00:04:32,320
caractéristiques de ce chat, c'est probablement un exemple rare: c'est quelque chose qui

44
00:04:32,320 --> 00:04:38,690
vous a surpris , auquel vous avez réagi. Si je vous donne juste des photos de mon

45
00:04:38,690 --> 00:04:44,949
chat, vous direz: c'est ennuyeux, parce que mon chat ressemble à tous les autres chats dans

46
00:04:44,949 --> 00:04:48,940
le monde. Donc la probabilité de mon chat est plus élevée que le chat drôle que

47
00:04:48,940 --> 00:04:53,630
vous pouvez voir sur l'Internet, et la façon de le représenter est avec cette

48
00:04:53,630 --> 00:04:58,020
probabilité d'entrée et de sortie. L'entrée est l'image et

49
00:04:58,020 --> 00:05:06,660
la sortie est l'étiquette associée. Nous allons donc définir un autre concept qui est la

50
00:05:06,660 --> 00:05:11,550
mesure du succès, elle est liée à la métrique de performance, mais elle est utilisée

51
00:05:11,550 --> 00:05:17,400
par l'algorithme d'apprentissage pour modifier les paramètres afin de maximiser

52
00:05:17,400 --> 00:05:23,210
cette mesure du succès. Nous la nommerons "fonction de perte", donc la

53
00:05:23,210 --> 00:05:31,460
fonction de perte prendra un exemple (x,y) et un modèle, un prédicteur, et elle

54
00:05:31,460 --> 00:05:39,490
me renverra une valeur positive appelée la perte. Ici je donne une

55
00:05:39,490 --> 00:05:46,580
image d'un chat avec l'étiquette 'chat'. J'ai mon modèle, si le modèle prend l'image d'un chat

56
00:05:46,580 --> 00:05:51,900
et dit que c'est un chat, c'est donc la vraie étiquette: il n'y a aucune perte.

57
00:05:51,900 --> 00:05:58,310
S'il me prédit un autre concept différent de la vraie étiquette y,

58
00:05:58,310 --> 00:06:02,870
alors il y aura une erreur de 1. Cette fonction de perte s'appelle la perte 0/1, c'est

59
00:06:02,870 --> 00:06:08,690
la plus simple. Si vous faites une régression, alors les y sont des valeurs

60
00:06:08,690 --> 00:06:16,070
numériques entre moins l'infini et l'infini. Je donnerai l'entrée à mon modèle h,

61
00:06:16,070 --> 00:06:22,350
disons que le y ici, c'est la température en Celsius et

62
00:06:22,350 --> 00:06:27,949
le x est une image. Le modèle doit donc prédire la température à l'intérieur de l'image, et

63
00:06:27,949 --> 00:06:31,780
parce que c'est une valeur numérique, je peux calculer la différence entre les deux

64
00:06:31,780 --> 00:06:36,860
valeurs, et utiliser la puissance de deux pour avoir un nombre positif.

65
00:06:36,860 --> 00:06:41,310
Donc voilà deux pertes différentes, il y a beaucoup d'autres pertes qui peuvent être utilisées.

66
00:06:41,310 --> 00:06:49,470
La perte mesure la performance de ce modèle sur un exemple donné. Maintenant, nous avons la

67
00:06:49,470 --> 00:06:56,009
définition du risque: le risque est cette perte que je considérerai pour tout

68
00:06:56,009 --> 00:06:59,910
exemple dans l'univers. Je veux donc être robuste:

69
00:06:59,910 --> 00:07:05,389
je veux que mon modèle, quand je le prendrai et que je le mettrai en production, si je

70
00:07:05,389 --> 00:07:11,050
lui donne un exemple, je veux être sûr que le risque est faible, que cette fonction est faible.

71
00:07:11,050 --> 00:07:15,380
Cette fonction prend un modèle en entrée et il a été paramétré par la

72
00:07:15,380 --> 00:07:24,710
distribution réelle des données de mes exemples. Ici, l'espérance est

73
00:07:24,710 --> 00:07:30,979
la somme sur tous les exemples possibles dans l'univers, mais je pondérerai la perte par la

74
00:07:30,979 --> 00:07:39,889
probabilité de cet exemple. Donc, si je donne une image amusante d'un chat à mon modèle et que

75
00:07:39,889 --> 00:07:44,710
le modèle n'est pas en mesure de bien prédire car la probabilité associée à

76
00:07:44,710 --> 00:07:50,819
cet exemple est faible, alors je pondérerai cette perte avec une valeur basse, et le modèle

77
00:07:50,819 --> 00:07:55,259
ne sera pas pénalisé. Si la probabilité associée à l'exemple

78
00:07:55,259 --> 00:08:01,409
est élevée, alors je multiplierai la perte par un nombre élevé et je

79
00:08:01,409 --> 00:08:06,270
dirai: "d'accord, cet exemple est très probable, nous le verrons probablement

80
00:08:06,270 --> 00:08:13,879
en production, alors la perte ne devrait pas être élevée sur celui-ci". C'est donc une somme pondérée

81
00:08:13,879 --> 00:08:21,979
sur tous les exemples possibles et vous me direz: "comment pouvons-nous vraiment le calculer

82
00:08:21,979 --> 00:08:27,180
sur un ordinateur? Comment puis-je évaluer mon modèle sur toutes les images possibles de

83
00:08:27,180 --> 00:08:33,750
chats dans l'univers?" Bien sûr nous ne pouvons pas faire ça parce que "D" est inconnu, cette chose

84
00:08:33,750 --> 00:08:40,560
est inconnue. Par contre, ce que nous pouvons faire, c'est essayer d'estimer cette quantité.

85
00:08:40,560 --> 00:08:46,890
Nous le ferons en utilisant notre ensemble de données. Donc, entre ces deux diapositives,

86
00:08:46,890 --> 00:08:52,750
j'ai remplacé la vraie distribution de données que je ne pourrai jamais utiliser, car elle est

87
00:08:52,750 --> 00:09:01,500
trop complexe, par l'ensemble de données que j'ai sur mon ordinateur.

88
00:09:01,500 --> 00:09:05,250
je remplacerai aussi cette espérance, cette

89
00:09:05,250 --> 00:09:10,380
somme pondérée sur un nombre infini d'exemples, par la

90
00:09:10,380 --> 00:09:17,940
moyenne empirique sur juste mon ensemble de données. Alors, si j'ai un exemple se produisant cinq fois dans mon

91
00:09:17,940 --> 00:09:24,480
ensemble de données, la somme sera sur cinq ici, et j'en aurai cinq sur le nombre total

92
00:09:24,480 --> 00:09:31,930
d'exemples. C'est donc une probabilité empirique que cet exemple se produise dans

93
00:09:31,930 --> 00:09:36,260
la vie réelle. D'un point de vue statistique, j'estime donc vraiment cette

94
00:09:36,260 --> 00:09:41,970
quantité avec cette quantité. C'est quelque chose que je peux calculer et nous

95
00:09:41,970 --> 00:09:46,840
le calculerons dans les tutoriels: nous surveillerons la perte d'entraînement, ce que

96
00:09:46,840 --> 00:09:50,460
nous nommons en apprentissage automatique le "risque empirique". Nous voudrons bien

97
00:09:50,460 --> 00:09:52,190
sûr minimiser le risque empirique.

