0
00:00:15,370 --> 00:00:21,340
La première semble intéressante et une question que nous pouvons nous poser est:

1
00:00:21,340 --> 00:00:27,130
est-ce que la seule solution est d'avoir plus de données? Si je vais chercher de plus en plus de données,

2
00:00:27,130 --> 00:00:32,500
e.g. je suis Google et je récupère toutes les données de la planète, peut-être que je peux simplement utiliser

3
00:00:32,500 --> 00:00:35,480
les classificateurs de voisin le plus proche pour réaliser n'importe quelle tâche.

4
00:00:35,480 --> 00:00:39,559
Vous pouvez voir qu'en 2D,

5
00:00:39,559 --> 00:00:44,160
nous pouvons voir clairement la frontière de la distribution de données réelles

6
00:00:44,160 --> 00:00:55,410
qui correspondra à la frontière donnée par ce modèle. En fait, dans un espace de

7
00:00:55,410 --> 00:01:00,320
petite dimension, la frontière convergera vers la vraie distribution de données

8
00:01:00,320 --> 00:01:06,270
si j'ai assez de points. Mais qu'est-ce que ça signifie, avoir assez de points pour des vidéos, pour

9
00:01:06,270 --> 00:01:15,840
des images? En pratique, nous ne pouvons pas nous attendre à utiliser uniquement des millions de vidéos et

10
00:01:15,840 --> 00:01:20,940
des méthodes de voisin le plus proche pour avoir un bon classificateur, parce qu'ici, l'important

11
00:01:20,940 --> 00:01:27,140
est que je couvre tout l'espace du domaine avec suffisamment de données. Il faut donc

12
00:01:27,140 --> 00:01:32,860
couvrir l'espace d'entrée avec suffisamment de données. Ici, il est nécessaires d'avoir

13
00:01:32,860 --> 00:01:39,280
des données, mais ce n'est pas suffisant pour résoudre le problème. Pour le visualiser:

14
00:01:39,280 --> 00:01:45,340
je veux couvrir mon espace d'entrée avec suffisamment de données pour avoir

15
00:01:45,340 --> 00:01:50,890
une distance maximale entre n'importe quel nouveau point que je peux recevoir en

16
00:01:50,890 --> 00:01:56,400
production, et le point que j'ai dans mon ensemble d'entraînement. Je veux que la distance soit

17
00:01:56,400 --> 00:02:02,070
inférieure à 0,1, par exemple. La plus grande distance entre deux points doit être inférieure

18
00:02:02,070 --> 00:02:09,840
à 0,1. En une dimension, si j'ai un espace de domaine qui est un, j'aurai seulement besoin

19
00:02:09,840 --> 00:02:21,000
de dix points: si je reçois un point, le voisin le plus proche sera plus proche que 0,1.

20
00:02:21,000 --> 00:02:24,650
Si je passe à deux dimensions, j'aurai besoin de 100 points

21
00:02:24,650 --> 00:02:31,659
pour très bien couvrir l'espace de mon domaine. Si je vais à trois dimensions, j'aurai besoin de

22
00:02:31,659 --> 00:02:40,659
1000 points pour très bien couvrir l'espace du domaine. C'est ce qu'on appelle

23
00:02:40,659 --> 00:02:46,750
la malédiction de la dimension: le nombre d'exemples requis pour bien couvrir un

24
00:02:46,750 --> 00:02:53,000
espace est exponentiel dans la dimension. Ici, il y a un moins parce que l'epsilon

25
00:02:53,000 --> 00:03:02,200
est entre 0 et 1. Nous utiliserons cette formule pour l'ensemble de données le plus simple

26
00:03:02,200 --> 00:03:09,540
en vision par ordinateur appelé MNIST: c'est un ensemble de petites images. Celle-ci est

27
00:03:09,540 --> 00:03:16,069
28 pixels par 28 pixels par exemple. Ce sont juste des pixels noirs et blancs. J'ai

28
00:03:16,069 --> 00:03:23,769
donc un espace d'entrée de 784 dimensions. Si je veux couvrir uniformément l'espace d'entrée

29
00:03:23,769 --> 00:03:32,099
avec des données, j'aurai besoin d'au moins 10 puissance 784 exemples pour le couvrir.

30
00:03:32,099 --> 00:03:37,609
On ne peut même pas imaginer ce nombre dans nos têtes, c'est probablement

31
00:03:37,609 --> 00:03:44,450
plus que le nombre d'atomes dans l'univers ou quelque chose comme ça. Alors non,

32
00:03:44,450 --> 00:03:52,450
plus de données ne règlent pas le problème, mais vous pouvez aussi vous demander:

33
00:03:52,450 --> 00:04:00,109
"mais qu'est-ce que cela signifie de couvrir uniformément l'espace d'entrée de 28

34
00:04:00,109 --> 00:04:06,950
images par 28 pixels?" Si je prends juste un point aléatoire dans cet espace, sans aucune

35
00:04:06,950 --> 00:04:13,189
contrainte, la probabilité d'avoir un chiffre de MNIST est proche de zéro. Si je ne fais

36
00:04:13,189 --> 00:04:20,220
qu'échantillonner uniformément dans cet immense espace, d'avoir un échantillon qui

37
00:04:20,220 --> 00:04:26,450
à un chiffre est très improbable. J'ai donc deux choses différentes, le

38
00:04:26,450 --> 00:04:33,560
modèle de voisin le plus proche nécessite de couvrir l'ensemble de l'espace de manière uniforme, mais d'autre part,

39
00:04:33,560 --> 00:04:38,030
seule une petite partie de cet espace contient des

40
00:04:38,030 --> 00:04:43,900
données qui sont probables, et c'est ça l'hypothèse de variété qui est très

41
00:04:43,900 --> 00:04:49,460
importante dans en apprentissage automatique: nous représentons nos données dans des

42
00:04:49,460 --> 00:04:55,620
espaces de trop grande dimension: nous avons trop de degrés de

43
00:04:55,620 --> 00:05:01,199
liberté pour représenter toutes les images possibles. En fait, les données utiles à

44
00:05:01,199 --> 00:05:06,490
votre tâche ne sont qu'une toute petite partie de cet espace, mais il est super difficile de représenter

45
00:05:06,490 --> 00:05:12,150
cette petite partie dans l'espace et c'est ça une variété. Dans un espace 3D,

46
00:05:12,150 --> 00:05:17,830
une variété est une surface. Le nombre de degrés de liberté sur une surface

47
00:05:17,830 --> 00:05:22,669
où je peux me déplacer sur la surface est 2, et dans l'espace ambiant où la surface

48
00:05:22,669 --> 00:05:28,890
existe, il est 3. Ici nous avons un espace avec des centaines de dimension et probablement la

49
00:05:28,890 --> 00:05:37,280
variété de données est un espace de dimension beaucoup plus petite. Comme exemple, je peux prendre une

50
00:05:37,280 --> 00:05:43,930
photo de moi-même et cette image vit dans un espace de 2 millions de dimensions parce que j'ai

51
00:05:43,930 --> 00:05:53,949
900 x 700 fois 3 canaux RVB valeurs numériques, mais vraiment le système

52
00:05:53,949 --> 00:06:00,680
qui va générer toutes les images possibles de mon visage n'est qu'à 43 degrés de

53
00:06:00,680 --> 00:06:06,889
liberté: ce sont les muscles que je peux utiliser pour générer les différentes formes de mon

54
00:06:06,889 --> 00:06:15,560
visage. Vous pouvez voir que 43 est bien inférieur à 2 millions, donc c'est seulement

55
00:06:15,560 --> 00:06:21,470
pour vous donner l'intuition que les données vivent dans un espace de plus petite dimension, mais elles

56
00:06:21,470 --> 00:06:31,400
sont représentées dans des données de grande dimension. On peut penser à une

57
00:06:31,400 --> 00:06:39,229
classe d'hypothèses qui trouvera ces espaces de faible dimension, ces variétés et

58
00:06:39,229 --> 00:06:45,060
c'est ça l'expertise en apprentissage automatique ou profond: selon la dimension

59
00:06:45,060 --> 00:06:49,569
de vos données, vous regarderez les données, vous ferez peut-être des

60
00:06:49,569 --> 00:06:55,419
visualisations, une analyse préliminaire avec des modèles simples, puis vous verrez à un

61
00:06:55,419 --> 00:07:02,970
moment donné que vous aurez besoin de modèles avec une certaine complexité. C'est quelque chose

62
00:07:02,970 --> 00:07:08,120
que vous acquerrez avec de la pratique, avec beaucoup d'expériences, puis en lisant

63
00:07:08,120 --> 00:07:12,061
les articles scientifiques ou en lisant les blogs, mais à un moment donné, vous verrez

64
00:07:12,061 --> 00:07:17,949
probablement que si j'utilise ce type de modèle, il trouverait la variété de petite

65
00:07:17,949 --> 00:07:23,849
dimension plus facilement. C'est pourquoi vous êtes ici cette semaine, pour

66
00:07:23,849 --> 00:07:35,850
voir certains de ces modèles qui apprennent ces variétés.  Si nous voulons

67
00:07:35,850 --> 00:07:41,939
interpréter l'apprentissage profond dans ce schéma, c'est un moyen puissant et un

68
00:07:41,939 --> 00:07:48,770
facile de définir la classe d'hypothèse H. Vous verrez en utilisant TensorFlow

69
00:07:48,770 --> 00:07:56,350
ou PyTorch que vous pouvez concevoir des architectures très complexes et ces

70
00:07:56,350 --> 00:07:59,990
architectures auront des paramètres et l'espace des paramètres de ces

71
00:07:59,990 --> 00:08:05,009
modèles sera ce H, ce sera votre classe d'hypothèses. Alors dès que vous

72
00:08:05,009 --> 00:08:09,770
fixez l'architecture d'un modèle, vous pouvez penser que vous fixez la

73
00:08:09,770 --> 00:08:18,590
classe d'hypothèse ici. Il y aura aussi un optimiseur qui est un

74
00:08:18,590 --> 00:08:25,919
algorithme itératif qui démarrera à un moment donné. Il est associé à

75
00:08:25,919 --> 00:08:30,030
l'initialisation des paramètres de cette architecture. Nous allons donc initialiser les

76
00:08:30,030 --> 00:08:34,101
paramètres au hasard, nous atterrirons quelque part dans l'espace des paramètres et

77
00:08:34,101 --> 00:08:40,180
l'optimiseur se déplacera dans l'espace H pour trouver le modèle d'apprentissage profond qui

78
00:08:40,180 --> 00:08:47,639
minimisera votre risque empirique. si vous limitez comment l'optimiseur peut se

79
00:08:47,639 --> 00:08:54,570
déplacer dans l'espace H, vous faites une sorte de régularisation. Vous direz peut-être que

80
00:08:54,570 --> 00:08:59,980
cette partie de l'espace H est très complexe, il existe

81
00:08:59,980 --> 00:09:03,290
des modèles très complexes qui peuvent facilement mémoriser tout mon ensemble

82
00:09:03,290 --> 00:09:09,440
d'entraînement, alors je mettrai quelques limites pour que mon optimiseur ne puisse pas

83
00:09:09,440 --> 00:09:16,579
explorer ce type de modèle dans l'espace H. C'est ce qu'on nomme la régularisation.

