0
00:00:13,309 --> 00:00:17,340
Maintenant que nous avons regardé des schémas d'apprentissage automatique, passons aux

1
00:00:17,340 --> 00:00:20,520
schémas d'apprentissage profond. Comme je l'ai mentionné, scikit-learn est idéal pour

2
00:00:20,520 --> 00:00:24,269
l'apprentissage automatique, mais il s'est en quelque sorte arrêté là. L'apprentissage profond nécessite un

3
00:00:24,269 --> 00:00:30,449
équipement beaucoup plus spécialisé, par exemple l'utilisation efficace d'un GPU.

4
00:00:30,449 --> 00:00:34,110
Il y a aussi beaucoup plus de paramètres, donc scikit-learn a en quelque sorte dit: "nous allons nous

5
00:00:34,110 --> 00:00:37,800
concentrer sur la partie d'apprentissage automatique, vous pouvez implémenter certains réseaux de neurones

6
00:00:37,800 --> 00:00:41,340
dans scikit-learn, mais en ce qui concerne l'apprentissage profond intensif, vous

7
00:00:41,340 --> 00:00:45,989
voulez généralement aller vers les bibliothèques qui ont été construits juste pour l'apprentissage profond."

8
00:00:45,989 --> 00:00:50,579
On va donc en parler dans les prochaines diapositives.

9
00:00:50,579 --> 00:00:55,800
Commençons par en quoi consiste un bon schéma d'apprentissage profond. Il y a probablement

10
00:00:55,800 --> 00:00:59,460
beaucoup de réponses différentes à cette question, mais à mon avis, quelque chose qui

11
00:00:59,460 --> 00:01:03,809
rend un schéma d'apprentissage profond bon est qu'il est vraiment facile d'implémenter un

12
00:01:03,809 --> 00:01:08,670
réseau de neurones: vous en tant qu'utilisateur devriez pouvoir simplement importer votre bibliothèque et si vous avez

13
00:01:08,670 --> 00:01:12,210
une idée du type de modèle que vous voulez construire, il devrait y avoir très

14
00:01:12,210 --> 00:01:16,950
peu de résistance durant la construction de ce modèle. Par contre, vu que la plupart d'entre vous venez

15
00:01:16,950 --> 00:01:21,420
probablement de l'industrie dans cette salle, il devrait être facile à déployer. Si vous êtes en mesure

16
00:01:21,420 --> 00:01:24,659
d'obtenir un très bon classificateur mais avez aucune idée comment vous pouvez

17
00:01:24,659 --> 00:01:29,189
éventuellement le déployer en production, alors cela pourrait être critique pour le

18
00:01:29,189 --> 00:01:31,979
problème que vous résolvez. Il se pourrait aussi que vous devez réellement le déployer

19
00:01:31,979 --> 00:01:36,750
et le faire évoluer: vous devez être surs que votre cadre est capable de le faire.

20
00:01:36,750 --> 00:01:41,009
Beaucoup de ces cadres sont construits autour de l'idée de graphes de calcul.

21
00:01:41,009 --> 00:01:44,579
C'est un des détails que nous n'allons pas aborder maintenant, mais le point qu'il

22
00:01:44,579 --> 00:01:48,450
y a ces cadres qui optimisent vraiment toutes vos

23
00:01:48,450 --> 00:01:51,659
opérations et vous pouvez voir ici une animation vraiment chouette d'un

24
00:01:51,659 --> 00:01:55,680
graphe de calcul. Ça vient du site Web de TensorFlow:

25
00:01:55,680 --> 00:02:00,180
en gros, il décompose toutes les opérations courantes qui se produisent en apprentissage

26
00:02:00,180 --> 00:02:03,600
profond et il les optimise vraiment pour l’exécution de votre code sur des

27
00:02:03,600 --> 00:02:10,739
GPU. Ils facilitent les opérations comme la rétropropagation,

28
00:02:10,739 --> 00:02:13,980
la descente de gradient, tous vos optimiseurs:

29
00:02:13,980 --> 00:02:19,019
ils s'occupent de cela pour vous. Alors maintenant, regardons l'histoire des

30
00:02:19,019 --> 00:02:26,069
cadres d'apprentissage profond. Scikit-learn a été publié en 2007 et l'apprentissage profond

31
00:02:26,069 --> 00:02:30,390
existait en 2007, mais il n'était pas aussi important qu'aujourd'hui. C'est

32
00:02:30,390 --> 00:02:34,560
vraiment vers 2008 que nous avons eu une contribution vraiment importante qui a été créée

33
00:02:34,560 --> 00:02:39,180
au Mila et qui s'appelait Theano. Theano était un

34
00:02:39,180 --> 00:02:42,360
cadre d'apprentissage profond assez important pour la recherche en apprentissage profond. C'était une

35
00:02:42,360 --> 00:02:46,920
bibliothèque source ouverte et elle était censée aider les chercheurs à trouver

36
00:02:46,920 --> 00:02:50,640
de nouveaux modèles et à tester leurs idées rapidement. Ça a été développé par le Mila

37
00:02:50,640 --> 00:02:55,440
pendant très longtemps et ce n'est qu'en 2017 que le Mila a finalement pris la

38
00:02:55,440 --> 00:03:00,959
décision officielle d'arrêter de soutenir Theano et d'abandonner le projet.

39
00:03:00,959 --> 00:03:04,739
Ce n'est pas nécessairement une mauvaise chose: depuis, il y a eu beaucoup de

40
00:03:04,739 --> 00:03:07,260
cadres qui sont venus et nous allons parler de certains d'entre eux.

41
00:03:07,260 --> 00:03:11,459
Les gens au Mila considéraient qu'ils avait contribué autant qu'ils le pouvaient.

42
00:03:11,459 --> 00:03:14,940
À ce moment-là, certains plus gros cadres comme TensorFlow

43
00:03:14,940 --> 00:03:20,639
et Pytorch étaient soutenus par l'industrie et avaient juste de meilleures ressources pour soutenir ces

44
00:03:20,639 --> 00:03:24,690
bibliothèques et les utilisateurs qu'ils avaient. Alors, le Mila a simplement décidé qu'il était

45
00:03:24,690 --> 00:03:27,630
temps de passer à différents projets et de contribuer à la communauté

46
00:03:27,630 --> 00:03:32,220
d'une autre manière significative. Comme vous pouvez le voir, au fil des ans depuis

47
00:03:32,220 --> 00:03:36,959
2008, beaucoup de cadres d'apprentissage profond sont apparus: il y a des

48
00:03:36,959 --> 00:03:42,359
bibliothèques comme Caffe, MXNet, Pytorch, etc. On ne va pas toutes les regarder, mais

49
00:03:42,359 --> 00:03:45,989
nous allons vraiment mettre en évidence les deux plus importantes qui, à mon avis, sont

50
00:03:45,989 --> 00:03:52,380
les plus utilisés de nos jours. Ces deux sont tensorflow et Pytorch.

51
00:03:52,380 --> 00:03:56,819
Essayons encore une levez de mains: qui a entendu parler de TensorFlow? D'accord, nous avons encore

52
00:03:56,819 --> 00:04:00,870
beaucoup de gens. Que diriez-vous de Pytorch? D'accord, maintenant essayons autre chose:

53
00:04:00,870 --> 00:04:07,590
qui utilise TensorFlow régulièrement? D'accord, qui utilise Pytorch régulièrement? D'accord, pas beaucoup de gens.

54
00:04:07,590 --> 00:04:10,950
Donc la plupart d'entre vous n'utilisent pas nécessairement l'un de ces deux cadres.

55
00:04:10,950 --> 00:04:14,519
C'est une bonne journée pour en parler et trouver celui qui pourrait le mieux fonctionner

56
00:04:14,519 --> 00:04:17,039
pour vous et en fait de donne cette conférence

57
00:04:17,039 --> 00:04:20,880
depuis environ un an et je dois mettre à jour cette diapositive tout le temps parce que les

58
00:04:20,880 --> 00:04:24,810
choses changent toujours. Par exemple, Tensorflow est maintenant une v.c. (version candidate)

59
00:04:24,810 --> 00:04:29,880
officielle: il est passé de bêta à v.c. il n'y a que quelques semaines, de alpha à bêta avant ça,

60
00:04:29,880 --> 00:04:34,290
il ne cesse d'évoluer. Même Pytorch, quand j'ai donné cette conférence était à 0.4.

61
00:04:34,290 --> 00:04:38,130
L'écosystème évolue très rapidement et beaucoup de ces informations

62
00:04:38,130 --> 00:04:43,590
pourraient changer, mais parlons de l'utilisation du cadre dans des articles soumis.

63
00:04:43,590 --> 00:04:47,880
C'est généralement un bon indicateur, donc si nous regardons ICLR, la différence de

64
00:04:47,880 --> 00:04:52,770
2018 à 2019 en termes de cadres utilisés, nous sommes donc en train de comparer

65
00:04:52,770 --> 00:04:56,669
TensorFlow et Pytorch en ce moment. Vous pouvez voir que TensorFlow a été

66
00:04:56,669 --> 00:05:00,870
plutôt stable au fil des ans, beaucoup de chercheurs l'utilisent, mais Pytorch est

67
00:05:00,870 --> 00:05:06,030
vraiment où nous voyons une grande explosion de 2018 à 2019. Nous voyons qu'il y a beaucoup

68
00:05:06,030 --> 00:05:09,180
plus de gens qui l'utilisent et il y a probablement une raison.

69
00:05:09,180 --> 00:05:13,620
J'aime ces tweets d'Andrej Karpathy qui est le

70
00:05:13,620 --> 00:05:20,190
chercheur en chef de l'IA pour les voitures autonomes de Tesla. On peut en quelque sorte voir

71
00:05:20,190 --> 00:05:25,889
l'évolution de son impression des différents cadres. Celui-ci est en

72
00:05:25,889 --> 00:05:32,850
février 2017, il parle d'abord de la façon dont MATLAB est si 2012, Caffe 2013, Theano 2014.

73
00:05:32,850 --> 00:05:37,110
Puis, il est très excité à propos de TensorFlow: il dit que TensorFlow est la nouvelle

74
00:05:37,110 --> 00:05:40,500
chose la plus fantastique. Ensuite, vous regardez son tweet quelques

75
00:05:40,500 --> 00:05:44,910
mois plus tard et il a finalement essayé Pytorch et il dit: "j'utilise PyTorch

76
00:05:44,910 --> 00:05:48,870
depuis quelques mois maintenant et je ne me suis jamais mieux senti. J'ai plus d'énergie,

77
00:05:48,870 --> 00:05:52,680
ma peau est plus claire." Vous pouvez donc voir comment les réactions des gens à

78
00:05:52,680 --> 00:05:55,530
ces différents cadres changent tout le temps et c'est parce qu'ils

79
00:05:55,530 --> 00:05:59,340
évoluent en fonction de leurs utilisateurs. Puisqu'ils sont source ouverte, tout le monde peut

80
00:05:59,340 --> 00:06:04,380
contribuer et les améliorer à leur manière. Alors, comparons

81
00:06:04,380 --> 00:06:07,889
les deux et encore, même ce graphique a beaucoup changé: quand j'ai commencé à

82
00:06:07,889 --> 00:06:11,669
présenter cette exposé, il y avait beaucoup de différences notables entre les deux.

83
00:06:11,669 --> 00:06:14,610
Maintenant vous allez voir que les graphiques sont plus ou moins

84
00:06:14,610 --> 00:06:18,570
alignés et il y a probablement une raison: Pytorch apprend de TensorFlow

85
00:06:18,570 --> 00:06:21,750
tout comme TensorFlow apprend de Pytorch. Les deux sont des

86
00:06:21,750 --> 00:06:26,340
projets source ouverte et les gens en général ont tendance à aimer les mêmes choses. Regardons

87
00:06:26,340 --> 00:06:29,820
une liste de différences: d'abord, ils sont tous les deux source ouverte.

88
00:06:29,820 --> 00:06:34,169
Pytorch utilise la licence BSD tandis que TensorFlow utilise la

89
00:06:34,169 --> 00:06:39,000
licence Apache, des petits détails. Pytorch est soutenu par Facebook, c'est un

90
00:06:39,000 --> 00:06:42,030
détail important: une grande partie de leur financement vient de Facebook,

91
00:06:42,030 --> 00:06:45,780
alors que TensorFlow est soutenu par Google. Alors rappelez-vous comment j'ai dit que le Mila

92
00:06:45,780 --> 00:06:48,630
a cessé de contribuer à Theano, c'est parce que quand vous comparez

93
00:06:48,630 --> 00:06:51,960
les ressources que Facebook et Google peuvent consacrer à ces projets

94
00:06:51,960 --> 00:06:55,440
comparé au Mila, il était plus logique de prendre du recul et les laissez faire

95
00:06:55,440 --> 00:07:02,310
leurs choses. Un aspect vraiment important est le support GPU, le support CuDNN. Nous allons

96
00:07:02,310 --> 00:07:06,000
regarder ce que les GPU et TPU sont plus tard: ils sont du matériel qui permettent

97
00:07:06,000 --> 00:07:09,780
d'accélérer ces calculs et ils les soutiennent tous les deux, mais encore une fois, ce

98
00:07:09,780 --> 00:07:14,340
n'était pas toujours le cas. Pour les visualisations, ils ont donc tous les deux les

99
00:07:14,340 --> 00:07:18,060
mêmes outils de visualisation disponibles même si ce n'était pas toujours le cas, mais

100
00:07:18,060 --> 00:07:21,690
Tensorboard est un outil vraiment cool. Nous allons l'explorer un peu plus tard

101
00:07:21,690 --> 00:07:27,180
pour visualiser vos expériences au fil du temps. Le point suivant est probablement le

102
00:07:27,180 --> 00:07:31,980
le plus important à mon avis: s'ils sont "pythoniques" ou pas. Pytorch a

103
00:07:31,980 --> 00:07:37,950
été développé en tant que langage Python, donc lorsque Pytorch a été publié,

104
00:07:37,950 --> 00:07:42,120
l'idée était toujours que vous écriviez du code Python, il n'y a pas d'ambiguïté là-dedans.

105
00:07:42,120 --> 00:07:45,750
TensorFlow, pour ceux d'entre vous qui ont utilisé TensorFlow durant ses premiers jours,

106
00:07:45,750 --> 00:07:49,860
il était vraiment difficile de commencer et il y des raisons pourquoi:

107
00:07:49,860 --> 00:07:53,940
oui, les optimisations, mais surtout que le débogage était beaucoup plus difficile. Ce n'était pas

108
00:07:53,940 --> 00:07:58,170
comme votre débogage typique en Python. Alors à mon avis, c'était l'un des

109
00:07:58,170 --> 00:08:02,280
principaux points à considérer, mais depuis TensorFlow 2.0, cela a

110
00:08:02,280 --> 00:08:05,100
beaucoup changé. Ils ont appris de Pytorch, surtout ce que les

111
00:08:05,100 --> 00:08:10,620
gens aimaient du débogage. Maintenant, "eager mode" est par défaut dans TensorFlow 2.0,

112
00:08:10,620 --> 00:08:14,900
ce qui signifie que vous pouvez définir des points d'arrêt beaucoup plus facilement dans votre code.

113
00:08:14,900 --> 00:08:20,160
Ensuite, est-ce que c'est prêt pour la production: très important en industrie. Pouvez-vous passer d'une idée

114
00:08:20,160 --> 00:08:25,020
au code en production et le déployer pour vos utilisateurs de façon relativement facile et ne

115
00:08:25,020 --> 00:08:29,550
rien perdre en performance? Je dirais que TensorFlow est probablement mieux adapté à ça pour

116
00:08:29,550 --> 00:08:32,910
plusieurs raisons, mais surtout parce qu'il existe depuis plus longtemps. ils ont

117
00:08:32,910 --> 00:08:36,780
été mis à l'essai au combat, ils ont beaucoup plus d'outils disponibles. Il y a des outils comme

118
00:08:36,780 --> 00:08:40,650
TensorFlow.js qui vous permettent de coder TensorFlow directement dans le navigateur pour

119
00:08:40,650 --> 00:08:45,450
faire les calculs de réseaux de neurones nativement sur le navigateur de votre utilisateur.Il y a des

120
00:08:45,450 --> 00:08:49,680
choses comme TensorFlowlite, tf.serving qui vous permettent de configurer des API assez

121
00:08:49,680 --> 00:08:55,350
facilement et ce sont des outils vraiment puissants. Pytorch, c'est ce

122
00:08:55,350 --> 00:08:59,250
que Facebook utilise en interne. Ils utilisaient Caffe et

123
00:08:59,250 --> 00:09:02,970
ont changé vers Pytorch pour qu'ils soient également prêts pour la production, ils ont

124
00:09:02,970 --> 00:09:07,260
ce script Torch "juste à temps" que vous pouvez utiliser pour convertir

125
00:09:07,260 --> 00:09:10,170
d'un graphique dynamique à un graphique statique.

126
00:09:10,170 --> 00:09:14,190
On le reverra plus tard, mais vous avez cette chose appelée TorchScript qui vous permet

127
00:09:14,190 --> 00:09:17,790
d'entrer en production. C'est relativement nouveau, ça a été publié au cours de

128
00:09:17,790 --> 00:09:22,500
la dernière année, donc pas nécessairement testé au combat, mais il va

129
00:09:22,500 --> 00:09:27,210
certainement dans la bonne direction. Les deux ont leurs propres ensembles de

130
00:09:27,210 --> 00:09:31,500
modèles pré-entraînés, le hub Pytorch et le hub TensorFlow. Vous pouvez donc y aller

131
00:09:31,500 --> 00:09:35,310
et télécharger directement à partir de votre code Python des modèles pré-formés

132
00:09:35,310 --> 00:09:39,270
qui sont assez bien connus et que vous voudrez peut-être utiliser tout le temps. Des modèles

133
00:09:39,270 --> 00:09:44,180
comme VGG MNIST, je pense même qu'ils commencent à faire des Transformateurs.

134
00:09:44,180 --> 00:09:49,080
Vous pouvez télécharger ces modèles relativement facilement et ils sont

135
00:09:49,080 --> 00:09:52,290
déjà pré-entraînés, ce qui est vraiment bien parce que parfois l'entraînement de

136
00:09:52,290 --> 00:09:57,000
ce modèles peut prendre beaucoup de temps et de ressources. Enfin, la plus grande

137
00:09:57,000 --> 00:10:01,260
différence entre les deux, je dirais que c'est la différence dans le

138
00:10:01,260 --> 00:10:06,210
graphe de calcul. Alors Pytorch a été construit dès le départ comme un graphe de calcul dynamique,

139
00:10:06,210 --> 00:10:09,720
alors que TensorFlow a été construit comme un graphe de calcul statique. La grande

140
00:10:09,720 --> 00:10:13,380
différence ici est de savoir comment ce graphe de calcul, ce graphe que nous avons vu

141
00:10:13,380 --> 00:10:17,580
plus tôt avec les belles animations, comment ce graphique est construit. Initialement, TensorFlow

142
00:10:17,580 --> 00:10:21,150
a été construit de sorte qu'il fallait construire le graphe complet avant de pouvoir

143
00:10:21,150 --> 00:10:25,170
exécuter du code, alors que Pytorch a été construit pour que ce graphe soit construit pendant

144
00:10:25,170 --> 00:10:28,470
que votre code était en cours d'exécution. La grande différence est que si

145
00:10:28,470 --> 00:10:32,370
votre graphique se construit pendant que votre code s'exécute, vous pouvez faire des erreurs

146
00:10:32,370 --> 00:10:35,910
et votre code continuera de fonctionner jusqu'à cette erreur.

147
00:10:35,910 --> 00:10:39,360
Il devient facile de diagnostiquer cette erreur, alors que si votre graphique doit

148
00:10:39,360 --> 00:10:43,320
être compilé depuis le début, et c'est ainsi que TensorFlow a été conçu à l'origine, il peut être

149
00:10:43,320 --> 00:10:46,410
beaucoup plus difficile de trouver vos erreurs: vous devez d'abord

150
00:10:46,410 --> 00:10:49,740
construire le graphique complet, puis essayer de le parcourir. C'est donc

151
00:10:49,740 --> 00:10:53,790
beaucoup plus difficile à déboguer. La raison pour laquelle vous voudriez un graphique dynamique ou

152
00:10:53,790 --> 00:10:57,480
statique est une question de performance. TensorFlow a été construit pour la performance

153
00:10:57,480 --> 00:11:01,290
et le graphique statique est certainement plus performant que le graphique dynamique, mais

154
00:11:01,290 --> 00:11:05,070
les utilisateurs ont préféré le graphique dynamique. C'est pourquoi, à mon avis, il est

155
00:11:05,070 --> 00:11:09,059
probablement beaucoup plus commun dans la communauté des chercheurs d'utiliser

156
00:11:09,059 --> 00:11:12,119
Pytorch. Tout au long des tutoriels aujourd'hui et cette

157
00:11:12,119 --> 00:11:19,619
semaine, nous utiliserons Pytorch. Il y a donc Pytorch et TensorFlow, mais ce qui

158
00:11:19,619 --> 00:11:23,009
est vraiment bien aussi, c'est qu'il y a des API d'encapsulage qui sont

159
00:11:23,009 --> 00:11:26,789
disponibles. Vous pouvez les considérer comme des bibliothèques au-dessus des autres

160
00:11:26,789 --> 00:11:30,989
bibliothèques, ce qui vous permet de faire des abstractions, ce qui

161
00:11:30,989 --> 00:11:34,589
rend ces bibliothèques beaucoup plus faciles à utiliser.

162
00:11:34,589 --> 00:11:38,129
Au fur et à mesure que vous vous impliquerez de plus en plus en apprentissage profond,

163
00:11:38,129 --> 00:11:43,139
il y aura plusieurs tâches à faire encore et encore. Ces tâches peuvent impliquer l'écriture de boucles d'entraînement,

164
00:11:43,139 --> 00:11:49,589
l'écriture de scripts d'évaluation et beaucoup de ces scripts sont très similaires d'une expérience

165
00:11:49,589 --> 00:11:52,889
à l'autre et d'un contexte à l'autre, et il peut être facile de faire des

166
00:11:52,889 --> 00:11:57,569
erreurs dans ceux-ci. Il y a donc des bibliothèques comme Keras et des bibliothèques comme

167
00:11:57,569 --> 00:12:01,439
Pytorch lightning auxquelles j'ajoute des liens dans cette diapositive, qui vous permettent de

168
00:12:01,439 --> 00:12:06,209
parcourir ces bibliothèques et de rendre l'entraînement de modèles relativement simples

169
00:12:06,209 --> 00:12:09,869
beaucoup plus facile et beaucoup plus comme scikit-learn: vous appelez simplement une

170
00:12:09,869 --> 00:12:24,429
méthode similaire à ".fit" et tout se passe comme par magie.

