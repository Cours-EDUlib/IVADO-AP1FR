1
00:00:14,259 --> 00:00:21,539
De l'autre bord, je peux avoir plusieurs sorties et un encodeur ici

2
00:00:21,539 --> 00:00:26,039
pour mes données et la représentation qui serait donnée par mon encodeur, peut-être que c'est

3
00:00:26,039 --> 00:00:31,950
pertinent pour différentes tâches. Peut-être que cette représentation peut être utilisée pour

4
00:00:31,950 --> 00:00:39,050
prédire différentes choses en parallèle parce que toutes les tâches partagent les mêmes

5
00:00:39,050 --> 00:00:45,460
données en entrée. Cela s'appelle « apprentissage multi-tâche »: ma tâche est la

6
00:00:45,460 --> 00:00:50,329
première tâche, elle consiste à dire quel est l'objet dans l'image et la couleur de l'objet

7
00:00:50,329 --> 00:00:56,879
dans l'image, et en dernier si l’objet est dangereux ou non. Donc, on a trois tâches sur

8
00:00:56,879 --> 00:01:03,140
trois questions différentes, mais elles sont toutes sur la même image en entrée.

9
00:01:03,140 --> 00:01:09,479
J'essaierai donc d'utiliser un seul encodeur pour avoir une représentation ici et cette

10
00:01:09,479 --> 00:01:12,690
représentation sera donnée à trois décodeurs

11
00:01:12,690 --> 00:01:19,510
qui prédiront les sorties et, ce faisant, la représentation doit

12
00:01:19,510 --> 00:01:25,920
préserver toutes les caractéristiques pertinentes pour toutes les tâches ensemble, alors peut-être que les

13
00:01:25,920 --> 00:01:32,550
caractéristiques de la couleur de l'objet aideront d'une certaine manière la première tâche à

14
00:01:32,550 --> 00:01:40,070
détecter l'objet dans l'image et par l’entraînement simultané

15
00:01:40,070 --> 00:01:49,320
avec les trois tâches, j'aurai peut-être de meilleures caractéristiques qui fonctionneront bien pour

16
00:01:49,320 --> 00:01:53,800
toutes mes tâches. Si vous êtes vraiment intéressé par la première prédiction, mais que

17
00:01:53,800 --> 00:01:58,870
vous avez des informations sur deux et trois dans votre ensemble de données, nous pouvons utiliser 

18
00:01:58,870 --> 00:02:04,870
l’apprentissage multi-tâches pour entraîner votre modèle à réaliser trois tâches en parallèle. Vous

19
00:02:04,870 --> 00:02:13,280
pouvez regarder si cela aide la première tâche. Il y a aussi des exemples où

20
00:02:13,280 --> 00:02:16,670
deux tâches peuvent être un peu contradictoires, elles peuvent se combattre

21
00:02:16,670 --> 00:02:22,920
parce qu’elles sont très l'opposées et donc les caractéristiques ne seront

22
00:02:22,920 --> 00:02:28,680
que pour le premier ou le deuxième et cela ne peut pas très bien fonctionner dans ce cas.

23
00:02:28,680 --> 00:02:36,980
Donc, pour le multi-tâche, vous devriez l'utiliser si vous pensez que prédire trois propriétés

24
00:02:36,980 --> 00:02:43,819
du même objet vous aidera à prédire ce que vous voulez atteindre. Un autre

25
00:02:43,819 --> 00:02:47,709
modèle est l'architecture enseignant-élève et c'est lié à

26
00:02:47,709 --> 00:02:52,370
hier quand j'ai dit qu’à la première itération, vous ne devriez pas prendre en

27
00:02:52,370 --> 00:02:58,609
compte toutes les contraintes du déploiement et de l'ingénierie parce

28
00:02:58,609 --> 00:03:04,889
qu'ici, ce que nous pouvons faire, c'est prendre nos données dans la tâche et explorer toute les

29
00:03:04,889 --> 00:03:10,319
architecture possible pour trouver un bon modèle qui généralisera. Quand nous

30
00:03:10,319 --> 00:03:14,980
aurons un bon modèle qui généralisera, nous l'appellerons l'enseignant et nous n’utiliserons plus

31
00:03:14,980 --> 00:03:21,169
les étiquettes: nous allons donc créer un nouveau modèle appelé l'étudiant.

32
00:03:21,169 --> 00:03:25,459
L'étudiant répondra à toutes les exigences que vous pouvez avoir pour le

33
00:03:25,459 --> 00:03:31,719
déploiement et l'ingénierie. Très souvent, c'est un modèle beaucoup plus simple et

34
00:03:31,719 --> 00:03:36,909
au lieu d’entraîner l'étudiant sur les étiquettes de votre ensemble de données, vous

35
00:03:36,909 --> 00:03:42,459
essayerez d'imiter la sortie du modèle de l'enseignant que vous avez entraîné auparavant. 

36
00:03:42,459 --> 00:03:46,870
C’est peut être super contre-intuitif que le modèle de l'élève

37
00:03:46,870 --> 00:03:53,049
fonctionnera mieux et généralisera mieux en prédisant la sortie de l'enseignant

38
00:03:53,049 --> 00:03:59,219
au lieu d'apprendre sur les vraies étiquettes, mais il a été vérifié à plusieurs reprises dans

39
00:03:59,219 --> 00:04:04,519
la littérature que c'est le cas: il est beaucoup plus facile d’entraîner un petit modèle à partir de

40
00:04:04,519 --> 00:04:13,189
la sortie d'un modèle complexe qu’à partir des vraies étiquettes. Intuitivement, une étiquette

41
00:04:13,189 --> 00:04:20,970
n'a pas beaucoup d'informations: c'est seulement oui ou non, « Y a-t-il un chat? », zéro ou un. Le

42
00:04:20,970 --> 00:04:24,720
professeur fournira une probabilité, un nombre

43
00:04:24,720 --> 00:04:31,040
compris entre zéro et un qui peut être beaucoup plus informatif sur quels sont les

44
00:04:31,040 --> 00:04:36,190
exemples faciles et quels sont les exemples difficiles dans votre ensemble de données. Apprendre

45
00:04:36,190 --> 00:04:41,750
de la probabilité peut être beaucoup plus facile pour l'élève que d'apprendre des

46
00:04:41,750 --> 00:04:48,130
vraies étiquettes où le signal est moins puissant. C’est vraiment utilisé pour faire

47
00:04:48,130 --> 00:04:53,340
de la compression de modèle pour qu'après, vous puissiez utiliser le modèle étudiant en déploiement

48
00:04:53,340 --> 00:05:01,820
sur un téléphone portable, par exemple. Le schéma de modulation

49
00:05:01,820 --> 00:05:09,370
utilise un module pour essayer de changer la plage de votre représentation.

50
00:05:09,370 --> 00:05:13,440
Les gens en apprentissage profond ont pensé à l'apprentissage profond avec le

51
00:05:13,440 --> 00:05:19,940
principe de compositionnalité pendant de nombreuses années, mais il n’y a que dix ans qu’ils étaient en

52
00:05:19,940 --> 00:05:25,480
mesure de vraiment entraîner un réseau de neurones profond, et la difficulté

53
00:05:25,480 --> 00:05:30,380
d’entraîner un réseau de neurones profond provenait d'un problème de modulation où la

54
00:05:30,380 --> 00:05:39,630
représentation allait sur plusieurs ordres de grandeur, de - 100 à 100.

55
00:05:39,630 --> 00:05:46,560
l’entraînement avec cette gamme était super difficile à faire pour un

56
00:05:46,560 --> 00:05:54,980
réseau de neurones profond, donc quand les gens ont réalisé que c'était à cause de

57
00:05:54,980 --> 00:05:58,670
l’ordre de grandeur de la représentation, ils ont inventé des

58
00:05:58,670 --> 00:06:04,040
modules pour essayer de moduler l'amplitude de la représentation. Ainsi, dans les LSTM par

59
00:06:04,040 --> 00:06:10,540
exemple, vous verrez le mécanisme de porte qui utilisera une fonction sigmoïde

60
00:06:10,540 --> 00:06:16,280
pour savoir quelles informations conserver et quelles informations oublier afin que la

61
00:06:16,280 --> 00:06:24,340
représentation ne varie pas sur une large plage. Nous pouvons également ignorer les connexions

62
00:06:24,340 --> 00:06:28,640
où, au lieu que toute la représentation passe par toute la séquence de

63
00:06:28,640 --> 00:06:34,140
modules, nous pouvons ignorer certains modules de temps en temps afin que, si j'ai un

64
00:06:34,140 --> 00:06:36,540
bon signal depuis le début, le signal peut se

65
00:06:36,540 --> 00:06:40,560
propager plus facilement dans l'architecture juste en sautant les

66
00:06:40,560 --> 00:06:48,350
modules. On peut aussi utiliser « batch norm » qui fera quelques statistiques pour normaliser

67
00:06:48,350 --> 00:06:54,220
votre représentation. « FiLM » est une variante adaptative: il fera « batch norm »

68
00:06:54,220 --> 00:07:03,310
selon les données que vous avez en entrée. C'est une

69
00:07:03,310 --> 00:07:07,630
version adaptative de « batch norm ». Vous avez également un mécanisme d'attention que vous verrez

70
00:07:07,630 --> 00:07:14,930
jeudi, qui est une technique de modulation très puissante. Le dernier

71
00:07:14,930 --> 00:07:20,890
schéma que nous verrons est l'approche ascendante. Ici on utilise une

72
00:07:20,890 --> 00:07:28,110
certaine intuition de la tâche et on essaie de l'encoder dans l'architecture. Alors

73
00:07:28,110 --> 00:07:32,300
ici la tâche est de répondre à une question à propos de

74
00:07:32,300 --> 00:07:39,950
cette image: « une personne fait-elle du skateboard sur cette image? » C'est la

75
00:07:39,950 --> 00:07:44,430
question. Je vais prendre cette question,

76
00:07:44,430 --> 00:07:48,990
je vais l’encoder et la donner au modèle. Je vais prendre cette image, l’encoder et la

77
00:07:48,990 --> 00:07:55,580
donner au modèle. Maintenant, le modèle doit analyser cette image et la réponse à

78
00:07:55,580 --> 00:08:00,500
cette question est qu'il y a quelqu'un qui fait du skateboard dans l'image. Donc, une façon de le faire

79
00:08:00,500 --> 00:08:07,810
est peut-être de segmenter cette image en petits blocs sur une grille régulière et de la donner

80
00:08:07,810 --> 00:08:13,590
au modèle bloc par bloc en espérant que le modèle

81
00:08:13,590 --> 00:08:19,160
combinera toutes les informations de ces minuscules patchs pour trouver le skateboard de la

82
00:08:19,160 --> 00:08:26,320
personne et oublier toutes les informations autour des éléments

83
00:08:26,320 --> 00:08:32,440
d’intérêt. Cela ne fonctionnait pas très bien de cette façon parce

84
00:08:32,440 --> 00:08:37,990
qu'en tant qu'humain, si vous me posez une question sur cette image, je regarderai très

85
00:08:37,990 --> 00:08:43,029
rapidement les différents éléments qui me semblent pertinents et je concentrerai mon

86
00:08:43,029 --> 00:08:47,990
attention vraiment sur le centre de l'image ici. Ensuite,

87
00:08:47,990 --> 00:08:53,440
ce sera plus facile pour moi de répondre à la question et d'essayer d'imiter un

88
00:08:53,440 --> 00:08:59,000
peu mon processus pour répondre à la question. J'utiliserai ici un module de détection

89
00:08:59,000 --> 00:09:04,860
qui me fournira toutes les cadres de limitation des éléments d'intérêt dans

90
00:09:04,860 --> 00:09:10,080
l'image et avec toutes ces cadres de limitation, je donnerai l’image à un prédicteur.

91
00:09:10,080 --> 00:09:15,840
Il sera plus facile pour le prédicteur de trouver les informations afin de

92
00:09:15,840 --> 00:09:23,040
répondre à la question. Puisque je savais qu'il est plus facile de regarder certaines

93
00:09:23,040 --> 00:09:29,390
parties intéressantes, je le ferai apprendre d'abord quels sont les parties intéressantes dans l’image en général.

94
00:09:29,390 --> 00:09:33,880
Je vais l'utiliser comme sous module, puis je fournirai la réponse à un autre

95
00:09:33,880 --> 00:09:41,400
module qui répondra à la question liée à ces concepts. Cela

96
00:09:41,400 --> 00:09:45,880
s'appelle l'approche ascendante. L’approche descendante utilise vraiment un

97
00:09:45,880 --> 00:09:51,170
très grand modèle d'apprentissage de bout en bout où j'essaie d'apprendre à partir d'une image pour

98
00:09:51,170 --> 00:09:55,810
répondre à la question. L'approche ascendante demande: « existe-t-il un moyen de simplifier

99
00:09:55,810 --> 00:10:01,130
le travail en décomposant ma tâche en sous-tâches avec un module pour

100
00:10:01,130 --> 00:10:07,730
réaliser chacune des sous-tâches? » Alors, le message à retenir est qu’avec l’apprentissage profond,

101
00:10:07,730 --> 00:10:12,340
nous pouvons définir des classes d'hypothèses avec des graphes de calcul facilement avec ces

102
00:10:12,340 --> 00:10:17,620
modules et cet après-midi, vous créerez votre premier graphe de calcul.

103
00:10:17,620 --> 00:10:21,680
Probablement pas votre premier, j'ai entendu dire que beaucoup d'entre vous aviez déjà fait

104
00:10:21,680 --> 00:10:27,900
de l’apprentissage profond, mais ce sera le premier graphe de calcul de cette

105
00:10:27,900 --> 00:10:33,290
école d'apprentissage profond: créer un graphe pour une tâche donnée et un ensemble de données fait partie de

106
00:10:33,290 --> 00:10:38,570
l’expertise en apprentissage profond. Une architecture a souvent de nombreuses couches

107
00:10:38,570 --> 00:10:44,310
fournissant chacune une nouvelle représentation distribuée pour la suivante et

108
00:10:44,310 --> 00:10:47,310
les modules essaient de simplifier la représentation de sorte qu'au

109
00:10:47,310 --> 00:10:53,880
final, répondre à la question est très facile. Aussi, les schémas de conception

110
00:10:53,880 --> 00:10:57,510
d’architecture émergent dans la littérature; ce n'est pas quelque chose qui est

111
00:10:57,510 --> 00:11:02,820
bien documenté, je pense, mais nous pouvons clairement voir ces modèles. Vous verrez

112
00:11:02,820 --> 00:11:09,050
les schémas du mécanisme d'attention en détail jeudi et l'attention est

113
00:11:09,050 --> 00:11:14,589
l'une des techniques les plus utilisées actuellement dans le traitement du langage naturel, donc je pense

114
00:11:14,589 --> 00:11:20,150
qu'il est important d'essayer de comprendre comment créer l'intuition et comment

115
00:11:20,150 --> 00:11:27,800
créer une nouvelle architecture en fonction d'une tâche et d'un ensemble de données. Merci beaucoup.