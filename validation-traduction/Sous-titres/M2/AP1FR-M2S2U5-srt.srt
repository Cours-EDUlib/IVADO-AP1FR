1
00:00:14,040 --> 00:00:20,020
Regardons les applications de la rétropropagation. D'abord, en comprenant la rétropropagation,

2
00:00:20,020 --> 00:00:26,990
nous pouvons comprendre l'un des problèmes les plus terribles de l'apprentissage profond

3
00:00:26,990 --> 00:00:33,500
avant qu'il ne fonctionne bien. Donc ici, je n'ai que quatre couches, c'est un

4
00:00:33,500 --> 00:00:40,731
perceptron multicouche avec quatre couches. Comme vous pouvez le voir ici, c'est pour tous

5
00:00:40,731 --> 00:00:44,210
les exemples dans mon ensemble d'entraînement. Nous calculons des statistiques,

6
00:00:44,210 --> 00:00:53,520
des statistiques sur les valeurs d'activation et sur un neurone. Ici, ce que nous pouvons

7
00:00:53,520 --> 00:01:00,610
voir, c'est que dans la couche 4, la moyenne de toutes les

8
00:01:00,610 --> 00:01:04,829
valeurs de la fonction d'activation de tous les exemples est proche de zéro.

9
00:01:04,829 --> 00:01:09,290
C'est la sortie du sigmoïde qui est proche de zéro, ce qui signifie que je reçois

10
00:01:09,290 --> 00:01:15,259
des représentations très négatives, inférieures à moins six.

11
00:01:15,259 --> 00:01:20,880
Si je prends la dérivée du sigmoïde évaluée à moins six, la

12
00:01:20,880 --> 00:01:25,510
dérivée est presque nulle: cela signifie que si je change un peu l'entrée du

13
00:01:25,510 --> 00:01:31,610
sigmoïde lorsque la fonction d'activation est de moins 6, cela ne change pas

14
00:01:31,610 --> 00:01:37,430
beaucoup la sortie à cause de la non-linéarité. Donc, en

15
00:01:37,430 --> 00:01:43,670
initialisant mal mon modèle, le gradient est nul et je n'ai aucune rétroaction sur comment

16
00:01:43,670 --> 00:01:49,850
je peux changer mes paramètres pour diminuer la perte car je suis dans un mode saturé.

17
00:01:49,850 --> 00:01:55,930
Je devrais être dans cette région pour avoir un gradient non nul qui me fournira une

18
00:01:55,930 --> 00:02:02,080
direction pour améliorer le résultat. Par contre, puisque je suis ici, le gradient est nul et,

19
00:02:02,080 --> 00:02:04,150
pour calculer le gradient des

20
00:02:04,150 --> 00:02:13,610
modules précédents par rapport à ce module, les autres modules recevaient

21
00:02:13,610 --> 00:02:22,370
seulement un gradient nul. Ils n'étaient donc pas mis à jour. Donc pour 100 époques, après avoir vu

22
00:02:22,370 --> 00:02:27,760
le jeu de données 100 fois, la représentation change très

23
00:02:27,760 --> 00:02:32,340
lentement: il n'y a rien qui se passe vraiment durant l'apprentissage. En termes de

24
00:02:32,340 --> 00:02:38,109
courbe d'apprentissage,  elle sera très plate: c'est parce que le sigmoïde

25
00:02:38,109 --> 00:02:42,980
tue vraiment le signal de rétroaction à la sortie du modèle, alors la

26
00:02:42,980 --> 00:02:50,299
représentation des modules antécédents ne peut pas être modifiée

27
00:02:50,299 --> 00:02:56,379
afin de minimiser la perte. Après un certain temps, puisque ce n'est pas une rétroaction

28
00:02:56,379 --> 00:03:02,319
purement nulle, c'est un retour très très très petit, la première couche va commencer à

29
00:03:02,319 --> 00:03:06,590
changer un peu la représentation: le sigmoïde à la sortie du

30
00:03:06,590 --> 00:03:11,980
modèle recevra des valeurs qui iront de plus en plus à zéro. À ce stade,

31
00:03:11,980 --> 00:03:19,620
le signal sera supérieur à zéro et la rétropropagation fonctionnera bien.

32
00:03:19,620 --> 00:03:25,769
La façon de résoudre ce problème d'incapacité de rétropropagation du

33
00:03:25,769 --> 00:03:31,499
signal est l'initialisation de ces modules. Ainsi, lorsque vous créez un nouveau module,

34
00:03:31,499 --> 00:03:37,799
veillez à ce que le gradient qui sera calculé pour votre modèle

35
00:03:37,799 --> 00:03:42,230
ne sera pas tué, que vous n'aurez pas ce genre de problème. Choisir

36
00:03:42,230 --> 00:03:48,319
l'initialisation est quelque chose que vous devez faire si vous créez un

37
00:03:48,319 --> 00:03:56,519
nouveau module: vous ne pouvez pas laisser la bibliothèque choisir l'initialisation pour vous.

38
00:03:56,519 --> 00:04:01,129
Nous pouvons également faire quelque chose d'autre quelque chose de drôle appelé

39
00:04:01,129 --> 00:04:06,819
« exemple antagoniste ». Alors rappelez-vous dans mon exemple que je prenais le gradient de la perte par

40
00:04:06,819 --> 00:04:13,420
rapport à tous les paramètres, mais au lieu d'arrêter l'algorithme de

41
00:04:13,420 --> 00:04:19,049
rétropropagation à ce module, j'ai calculé le gradient de la perte par rapport à

42
00:04:19,049 --> 00:04:24,750
l'image: il me donnera donc les informations de comment ma perte augmentera

43
00:04:24,750 --> 00:04:29,919
ou pas si je change ce pixel. J'aurai ces informations pour tous les pixels de mon

44
00:04:29,919 --> 00:04:34,850
image et ce que certains chercheurs du

45
00:04:34,850 --> 00:04:41,070
MILA ont fait était de calculer le gradient de la perte pour un panda par rapport

46
00:04:41,070 --> 00:04:47,270
à cette image. Ils ont récupéré ce gradient avec la même forme que

47
00:04:47,270 --> 00:04:52,650
l'image qu'ils vont réduire, ils multiplieront par 0.007

48
00:04:52,650 --> 00:04:58,820
afin que nous ne voyions pas la différence en tant qu'humain. Il sont vraiment en

49
00:04:58,820 --> 00:05:06,340
train de créer du bruit pour tous les pixels de manière à ce que ces valeurs

50
00:05:06,340 --> 00:05:11,530
changent beaucoup la perte: on sait que la perte est très sensible aux

51
00:05:11,530 --> 00:05:17,000
valeurs de ces pixels, car ça a été calculé avec la rétropropagation.

52
00:05:17,000 --> 00:05:23,510
Je vais donc combiner ces deux, je vais obtenir cette image qui pour nous est

53
00:05:23,510 --> 00:05:29,680
la même. Ici, j'avais une certitude de 57,7% que c'était un

54
00:05:29,680 --> 00:05:34,900
panda, c'est la prédiction de mon modèle. Par contre, en ajoutant ce bruit qui a été très

55
00:05:34,900 --> 00:05:41,100
bien conçu par la rétropropagation, si je donne cette

56
00:05:41,100 --> 00:05:45,000
image au modèle, il prédit maintenant avec une confiance de 99,3%

57
00:05:45,000 --> 00:05:51,560
qu'il s'agit d'un gibbon, et un gibbon est un singe comme celui-ci. La rétropropagation

58
00:05:51,560 --> 00:05:58,520
peut donc être utilisée pour trouver les pixels où le modèle est très

59
00:05:58,520 --> 00:06:04,320
sensible: si je change ces pixels dans l'image, la perte changera beaucoup.

60
00:06:04,320 --> 00:06:10,070
Au lieu de cacher le bruit dans l'image, ce que je peux faire est simplement de complètement

61
00:06:10,070 --> 00:06:15,840
modifier l'image: ce qu'ils ont fait ici, c'est prendre un neurone très proche de

62
00:06:15,840 --> 00:06:21,870
la sortie du modèle, près de la sortie « chien », et ils calculaient le

63
00:06:21,870 --> 00:06:27,460
gradient par rapport à l'image. Alors, tous ces pixels, la façon dont je

64
00:06:27,460 --> 00:06:33,580
modifierai l'image maximisera la probabilité d'avoir un chien dans l'image.

65
00:06:33,580 --> 00:06:39,440
Ça se fait de manière itérative: j'ai d'abord pris une image, je fais une propagation avant,

66
00:06:39,440 --> 00:06:43,530
je choisis le neurone associé à la probabilité d'un chien, je fais

67
00:06:43,530 --> 00:06:49,310
l'algorithme de rétropropagation, je récupère un gradient dans l'espace des images, je change mon

68
00:06:49,310 --> 00:06:55,460
image et je le fais plusieurs fois. Je vais donc me déplacer dans l'espace des images et je vais trouver

69
00:06:55,460 --> 00:07:00,680
une image qui maximisera la probabilité d'un chien. Celle-ci n'est

70
00:07:00,680 --> 00:07:06,880
clairement pas une image d'un chien, mais d'une certaine manière, puisque j'utilise des modules qui

71
00:07:06,880 --> 00:07:12,490
ont des propriétés comme l'invariance aux translations et 'invariance à l'échelle, c'est

72
00:07:12,490 --> 00:07:16,240
ce qui va vraiment maximiser la probabilité de ce neurone,

73
00:07:16,240 --> 00:07:22,160
l'activation de ce neurone. C'est quelque chose qui est très fascinant:

74
00:07:22,160 --> 00:07:28,030
nous ne comprenons pas pourquoi nous avons ces structures dans cette image qui

75
00:07:28,030 --> 00:07:32,970
maximisent l'activation de ce neurone. Pour ce faire, nous utilisons la

76
00:07:32,970 --> 00:07:38,360
rétropropagation pour naviguer dans l'espace image. Les gens utilisent également la

77
00:07:38,360 --> 00:07:48,740
rétropropagation pour calculer la cartographie des caractéristiques saillantes pour retrouver les pixels

78
00:07:48,740 --> 00:07:51,230
auxquels la perte est la plus sensible.

79
00:07:51,230 --> 00:07:57,650
Ils ont effectué un post-traitement sur les informations du

80
00:07:57,650 --> 00:08:03,500
gradient de l'image en pixels pour segmenter et récupérer un

81
00:08:03,500 --> 00:08:10,450
objet dans cette image. Par la suite, si je veux prédire

82
00:08:10,450 --> 00:08:17,360
s'il y a un chien ou non, j'utilise cette technique

83
00:08:17,360 --> 00:08:22,261
et la technique me renvoie cette image où je ne peux voir que le chien, ce qui

84
00:08:22,261 --> 00:08:27,010
signifie que les pixels où le modèle est sensible à la

85
00:08:27,010 --> 00:08:32,419
prédiction sont les pixels associés au chien. Maintenant, j'ai un peu

86
00:08:32,419 --> 00:08:37,490
plus d'interprétation sur les caractéristiques de l'image qui sont utilisées pour

87
00:08:37,490 --> 00:08:42,550
prédire ma sortie. Je ne regarde pas à l'intérieur du modèle: en raison de la

88
00:08:42,550 --> 00:08:46,870
représentation distribuée, c'est difficile à d'interpréter. J'utilise la rétropropagation

89
00:08:46,870 --> 00:08:54,920
pour trouver les pixels pour lesquels la perte est la plus sensible.

90
00:08:54,920 --> 00:08:59,240
Il existe maintenant de nombreuses techniques différentes pour calculer la cartographie des caractéristiques saillantes,

91
00:08:59,240 --> 00:09:03,610
mais il faudra encore beaucoup de recherches pour comprendre: il y a environ huit

92
00:09:03,610 --> 00:09:07,959
techniques différentes qui sont très populaires et il y a beaucoup de recherches

93
00:09:07,959 --> 00:09:13,199
pour voir si c'est vraiment la bonne chose à faire pour interpréter si le modèle fait

94
00:09:13,199 --> 00:09:17,600
la bonne chose ou non. Maintenant pour certaines techniques utilisant la rétropropagation

95
00:09:17,600 --> 00:09:23,759
pour calculer la cartographie des caractéristiques saillantes, on peut voir qu'elles n'offrent pas

96
00:09:23,759 --> 00:09:29,550
d'interprétation. Nous avons besoin de plus de travail pour comprendre vraiment bien quelles

97
00:09:29,550 --> 00:09:36,680
sont les caractéristiques utilisées par le modèle. Alors, le message à retenir est que

98
00:09:36,680 --> 00:09:40,959
nous pouvons utiliser l'approximation linéaire d'une fonction représentée par un

99
00:09:40,959 --> 00:09:45,050
graphe de calcul, nous savons que l'approximation linéaire nous donnera

100
00:09:45,050 --> 00:09:49,589
l'information de la façon dont la sortie se déplacera si je déplace un paramètre, et que nous pouvons le faire

101
00:09:49,589 --> 00:09:56,939
sur la structure de graphe. La rétropropagation est un moyen efficace d'implémenter

102
00:09:56,939 --> 00:10:04,220
le calcul de cette approximation linéaire et cela fonctionne avec une propagation avant et une

103
00:10:04,220 --> 00:10:09,089
propagation arrière sur le graphe de calcul. Si vous voulez aller plus dans les détails,

104
00:10:09,089 --> 00:10:18,199
plus dans les maths, je vous recommande de lire ces liens. C'est tout, merci beaucoup.
