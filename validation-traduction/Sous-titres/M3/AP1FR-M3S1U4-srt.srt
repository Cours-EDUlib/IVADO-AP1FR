0
00:00:01,070 --> 00:00:12,339
[Musique]

1
00:00:13,299 --> 00:00:17,539
D'accord alors maintenant que nous avons vu les

2
00:00:15,590 --> 00:00:19,880
blocs de construction , regardons quelques-unes des

3
00:00:17,539 --> 00:00:22,220
motivations derrière les

4
00:00:19,880 --> 00:00:24,980
réseaux de neurones convolutifs (RNC). Pourquoi les utilisons-nous pourquoi sont-

5
00:00:22,220 --> 00:00:28,880
ils si utiles et pourquoi fonctionnent-ils si bien?

6
00:00:24,980 --> 00:00:30,980
Donc ce qui est vraiment utile des

7
00:00:28,880 --> 00:00:34,220
RNC est qu'ils peuvent apprendre des

8
00:00:30,980 --> 00:00:38,120
caractéristiques utiles à partir d'images automatiquement

9
00:00:34,220 --> 00:00:39,320
afin que nous

10
00:00:38,120 --> 00:00:41,059
n'ayons pas à dire au

11
00:00:39,320 --> 00:00:44,600
réseau quoi apprendre, le réseau apprend

12
00:00:41,059 --> 00:00:46,820
par lui-même. Classiquement cela a été fait à la

13
00:00:44,600 --> 00:00:49,309
Main, vous auriez des gens dont le

14
00:00:46,820 --> 00:00:51,980
travail consistait à construire

15
00:00:49,309 --> 00:00:53,840
certaines caractéristiques que votre classificateur

16
00:00:51,980 --> 00:00:55,280
devrait examiner et fabriquer à la main ces

17
00:00:53,840 --> 00:00:57,469
caractéristiques. Vous pouvez imaginer à quel point

18
00:00:55,280 --> 00:00:59,030
cela est minutieux. Cela ne signifie pas

19
00:00:57,469 --> 00:01:02,420
qu'il ne fonctionne pas bien: donc par

20
00:00:59,030 --> 00:01:04,190
exemple, un filtre très populaire pour la

21
00:01:02,420 --> 00:01:07,070
détection des bords est ce qu'on appelle le

22
00:01:04,190 --> 00:01:09,860
filtre Sobel , le filtre Sobel a été construit

23
00:01:07,070 --> 00:01:12,800
pour extraire les bords des images. Ici, nous

24
00:01:09,860 --> 00:01:15,979
avons une image d'entrée, donc c'est une série de points

25
00:01:12,800 --> 00:01:18,229
noirs suivies de points blancs et ici

26
00:01:15,979 --> 00:01:20,780
nous avons un noyau qui est un filtre Sobel .

27
00:01:18,229 --> 00:01:23,030
Le filtre Sobel , ce qu'il fait, son

28
00:01:20,780 --> 00:01:24,350
but, est vraiment d'extraire les bords de

29
00:01:23,030 --> 00:01:26,810
notre image. Si vous appliquiez cette

30
00:01:24,350 --> 00:01:28,220
convolution à l'image spécifique, l'image

31
00:01:26,810 --> 00:01:31,280
résultante que vous obtiendrez est

32
00:01:28,220 --> 00:01:34,250
ce qui est montré ici à droite et

33
00:01:31,280 --> 00:01:36,259
c'est vraiment le bord qui a été extrait.

34
00:01:34,250 --> 00:01:38,479
Nous avons donc ici un bord de cette image

35
00:01:36,259 --> 00:01:41,270
en plein centre ici et nous extrayons ce bord.

36
00:01:38,479 --> 00:01:42,740
Pendant très longtemps, la

37
00:01:41,270 --> 00:01:44,479
détection des bords a été utilisée et la

38
00:01:42,740 --> 00:01:48,350
détection des bords est encore largement utilisée. C'est

39
00:01:44,479 --> 00:01:50,329
une sorte de caractéristique très utile, mais

40
00:01:48,350 --> 00:01:53,149
encore une fois nous devons travailler très soigneusement pour

41
00:01:50,329 --> 00:01:55,579
fabriquer ces caractéristiques à la main. Regardons

42
00:01:53,149 --> 00:01:58,340
un exemple, disons que nous avons une sorte

43
00:01:55,579 --> 00:02:00,829
dimage et que nous utilisons nos filtres Sobel sur

44
00:01:58,340 --> 00:02:03,560
cette image. Nous pouvons utiliser

45
00:02:00,829 --> 00:02:06,079
des filtres Sobel horizontaux et verticaux et la sortie

46
00:02:03,560 --> 00:02:08,720
que nous obtenons est cette carte de bords de notre

47
00:02:06,079 --> 00:02:10,100
Fonction caractéristique. Sur la base de cela, nous pouvons

48
00:02:08,720 --> 00:02:12,530
alors essayer d'extraire de plus en plus de

49
00:02:10,100 --> 00:02:16,310
caractéristiques pour essayer de comprendre ce qui est dans

50
00:02:12,530 --> 00:02:18,889
notre image, mais cela peut être très difficile et

51
00:02:16,310 --> 00:02:20,419
cela prend beaucoup de temps pour proposer

52
00:02:18,889 --> 00:02:22,970
ces fonctionnalités. Vous pouvez imaginer que si

53
00:02:20,419 --> 00:02:24,780
c'est votre travail, vous pourriez faire un très

54
00:02:22,970 --> 00:02:27,090
bon travail sur un ensemble de données spécifique

55
00:02:24,780 --> 00:02:28,560
et le jour où le patron entre et

56
00:02:27,090 --> 00:02:30,660
dit que nous devons désormais classer

57
00:02:28,560 --> 00:02:32,100
certains différents types d'images, tout d'un

58
00:02:30,660 --> 00:02:36,030
coup, vous devez commencer ce travail acharné à

59
00:02:32,100 --> 00:02:39,690
partir de zéro. Lorsque nous appliquons des

60
00:02:36,030 --> 00:02:41,520
convolutions aux images, nous pouvons extraire

61
00:02:39,690 --> 00:02:43,200
des caractéristiques de haut niveau, mais encore une fois,

62
00:02:41,520 --> 00:02:45,030
cela peut être très difficile et

63
00:02:43,200 --> 00:02:47,370
limitant, en particulier en termes de

64
00:02:45,030 --> 00:02:49,380
Ressources. Ce qui est vraiment intéressant,

65
00:02:47,370 --> 00:02:51,180
c'est qu'en utilisant les

66
00:02:49,380 --> 00:02:53,880
réseaux de neurones convolutifs, non seulement nous pouvons extraire des

67
00:02:51,180 --> 00:02:55,709
caractéristiques de haut niveau directement à partir de

68
00:02:53,880 --> 00:02:58,350
l'image, mais nous pouvons également extraire des

69
00:02:55,709 --> 00:03:00,269
caractéristiques à des couches ultérieures de notre image.

70
00:02:58,350 --> 00:03:02,550
Nous extrayons des caractéristiques à partir de caractéristiques.

71
00:03:00,269 --> 00:03:04,050
Maintenant, vous pouvez imaginer que si vous essayez

72
00:03:02,550 --> 00:03:05,970
d'extraire des caractéristiques à partir de caractéristiques, il

73
00:03:04,050 --> 00:03:08,580
pourrait être vraiment très difficile pour quelqu'un

74
00:03:05,970 --> 00:03:10,650
de trouver certains

75
00:03:08,580 --> 00:03:12,569
bons filtres pour ça. Le réseau est

76
00:03:10,650 --> 00:03:15,090
capable de les apprendre automatiquement. Alors

77
00:03:12,569 --> 00:03:17,250
voici un bon exemple: ce sont quelques-uns

78
00:03:15,090 --> 00:03:18,540
des filtres appris par AlexNet qui

79
00:03:17,250 --> 00:03:21,000
est une architecture que nous allons examiner.

80
00:03:18,540 --> 00:03:23,280
Donc AlexNet a été entraîné sur un tas

81
00:03:21,000 --> 00:03:25,860
dimages de chats, de chiens et toutes sortes de

82
00:03:23,280 --> 00:03:28,080
catégories différentes et il s'avère

83
00:03:25,860 --> 00:03:30,570
que c'est une très bonne bonne

84
00:03:28,080 --> 00:03:32,610
architecture pour classer ces objets.

85
00:03:30,570 --> 00:03:34,590
Voici les types de filtres qui

86
00:03:32,610 --> 00:03:36,780
ont été appris, nous avons donc vu que le

87
00:03:34,590 --> 00:03:38,280
filtre Sobel était capable de détecter certains bords, mais

88
00:03:36,780 --> 00:03:40,290
ici, nous voyons toutes sortes de

89
00:03:38,280 --> 00:03:42,690
caractéristiques différentes que nous pouvons apprendre et elles sont

90
00:03:40,290 --> 00:03:44,700
très compliquées. Si vous commencez à les

91
00:03:42,690 --> 00:03:46,560
regarder, vous voyez que

92
00:03:44,700 --> 00:03:47,730
certains bords sont extraits mais aussi,

93
00:03:46,560 --> 00:03:51,239
quils ont différents types de

94
00:03:47,730 --> 00:03:54,209
dégradés et cela joue aussi avec

95
00:03:51,239 --> 00:03:55,590
les couleurs des image. Si un

96
00:03:54,209 --> 00:03:57,299
humain devait trouver cela, ce serait

97
00:03:55,590 --> 00:03:59,280
vraiment difficile, mais dans ce cas, nous le mettons

98
00:03:57,299 --> 00:04:00,870
en place comme un problème d'optimisation et le

99
00:03:59,280 --> 00:04:07,040
réseau converge en quelque sorte vers cette

100
00:04:00,870 --> 00:04:08,190
meilleure solution. Une autre motivation pour les

101
00:04:07,040 --> 00:04:11,850
RNC:

102
00:04:08,190 --> 00:04:14,370
donc dans les MLP, la façon dont le problème est

103
00:04:11,850 --> 00:04:16,620
réglé est que chaque entrée contribue de

104
00:04:14,370 --> 00:04:18,479
manière égale à la sortie. Ici nous avons un

105
00:04:16,620 --> 00:04:20,280
petit aperçu de cela: nous

106
00:04:18,479 --> 00:04:22,109
avons notre carte topologique de sortie et nous voyons

107
00:04:20,280 --> 00:04:24,479
que cette entrée contribue de manière égale à

108
00:04:22,109 --> 00:04:26,460
chaque de ces sorties. Dans le

109
00:04:24,479 --> 00:04:28,590
cas des réseaux de neurones convolutifs,

110
00:04:26,460 --> 00:04:31,620
nous forçons le réseau à se

111
00:04:28,590 --> 00:04:33,690
concentrer sur les correctifs locaux, de sorte que

112
00:04:31,620 --> 00:04:35,760
cette entrée ici ne

113
00:04:33,690 --> 00:04:38,310
contribue qu'aux sorties voisines,

114
00:04:35,760 --> 00:04:40,650
pas à tout le groupe.

115
00:04:38,310 --> 00:04:42,000
Il s'avère que ce est très utile

116
00:04:40,650 --> 00:04:47,040
et que les réseaux peuvent en fait se

117
00:04:42,000 --> 00:04:49,380
généraliser bien mieux qu'avec les MLP. On a

118
00:04:47,040 --> 00:04:53,760
aussi cette idée d'un champ réceptif que

119
00:04:49,380 --> 00:04:56,130
nous avons donc vu. Vous pourriez penser

120
00:04:53,760 --> 00:04:57,660
que c'est peut-être un inconvénient lors de

121
00:04:56,130 --> 00:04:58,980
lutilisation du réseau de neurones convolutif

122
00:04:57,660 --> 00:05:01,470
parce que nous n'obtenons pas

123
00:04:58,980 --> 00:05:03,419
lentrée complète de l'image précédente, mais il

124
00:05:01,470 --> 00:05:05,220
se trouve que nous avons ce concept de

125
00:05:03,419 --> 00:05:08,340
champ réceptif et les réseaux de neurones

126
00:05:05,220 --> 00:05:10,290
convolutifs où l'entrée précédente peut

127
00:05:08,340 --> 00:05:12,450
ne contribuer qu'à certaines couches, mais

128
00:05:10,290 --> 00:05:14,340
ils contiennent de plus en plus d'informations.

129
00:05:12,450 --> 00:05:16,200
À mesure que vous vous propagez de plus en plus

130
00:05:14,340 --> 00:05:18,360
dans votre réseau, vous obtenez en réalité

131
00:05:16,200 --> 00:05:20,700
beaucoup plus de contributions

132
00:05:18,360 --> 00:05:22,440
de l'image entière. Vous vous

133
00:05:20,700 --> 00:05:24,210
concentrez donc d' abord localement, mais comme vous continuez à

134
00:05:22,440 --> 00:05:26,130
aller de plus en plus profondément dans les couches,

135
00:05:24,210 --> 00:05:27,630
vous obtenez en fait des représentations

136
00:05:26,130 --> 00:05:29,340
de partout de votre image

137
00:05:27,630 --> 00:05:31,290
et vous les combinez de

138
00:05:29,340 --> 00:05:34,200
manière non linéaire, ce qui est beaucoup plus puissant que le

139
00:05:31,290 --> 00:05:36,960
perceptron multicouche.

140
00:05:34,200 --> 00:05:39,210
Nous pouvons penser à cela ici aussi pour un

141
00:05:36,960 --> 00:05:41,580
système 2d: ici nous avons notre noyau et

142
00:05:39,210 --> 00:05:44,130
nous obtiendrons cette sortie spécifique de sorte que la

143
00:05:41,580 --> 00:05:47,340
sortie ici sur cette cellule sera

144
00:05:44,130 --> 00:05:50,280
la combinaison de ces trois cellules.

145
00:05:47,340 --> 00:05:52,169
Alors que nous continuons, ce que nous obtiendrons par

146
00:05:50,280 --> 00:05:54,150
exemple si nous ne passons en revue que cette

147
00:05:52,169 --> 00:05:56,610
zone cinq par cinq, nous nous retrouverons avec une

148
00:05:54,150 --> 00:05:58,919
zone trois par trois, mais cette zone 3 par 3 est

149
00:05:56,610 --> 00:06:01,500
composée à partir des informations de cette

150
00:05:58,919 --> 00:06:04,020
zone 5x5. Alors déjà dans une zone 3 par 3,

151
00:06:01,500 --> 00:06:07,530
nous avons les informations d'une zone 5x5.

152
00:06:04,020 --> 00:06:09,570
Si nous allons une couche plus profonde, cette

153
00:06:07,530 --> 00:06:11,729
zone 3x3 suivante aura les informations que

154
00:06:09,570 --> 00:06:13,140
la zone 5x5 précédente

155
00:06:11,729 --> 00:06:15,630
qui contient en fait les informations de la

156
00:06:13,140 --> 00:06:17,910
zone 7 x 7 précédente. Alors que vous

157
00:06:15,630 --> 00:06:20,250
approfondissez votre réseau, ce

158
00:06:17,910 --> 00:06:21,810
champ réceptif donne en fait de

159
00:06:20,250 --> 00:06:25,800
meilleures représentations à

160
00:06:21,810 --> 00:06:28,919
votre réseau. Nous avons également ce concept

161
00:06:25,800 --> 00:06:30,539
de partage de paramètres, donc les mêmes poids

162
00:06:28,919 --> 00:06:32,460
sont utilisés dans différentes zones de l'image

163
00:06:30,539 --> 00:06:35,250
et si nous y réfléchissons dans le

164
00:06:32,460 --> 00:06:37,380
contexte de la recherche d'oreilles ou dimages dans

165
00:06:35,250 --> 00:06:39,270
une image, cela est très utile. Dans le cas

166
00:06:37,380 --> 00:06:41,070
d'un MLP, vous devez apprendre à

167
00:06:39,270 --> 00:06:43,320
recherchez des oreilles et des images à chaque point

168
00:06:41,070 --> 00:06:45,479
dans votre image. Maintenant, nous utilisons les mêmes

169
00:06:43,320 --> 00:06:47,669
caractéristiques à différents endroits, nous avons donc

170
00:06:45,479 --> 00:06:50,340
notre fenêtre coulissante. Si elle détecte une

171
00:06:47,669 --> 00:06:52,110
oreille ou une bouche à un endroit de l'image,

172
00:06:50,340 --> 00:06:53,880
elle cherche la même oreille ou la même bouche

173
00:06:52,110 --> 00:06:55,830
partout et peut ensuite combiner ces

174
00:06:53,880 --> 00:06:58,140
Informations. Nous avons donc cette idée de

175
00:06:55,830 --> 00:07:00,240
partage de paramètres. Il est également vrai

176
00:06:58,140 --> 00:07:02,340
que cela nécessite beaucoup moins de

177
00:07:00,240 --> 00:07:04,530
mémoire, car encore une fois, nous avons ces

178
00:07:02,340 --> 00:07:05,909
paramètres partagés à travers

179
00:07:04,530 --> 00:07:07,710
lensemble de l'image, nous n'avons pas à apprendre les

180
00:07:05,909 --> 00:07:10,380
paramètres pour chaque point de notre image.

181
00:07:07,710 --> 00:07:12,990
On a cette idée que, encore une fois, ces noyaux

182
00:07:10,380 --> 00:07:14,729
peuvent extraire des caractéristiques similaires à plusieurs

183
00:07:12,990 --> 00:07:16,200
endroits dans une image, donc si le réseau

184
00:07:14,729 --> 00:07:18,000
comprend que la recherche d'une bouche est

185
00:07:16,200 --> 00:07:19,440
importante, il le comprendra pour

186
00:07:18,000 --> 00:07:21,560
toute l'image, il n'a pas à le comprendre

187
00:07:19,440 --> 00:07:23,490
à plusieurs endroits de l'image.

188
00:07:21,560 --> 00:07:25,409
Un autre point intéressant est que les

189
00:07:23,490 --> 00:07:27,360
convolutions sont équivariantes sous la

190
00:07:25,409 --> 00:07:28,950
translation, alors qu'est-ce que cela signifie?

191
00:07:27,360 --> 00:07:31,950
Ça signifie simplement que si vous décalez votre

192
00:07:28,950 --> 00:07:33,599
entrée dans l'espace, votre convolution sera

193
00:07:31,950 --> 00:07:35,760
également décalée. C'est donc une

194
00:07:33,599 --> 00:07:37,650
propriété très utile: si vous classifiez le chien

195
00:07:35,760 --> 00:07:39,810
et que vous le déplacez, vous voulez toujours vous

196
00:07:37,650 --> 00:07:41,190
attendre à classer ce même chien dans

197
00:07:39,810 --> 00:07:43,140
l'image. Ce n'est pas parce que le chien a été

198
00:07:41,190 --> 00:07:44,849
décalé de quelques pixels que tout

199
00:07:43,140 --> 00:07:46,620
d'un coup, vous devriez vous attendre à

200
00:07:44,849 --> 00:07:50,070
classer quelque chose de complètement différent.

201
00:07:46,620 --> 00:07:51,570
Je répète ce point encore une fois: des

202
00:07:50,070 --> 00:07:53,490
caractéristiques utiles qui ont été apprises peuvent être

203
00:07:51,570 --> 00:07:55,530
réutilisées à plusieurs étapes dans l'image.

204
00:07:53,490 --> 00:07:58,200
Pensez à cette image mentale:

205
00:07:55,530 --> 00:08:00,330
si vous étiez en mesure de détecter des lèvres ou des oreilles

206
00:07:58,200 --> 00:08:04,950
ou des yeux, alors vous pouvez les détecter à

207
00:08:00,330 --> 00:08:07,349
plusieurs points dans votre image.

208
00:08:04,950 --> 00:08:09,599
Maintenant, prenons le temps de considérer un

209
00:08:07,349 --> 00:08:11,789
exemple réel d'un RNC: celui-ci existe depuis

210
00:08:09,599 --> 00:08:14,550
très très longtemps,

211
00:08:11,789 --> 00:08:15,960
il s'appelle LeNet et vous allez

212
00:08:14,550 --> 00:08:16,380
jouer avec lui aussi dans les

213
00:08:15,960 --> 00:08:18,570
tutoriels.

214
00:08:16,380 --> 00:08:20,789
Il s'appelle LeNet parce que il a été

215
00:08:18,570 --> 00:08:22,979
conçu par Yann Lecun, Yann Lecun

216
00:08:20,789 --> 00:08:24,960
qui est très célèbre dans le

217
00:08:22,979 --> 00:08:27,659
monde de l'apprentissage profond, il est le chef

218
00:08:24,960 --> 00:08:29,460
scientifique de l' IA chez Facebook, un ancien collègue

219
00:08:27,659 --> 00:08:30,990
du professeur Bengio aussi, ils ont

220
00:08:29,460 --> 00:08:32,610
reçu le prix de Turing

221
00:08:30,990 --> 00:08:33,079
avec Geoffrey

222
00:08:32,610 --> 00:08:37,110
Hinton.

223
00:08:33,079 --> 00:08:39,659
C'était dans les années 90, donc personne

224
00:08:37,110 --> 00:08:41,339
ne travaillait vraiment trop sur

225
00:08:39,659 --> 00:08:43,349
les réseaux de neurones convolutifs dans les années 90.

226
00:08:41,339 --> 00:08:45,180
Yann Lecun et Yoshua Bengio

227
00:08:43,349 --> 00:08:47,250
y travaillaient et ils

228
00:08:45,180 --> 00:08:49,709
essayaient de classer les chiffres manuscrits

229
00:08:47,250 --> 00:08:51,959
du jeu de données MNIST.

230
00:08:49,709 --> 00:08:54,329
Ce jeu de données MNIST, vous lavez vu un peu

231
00:08:51,959 --> 00:08:56,130
plus tôt, vous avez vu un peu de ce

232
00:08:54,329 --> 00:08:57,449
jeu de données hier, nous allons le regarder un

233
00:08:56,130 --> 00:08:59,459
peu plus en profondeur,

234
00:08:57,449 --> 00:09:01,860
mais vraiment, il s'agit

235
00:08:59,459 --> 00:09:02,730
dun ensemble de chiffres manuscrits.

236
00:09:01,860 --> 00:09:04,710
Vous avez donc environ

237
00:09:02,730 --> 00:09:07,050
soixante mille chiffres manuscrits et

238
00:09:04,710 --> 00:09:08,790
leurs étiquettes associées pour que vous sachiez que cela

239
00:09:07,050 --> 00:09:10,680
serait représenté comme un zéro(0), cela

240
00:09:08,790 --> 00:09:14,160
serait représenté comme un un(1), et la

241
00:09:10,680 --> 00:09:15,750
tâche est de prendre une image en entrée, par exemple

242
00:09:14,160 --> 00:09:18,360
si limage a un deux(2), vous voulez que votre réseau

243
00:09:15,750 --> 00:09:21,780
reconnaisse qu'il y a un deux(2) dans

244
00:09:18,360 --> 00:09:23,760
limage. Encore une fois, notre

245
00:09:21,780 --> 00:09:25,470
énoncé du problème: disons que nous avons notre huit ici,

246
00:09:23,760 --> 00:09:27,180
vous voulez être en mesure de comprendre en

247
00:09:25,470 --> 00:09:29,100
quelque sorte avec un haut degré de confiance

248
00:09:27,180 --> 00:09:31,110
que vous regardez un huit dans cette

249
00:09:29,100 --> 00:09:33,030
Image. Idéalement, si vous avez entraîné

250
00:09:31,110 --> 00:09:38,100
votre réseau en conséquence, la sortie que

251
00:09:33,030 --> 00:09:40,320
vous obtenez représente un huit. Alors voici

252
00:09:38,100 --> 00:09:42,330
l'architecture

253
00:09:40,320 --> 00:09:43,860
de LeNet, essayez de

254
00:09:42,330 --> 00:09:46,560
penser à ces blocs de construction dont nous

255
00:09:43,860 --> 00:09:49,440
parlions plus tôt. Nous avons

256
00:09:46,560 --> 00:09:51,030
notre image en entrée qui est 28 par 28 et

257
00:09:49,440 --> 00:09:53,730
dans ce cas, c'est une image en niveaux de gris,

258
00:09:51,030 --> 00:09:55,530
donc il y a un seul canal dans notre entrée.

259
00:09:53,730 --> 00:09:57,720
Nous commençons d'abord avec une couche de

260
00:09:55,530 --> 00:09:58,800
Convolutions. Ici, nous avons les

261
00:09:57,720 --> 00:10:01,050
différents paramètres dont nous

262
00:09:58,800 --> 00:10:03,120
parlions, donc la taille du noyau est initialisée à

263
00:10:01,050 --> 00:10:05,880
Cinq. Essayons de linitialiser à un et le

264
00:10:03,120 --> 00:10:08,340
remplissage est initialisée sur deux, suivi

265
00:10:05,880 --> 00:10:10,560
par une opération de mise en commun maximale.

266
00:10:08,340 --> 00:10:12,360
Nous réduisons la taille de notre carte

267
00:10:10,560 --> 00:10:15,060
topologique, puis nous allons de l'avant et appliquons

268
00:10:12,360 --> 00:10:17,400
une autre couche convolutionnelle, suivie

269
00:10:15,060 --> 00:10:20,310
d'une autre couche de mise en commun maximale et de

270
00:10:17,400 --> 00:10:21,960
quelques couches entièrement connectées. Ces couches

271
00:10:20,310 --> 00:10:24,540
entièrement connectées nous permettront ensuite

272
00:10:21,960 --> 00:10:26,280
daller calculer un softmax. Nous pouvons alors

273
00:10:24,540 --> 00:10:28,830
obtenir une distribution de probabilité basée sur

274
00:10:26,280 --> 00:10:30,990
notre image et nous pouvons calculer

275
00:10:28,830 --> 00:10:33,210
lentropie croisée et propager vers larrière le

276
00:10:30,990 --> 00:10:35,370
résultat entier. Nous faisons ceci sur l'ensemble

277
00:10:33,210 --> 00:10:38,370
des images, puis nous pouvons obtenir un assez

278
00:10:35,370 --> 00:10:40,500
bon dispositif de reconnaissance optique de caractères

279
00:10:38,370 --> 00:10:43,200
Dans ce cas, nous sommes en mesure de

280
00:10:40,500 --> 00:10:45,390
classer très bien les chiffres de 0 à 9

281
00:10:43,200 --> 00:10:50,550
et c'est ce que vous allez

282
00:10:45,390 --> 00:10:52,260
construire dans le tutoriel aujourd'hui.

283
00:10:50,550 --> 00:10:54,090
Remarquez juste que ce réseau est

284
00:10:52,260 --> 00:10:56,490
composé vraiment de conv(couches convolutionnelles), c'est

285
00:10:54,090 --> 00:10:58,320
essentiellement des convolutions, des mises en commun et

286
00:10:56,490 --> 00:11:00,630
des couches entièrement connectées. Cest un

287
00:10:58,320 --> 00:11:02,520
modèle développé à la fin des années 90 et ça

288
00:11:00,630 --> 00:11:05,070
reste toujours vrai de la plupart des architectures

289
00:11:02,520 --> 00:11:06,690
aujourd'hui qui ne sont que des convolutions, des couches de

290
00:11:05,070 --> 00:11:08,070
mise en commun et entièrement connectées.

291
00:11:06,690 --> 00:11:09,360
Plus tard dans la journée, je vais vous

292
00:11:08,070 --> 00:11:10,860
présenter des architectures plus modernes

293
00:11:09,360 --> 00:11:14,570
et vous verrez comment cela est

294
00:11:10,860 --> 00:11:16,510
toujours vrai. Alors maintenant, regardons une démo,

295
00:11:14,570 --> 00:11:18,660
jaime vraiment cette

296
00:11:16,510 --> 00:11:23,800
démo, donc j'espère que la

297
00:11:18,660 --> 00:11:27,750
connexion internet est heureuse avec nous aujourd'hui, peut-être

298
00:11:23,800 --> 00:11:31,300
quelle ne le sera pas.

299
00:11:27,750 --> 00:11:32,890
Donc quelqu'un a implémenté LeNet,

300
00:11:31,300 --> 00:11:35,550
cette architecture que nous

301
00:11:32,890 --> 00:11:38,530
regardions tantôt, de telle sorte que vous pouvez la

302
00:11:35,550 --> 00:11:40,960
visualiser dans votre navigateur. Ce qui

303
00:11:38,530 --> 00:11:43,210
se passe ici est que nous dessinons un nombre, alors

304
00:11:40,960 --> 00:11:45,310
dessinons un nombre aléatoire, par

305
00:11:43,210 --> 00:11:48,160
exemple le numéro trois.

306
00:11:45,310 --> 00:11:49,510
En fait, cest plus difficile avec ce

307
00:11:48,160 --> 00:11:50,140
trackpad que je pensais,

308
00:11:49,510 --> 00:12:00,520
recommençons.

309
00:11:50,140 --> 00:12:03,160
Oh c'est dur, ce n'est pas mon trackpad

310
00:12:00,520 --> 00:12:05,200
d'ailleurs. Alors, le réseau est

311
00:12:03,160 --> 00:12:07,420
définitivement confus et je

312
00:12:05,200 --> 00:12:10,060
ne le blâme pas, ce n'est pas vraiment un beau

313
00:12:07,420 --> 00:12:11,770
chiffre, mais ce que vous pouvez voir

314
00:12:10,060 --> 00:12:13,600
ici, c'est ce qui se passe à

315
00:12:11,770 --> 00:12:15,220
létape de la classification. Nous avons notre

316
00:12:13,600 --> 00:12:16,660
entrée et nos différentes couches,

317
00:12:15,220 --> 00:12:18,340
vous pouvez donc voir ici différentes

318
00:12:16,660 --> 00:12:20,020
couches convolutives et les différentes

319
00:12:18,340 --> 00:12:21,940
sorties. Puis, nous avons notre

320
00:12:20,020 --> 00:12:24,490
étape de mise en commun ici: vous pouvez voir comment cela est

321
00:12:21,940 --> 00:12:26,050
réduit en dimensions et c'est en

322
00:12:24,490 --> 00:12:27,430
fait vraiment intéressant. Vous pouvez voir les

323
00:12:26,050 --> 00:12:28,930
différents filtres utilisés,

324
00:12:27,430 --> 00:12:30,850
vous pouvez voir sur quel point de l'image

325
00:12:28,930 --> 00:12:33,280
ils se concentrent, vous pouvez même zoomer

326
00:12:30,850 --> 00:12:35,050
et dézoomer. Vous pouvez continuer à

327
00:12:33,280 --> 00:12:37,000
traverser votre réseau jusqu'à

328
00:12:35,050 --> 00:12:38,500
vos couches entièrement connectées et votre

329
00:12:37,000 --> 00:12:40,300
prédiction qui dans ce cas est ici.

330
00:12:38,500 --> 00:12:44,830
Essayons d'en obtenir un qui fonctionne réellement,

331
00:12:40,300 --> 00:12:47,140
peut-être que j'essaierai un nombre plus facile. Il réussit

332
00:12:44,830 --> 00:12:49,510
le sept, peut-être pas la meilleure

333
00:12:47,140 --> 00:12:50,380
implémentation de MNIST mais vous avez

334
00:12:49,510 --> 00:12:53,320
lidée.

335
00:12:50,380 --> 00:12:55,150
Donc le lien est dans les diapositives, vous pouvez essayer

336
00:12:53,320 --> 00:12:56,680
cela par vous-même: essayez de

337
00:12:55,150 --> 00:12:57,040
voir si vous pouvez dessiner des nombres mieux que

338
00:12:56,680 --> 00:12:59,320
moi, je lespère.

339
00:12:57,040 --> 00:13:01,530
Espérons que ce réseau peut

340
00:12:59,320 --> 00:13:04,360
mieux détecter ces chiffres qu'il ne détecte le mien,

341
00:13:01,530 --> 00:13:05,860
mais encore une fois un outil vraiment très cool pour

342
00:13:04,360 --> 00:13:07,840
visualiser ce qui se passe avec MNIST.

343
00:13:05,860 --> 00:13:10,030
Parfois, c'est un peu

344
00:13:07,840 --> 00:13:11,440
délicat de comprendre la connexion

345
00:13:10,030 --> 00:13:14,860
entre toutes les différentes convolutions

346
00:13:11,440 --> 00:13:24,419
et les opérations qui se déroulent.

347
00:13:14,860 --> 00:13:24,419


348
00:13:27,560 --> 00:13:31,470


349
00:13:32,560 --> 00:13:38,630


350
00:13:41,170 --> 00:13:43,850



