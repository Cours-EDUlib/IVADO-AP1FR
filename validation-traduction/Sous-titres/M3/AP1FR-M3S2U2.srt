1
00:00:13,309 --> 00:00:19,470
Maintenant que nous avons survécu aux calculs, examinons quelques applications intéressantes

2
00:00:19,470 --> 00:00:23,550
des réseaux neuronaux convolutifs. J'espère que votre cerveau n'est pas trop fatigué maintenant 

3
00:00:23,550 --> 00:00:26,970
et que vous êtes encore un peu réveillés. Nous pouvons passer aux choses amusantes

4
00:00:26,970 --> 00:00:33,510
que nous pouvons faire avec les réseaux neuronaux convolutifs.

5
00:00:33,510 --> 00:00:37,350
La première tâche est la classification des images : c'est une tâche courante que l'on voit souvent

6
00:00:37,350 --> 00:00:42,870
au cours des derniers jours. Alors vous prenez une image et vous demandez ensuite

7
00:00:42,870 --> 00:00:47,760
à quelle catégorie elle appartient. Vous faites l'apprentissage sur un ensemble de catégories de

8
00:00:47,760 --> 00:00:52,140
ce que ces images peuvent représenter et vous entraînez le modèle sur de grands ensembles de données

9
00:00:52,140 --> 00:00:56,519
dans le but d’obtenir une sorte de classification. Il s'agit d'une tâche très couramment utilisée pour

10
00:00:56,519 --> 00:01:00,869
les réseaux neuronaux convolutifs, donc si vous avez un ensemble de données qui sont images

11
00:01:00,869 --> 00:01:05,339
avec certaines catégories qui y sont rattachées, il s'avère que les réseaux neuronaux convolutifs

12
00:01:05,339 --> 00:01:11,340
sont vraiment utiles pour cette tâche. Une autre chose que nous pouvons faire est la détection d'objets.

13
00:01:11,340 --> 00:01:16,110
La classification est intéressante mais elle ne nous donne pas nécessairement

14
00:01:16,110 --> 00:01:20,580
beaucoup d’informations sur la localisation de ces objets dans notre image.

15
00:01:20,580 --> 00:01:25,500
Ce que nous faisons, c'est que nous trouvons une boîte englobante qui indique où

16
00:01:25,500 --> 00:01:29,700
les objets sont localisés. Nous trouvons donc une boîte qui dit « voici notre objet » et

17
00:01:29,700 --> 00:01:33,120
nous essayons aussi de prédire ce qu'il y a dans cette boîte englobante.

18
00:01:33,120 --> 00:01:36,990
Vous pouvez imaginer que ce problème est déjà un peu plus ardu et nous allons examiner un peu plus en détail

19
00:01:36,990 --> 00:01:40,770
plus tard comment faire la détection d'objets et comment en évaluer la performance.

20
00:01:40,770 --> 00:01:46,790
La segmentation de l'image est aussi une application intéressante

21
00:01:46,790 --> 00:01:51,270
pour les réseaux neuronaux convolutifs. Dans ce cas, ce que nous faisons est que

22
00:01:51,270 --> 00:01:55,380
non seulement nous essayons de faire de la détection d'objets,

23
00:01:55,380 --> 00:01:59,850
c’est-à-dire identifier où les objets sont situés dans une image, mais dans la boîte englobante, 

24
00:01:59,850 --> 00:02:04,320
identifier quels sont les pixels associés à ces objets spécifiques. Nous avons donc ici un exemple intéressant qui utilise

25
00:02:04,320 --> 00:02:09,450
Mask R-CNN (Masque R-RNC) que nous examinerons plus tard et nous avons donc notre réseau de neurones qui prédit

26
00:02:09,450 --> 00:02:13,319
où se trouvent les voitures dans une image, où se trouvent les humains dans une image.

27
00:02:13,319 --> 00:02:17,310
Mais ce qui est vraiment bien, c'est que donné une boîte englobante, il prédit aussi les pixels qui sont

28
00:02:17,310 --> 00:02:22,020
associés à ces différentes catégories et une chose que je trouve vraiment intéressante,

29
00:02:22,020 --> 00:02:27,120
c'est que si vous regardez de près, attendons que la vidéo passe de nouveau en boucle,

30
00:02:27,120 --> 00:02:30,330
mais vous voyez ici nous avons une fenêtre et il y a en fait le reflet de la

31
00:02:30,330 --> 00:02:33,900
voiture dans la fenêtre et il détecte la voiture là-bas. Je ne sais pas si vous l'avez vu ou pas.

32
00:02:33,900 --> 00:02:37,830
Regardez de près ici dans cette fenêtre.

33
00:02:37,830 --> 00:02:41,130
Ces réseaux sont très puissants et peuvent produire

34
00:02:41,130 --> 00:02:44,250
des représentations très intéressantes. Vous pouvez imaginer à quel point cela pourrait être utile

35
00:02:44,250 --> 00:02:49,800
dans le contexte, par exemple, des voitures sans conducteur.

36
00:02:49,800 --> 00:02:53,310
Ces mêmes algorithmes peuvent aussi être utilisés en biologie. Supposons que vous êtes un biologiste

37
00:02:53,310 --> 00:02:57,360
et que vous recherchez des noyaux dans des cellules spécifiques,

38
00:02:57,360 --> 00:03:01,190
c’est un travail laborieux de tous les trouver et de les annoter.

39
00:03:01,190 --> 00:03:05,370
Il y a des moyens d’annoter automatiquement les cellules en utilisant l'apprentissage profond.

40
00:03:05,370 --> 00:03:09,480
Dans ce cas-ci, nous utilisons exactement le même algorithme que celui qui était utilisé pour détecter les personnes,

41
00:03:09,480 --> 00:03:13,440
sauf que maintenant nous l'avons entraîné sur un ensemble de données qui contient de nombreux noyaux différents et

42
00:03:13,440 --> 00:03:20,100
nous disons au réseau de chercher des noyaux dans une cellule. Il existe une autre utilisation vraiment intéressante

43
00:03:20,100 --> 00:03:24,030
pour ce genre d'applications et il y a un lien ici pour aller lire l'article

44
00:03:24,030 --> 00:03:29,519
qui a été publié récemment dans le journal Nature.

45
00:03:29,519 --> 00:03:32,870
Nous sommes au point aujourd’hui où nous commençons à avoir ces applications de l'apprentissage profond

46
00:03:32,870 --> 00:03:38,310
qui peuvent être utilisées par la plupart des gens, donc si vous êtes pathologiste, vous n'avez peut-être pas

47
00:03:38,310 --> 00:03:41,370
trop de connaissances en matière d'apprentissage profond et si vous êtes vraiment doué pour l'apprentissage profond,

48
00:03:41,370 --> 00:03:45,269
vous avez peut-être très peu de connaissances en pathologie.

49
00:03:45,269 --> 00:03:49,650
Dans la diapositive précédente, nous avons vu que c'est pratique de pouvoir annoter les noyaux.

50
00:03:49,650 --> 00:03:52,769
Mais si vous êtes pathologiste, vous devez maintenant apprendre toute une série de

51
00:03:52,769 --> 00:03:56,670
théories d'apprentissage profond et apprendre à coder juste pour être capable de faire ces choses automatiquement.

52
00:03:56,670 --> 00:03:59,010
Mais maintenant nous sommes au point où ces modèles

53
00:03:59,010 --> 00:04:02,130
deviennent assez rapides et portables là où ils peuvent réellement

54
00:04:02,130 --> 00:04:06,299
être directement intégrés dans les microscopes. Maintenant un pathologiste qui travaille peut être aidé

55
00:04:06,299 --> 00:04:09,870
par les annotations prédites par le réseau d'apprentissage profond

56
00:04:09,870 --> 00:04:14,190
et en tant qu'utilisateur, vous ne devez pas nécessairement comprendre

57
00:04:14,190 --> 00:04:18,239
toutes les mises en œuvre derrière le RNC mais vous pouvez toujours utiliser

58
00:04:18,239 --> 00:04:24,780
les représentations complètes que vous obtenez ainsi si vous avez une diapositive d'une sorte de tranche de cellule ou de tissus,

59
00:04:24,780 --> 00:04:31,080
il y a un GPU à bord qui est connecté au microscope,

60
00:04:31,080 --> 00:04:35,700
vous pourriez lire l'article pour plus de détails, et le GPU est capable de faire

61
00:04:35,700 --> 00:04:37,930
la segmentation de l'image en temps réel.

62
00:04:37,930 --> 00:04:41,680
Alors le pathologiste déplace les images sous le microscope et il peut regarder

63
00:04:41,680 --> 00:04:46,270
à travers l'oculaire et voir que le réseau prédit certaines structures.

64
00:04:46,270 --> 00:04:51,220
Il s'agit donc d'un cas d'utilisation très intéressant où l'apprentissage profond et la pathologie se rencontrent.

65
00:04:51,220 --> 00:04:59,680
Une autre application très amusante est que les RNC peuvent être utilisées pour aider les modèles à apprendre à générer des légendes. 

66
00:04:59,680 --> 00:05:05,139
Dans la prochaine section vous allez apprendre sur le traitement du langage naturel avec Mirko,

67
00:05:05,139 --> 00:05:09,729
et il vous a préparé un superbe ensemble de diapositives.

68
00:05:09,729 --> 00:05:13,570
Il se trouve que nous pouvons combiner

69
00:05:13,570 --> 00:05:17,470
les réseaux neuronaux convolutifs et les algorithmes de traitement du langage naturel

70
00:05:17,470 --> 00:05:22,150
pour ensuite trouver le moyen de générer des légendes.

71
00:05:22,150 --> 00:05:26,650
Alors ici, nous avons l’exemple d'une femme lançant un frisbee dans un parc, et cette légende était générée par notre réseau de neurones.

72
00:05:26,650 --> 00:05:31,599
Alors l'image que vous pouvez voir est effectivement une femme lançant un frisbee, 

73
00:05:31,599 --> 00:05:35,530
mais ce qui est présenté dans l'article est

74
00:05:35,530 --> 00:05:41,320
que le réseau peut apprendre à s'occuper des régions spécifiques de l'image.

75
00:05:41,320 --> 00:05:44,440
Lorsque le réseau génère le mot frisbee, vous pouvez voir que

76
00:05:44,440 --> 00:05:48,039
le réseau se concentre sur le frisbee. De nombreux travaux ont été publiés après celui-ci,

77
00:05:48,039 --> 00:05:52,240
c'est un cas d'utilisation très intéressant et encore une fois,

78
00:05:52,240 --> 00:05:55,590
elle combine à la fois les réseaux de neurones convolutifs et des techniques de de traitement du langage naturel.

79
00:05:55,590 --> 00:06:04,260
Une autre application intéressante est l'estimation de la pose humaine.

80
00:06:04,260 --> 00:06:08,530
Ici vous voyez que vous avez un réseau neuronal convolutif

81
00:06:08,530 --> 00:06:12,099
qui apprend non seulement à déterminer où se trouvent les humains dans une image,

82
00:06:12,099 --> 00:06:17,800
mais aussi à associer une sorte de bonhomme-allumettes à la personne.

83
00:06:17,800 --> 00:06:22,180
Ici vous voyez ces gens qui dansent et le modèle apprend à les associer à des modèles de bonhommes-allumettes.

84
00:06:22,180 --> 00:06:25,690
Il doit donc comprendre la relation entre un coude un bras 

85
00:06:25,690 --> 00:06:30,849
et non seulement trouver les personnes, mais aussi associer ces modèles aux personnes.

86
00:06:30,849 --> 00:06:35,470
Ici encore, je fais le lien avec différentes mises en œuvre,

87
00:06:35,470 --> 00:06:39,550
donc il existe celle-ci, aussi publiée par Facebook Research.

88
00:06:39,550 --> 00:06:44,349
En ce moment, ils utilisent un modèle humain plus dense, donc ceux-ci sont définitivement plus difficiles à entraîner

89
00:06:44,349 --> 00:06:47,680
parce qu’ils disposent de plus de données. Encore une fois, ce sont des travaux très intéressants.

90
00:06:47,680 --> 00:06:51,400
Ce modèle est capable de faire la détection en temps réel image par image.

91
00:06:51,400 --> 00:06:55,030
Je pense que si vous regardez en haut ici, il semble qu'il traite environ dix images par seconde,

92
00:06:55,030 --> 00:07:01,780
ce qui est assez impressionnant. Une autre application intéressante

93
00:07:01,780 --> 00:07:05,770
est la cartographie routière. Nous avons donc beaucoup d'images satellites et vous pouvez imaginer que

94
00:07:05,770 --> 00:07:11,530
si vous essayez de cartographier des routes, par exemple, dans Google Maps ou même Open Maps,

95
00:07:11,530 --> 00:07:15,789
d’habitude les cartes doivent généralement être annotées manuellement.

96
00:07:15,789 --> 00:07:19,570
Cela pourrait prendre beaucoup de temps et dans les pays où vous n'avez peut-être pas accès à

97
00:07:19,570 --> 00:07:24,400
de nombreuses ressources, cela pourrait être un facteur très difficile et limitatif.

98
00:07:24,400 --> 00:07:29,620
Il existe donc de plus en plus d'algorithmes qui proposent des moyens de cartographier automatiquement

99
00:07:29,620 --> 00:07:34,870
les routes en se basant sur l'imagerie satellite et, encore une fois, nous prenons l'image satellite,

100
00:07:34,870 --> 00:07:40,270
nous la faisons passer par un RNC et celui-ci prédit ces différentes lignes qui

101
00:07:40,270 --> 00:07:46,180
représenteraient en quelque sorte des routes. Ici aussi, ce que nous faisons, c'est non seulement détecter les routes,

102
00:07:46,180 --> 00:07:50,710
mais détecter aussi les formes des bâtiments. Donc à partir d'une seule image en deux dimensions,

103
00:07:50,710 --> 00:07:55,479
nous essayons de déduire la profondeur des bâtiments afin d'obtenir le paysage d'une ville

104
00:07:55,479 --> 00:07:58,810
en fonction des types de bâtiments qui s'y trouvent. Vous pouvez donc imaginer

105
00:07:58,810 --> 00:08:05,320
comment cela pourrait être utile pour des tâches comme la planification urbaine. Nous nous sommes surtout concentrés sur les images,

106
00:08:05,320 --> 00:08:10,840
mais les RNC peuvent aussi être appliqués à une grande variété d'autres types d'entrées.

107
00:08:10,840 --> 00:08:16,659
Les sons sont une catégorie très populaires. Supposons ue vous voulez classer les sons. Comment vous vous y prendriez

108
00:08:16,659 --> 00:08:22,150
Un exemple typique, qui est présent dans la littérature

109
00:08:22,150 --> 00:08:27,220
est d'utiliser une sorte de représentation par spectrogramme.

110
00:08:27,220 --> 00:08:32,110
Alors un son peut être un signal très dense à analyser. Donc ce que nous pouvons faire, c'est calculer certaines caractéristiques qui,

111
00:08:32,110 --> 00:08:35,650
dans ce cas, pourraient être considérées comme des caractéristiques artisanales

112
00:08:35,650 --> 00:08:39,729
où nous produisons une sorte de spectrogramme. Vous avez donc probablement vu

113
00:08:39,729 --> 00:08:43,839
ce genre de représentations auparavant si vous avez traité des sons et

114
00:08:43,839 --> 00:08:48,070
ce qui est pratique, c'est que nous pouvons les utiliser comme images.

115
00:08:48,070 --> 00:08:51,880
Ensuite, nous pouvons utiliser toutes les architectures que nous avons pu trouver pour les images et les utiliser

116
00:08:51,880 --> 00:08:56,830
pour d'autres types de signaux. Là encore, cela ne se limite pas au son,

117
00:08:56,830 --> 00:09:00,520
mais toute sorte de signal où vous pourriez être en mesure de faire une sorte de transformation,

118
00:09:00,520 --> 00:09:05,290
disons une transformation de Fourier, ou tout autre type de cartographie que vous pouvez faire de votre signal

119
00:09:05,290 --> 00:09:09,810
au domaine spectral.