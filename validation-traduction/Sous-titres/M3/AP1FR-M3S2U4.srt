1
00:00:13,190 --> 00:00:18,119
Alors nous avons fait un résumé des travaux sur les RAG.

2
00:00:18,119 --> 00:00:21,660
Il existe des travaux très intéressants qui peuvent être accomplis avec les RAG et beaucoup de RNC qui sont utilisés en arrière.

3
00:00:21,660 --> 00:00:27,270
Maintenant je veux parler un peu des ensembles de données de RNC,

4
00:00:27,270 --> 00:00:34,050
donc les ensembles de données typiques que nous utilisons pour les réseaux neuronaux convolutifs.

5
00:00:34,050 --> 00:00:39,150
Celui que nous avons vu à maintes reprises est l’ensemble de données MNIST.

6
00:00:39,150 --> 00:00:43,650
Dans le case de MNIST, nous avons 60 000 chiffres manuscrits, tous des images en échelle de gris, avec une résolution de 28 par 28.

7
00:00:43,650 --> 00:00:49,049
Ce sont des images relativement petites, et c'est un réseau très facile à entraîner.

8
00:00:49,049 --> 00:00:53,159
Ce que j'entends par « facile », c'est que si vous le fournissez à la plupart des architectures de nos jours,

9
00:00:53,159 --> 00:00:57,390
vous pourrez obtenir une précision satisfaisante.

10
00:00:57,390 --> 00:01:02,790
Gaétan a également mentionné qu'il a été beaucoup utilisé et

11
00:01:02,790 --> 00:01:06,060
l'ensemble d’évaluation a été tellement évalué qu’à ce stade nous faisons du surapprentissage

12
00:01:06,060 --> 00:01:10,740
sur l’ensemble d'évaluation. Dans la communauté de l’apprentissage profond,

13
00:01:10,740 --> 00:01:14,700
il est intéressant d’aller au-delà de l’ensemble de données MNIST et d’entraîner avec d'autres ensembles de données.

14
00:01:14,700 --> 00:01:20,220
Par exemple, nous avons le MNIST de la mode. Donc j'aime penser que c'est comme

15
00:01:20,220 --> 00:01:25,230
le MNIST mais plus à la mode. L'entraînement est aussi un peu plus difficile. Donc nous avons plus d’informations

16
00:01:25,230 --> 00:01:29,460
que juste les bords dans ces images. Il y a toujours 10 catégories et les images sont en échelle de gris.

17
00:01:29,460 --> 00:01:34,680
Les catégories comprennent les chaussures de sport, les chemises et les bottes, entre autres.

18
00:01:34,680 --> 00:01:38,970
J’aime cette citation des créateurs qui dit « Si le réseau ne fonctionne pas sur le MNIST, il ne fonctionnera simplement pas.

19
00:01:38,970 --> 00:01:43,350
Mais s’il fonctionne sur le MNIST, il peut faire défaut sur d'autres ensembles de données plus difficiles. »

20
00:01:43,350 --> 00:01:47,880
Alors il s'agit plutôt d'un ensemble de données de test sur lequel juste un peu plus difficile pour tester vos idées que sur le MNIST.

21
00:01:47,880 --> 00:01:57,300
CIFAR-10, c'est aussi un ensemble de données largement utilisé.

22
00:01:57,300 --> 00:02:02,729
C’est un ensemble de taille relativement petite, soit 60 000 images RVB, et à très faible résolution.

23
00:02:02,729 --> 00:02:06,930
Il peut parfois être très difficile de discerner ce qui se trouve dans ces images.

24
00:02:06,930 --> 00:02:11,489
Nous avons 10 classes de 6 000 images et vous pouvez voir les différentes classes :

25
00:02:11,489 --> 00:02:18,180
avions, automobiles, oiseaux, entre autres. Donc c'est typiquement utilisé pour les RNC

26
00:02:18,180 --> 00:02:22,500
quand nous traitons des images RVB pour essayer différents modèles de test ou des expériences de test.

27
00:02:22,500 --> 00:02:27,340
C'est semblable au MNIST, si le réseau ne fonctionne pas sur le CIFAR, 

28
00:02:27,340 --> 00:02:31,090
ça ne marchera probablement pas sur des ensembles de données à grande échelle. Bien entendu,

29
00:02:31,090 --> 00:02:34,720
ce sera un problème lorsque vous commencez à construire des modèles à grande échelle qui exigent

30
00:02:34,720 --> 00:02:40,750
des millions d'images. Après CIFAR-10, il y a CIFAR-100.

31
00:02:40,750 --> 00:02:45,520
C'est un ensemble de données de la même taille, c'est aussi 60 000 images RGB,

32
00:02:45,520 --> 00:02:50,440
mais maintenant il y a aussi sont 100 classes avec 600 images par classe. Nous avons une liste de classes différente.

33
00:02:50,440 --> 00:02:58,260
L’ensemble de données SVHN est aussi intéressant

34
00:02:58,260 --> 00:03:03,220
et il fait penser au MNIST, mais c'est certainement plus difficile. Donc dans ce cas-ci,

35
00:03:03,220 --> 00:03:07,810
nous avons plusieurs chiffres par image et pour chaque chiffre, nous avons les coordonnées

36
00:03:07,810 --> 00:03:11,800
de la boîte englobante qui entoure le chiffre. Ces images ont été tirées de Google Streetview.

37
00:03:11,800 --> 00:03:16,780
Cet ensemble de données a été publié il y a quelques années et

38
00:03:16,780 --> 00:03:22,690
nous avons ici environ 600 000 chiffres étiquetés, donc beaucoup plus de chiffres à

39
00:03:22,690 --> 00:03:27,400
entraîner sur des images en couleur. Les images ne sont pas toutes de la même échelle,

40
00:03:27,400 --> 00:03:30,549
il y a une échelle qui pourrait être un peu plus difficile à traiter pendant l’entraînement.

41
00:03:30,549 --> 00:03:34,750
Mais la résolution des images n’est pas toujours très haute

42
00:03:34,750 --> 00:03:39,430
et sur la plupart des images, les chiffres sont en quelque sorte l’élément principal de l’image.

43
00:03:39,430 --> 00:03:44,350
On pourrait le considérer comme plus facile si vous essayez

44
00:03:44,350 --> 00:03:49,840
de trouver des chiffres dans la nature pour faire de la reconnaissance optique de caractères.

45
00:03:49,840 --> 00:03:54,549
Passons à ImageNet et, à mon avis, c'est l'une des ensembles de données les plus importants.

46
00:03:54,549 --> 00:04:00,580
C’est un des ensembles de données les plus utilisés pour la classification des images et

47
00:04:00,580 --> 00:04:06,330
il a permis nombreuses découvertes importantes dans les RNC.

48
00:04:06,330 --> 00:04:10,570
En fait, je crois que sans l'ensemble de données d'ImageNet,

49
00:04:10,570 --> 00:04:13,900
nous ne serions pas dans cette salle aujourd'hui parce que de nombreuses découvertes importantes ont été faites

50
00:04:13,900 --> 00:04:17,560
qui ont réellement fait comprendre à la communauté la puissance des réseaux neuronaux convolutifs.

51
00:04:17,560 --> 00:04:23,380
ImageNet compte des milliers de catégories et des millions d’images.

52
00:04:23,380 --> 00:04:27,430
Ici, nous ne voyons que quelques exemples différents de catégories et

53
00:04:27,430 --> 00:04:31,270
ils sont très diversifiés. Évidemment, nous avons les catégories classiques de chats et de chiens,

54
00:04:31,270 --> 00:04:35,770
et il y a même des tandems et des caméléons d’Afrique, 

55
00:04:35,770 --> 00:04:40,250
tous dans le même ensemble de données. Votre réseau doit déterminer

56
00:04:40,250 --> 00:04:45,320
comment distinguer un caméléon d’un tandem.

57
00:04:45,320 --> 00:04:49,010
Donc vous pouvez imaginer que votre réseau doit avoir une certaine capacité pour pouvoir

58
00:04:49,010 --> 00:04:56,810
différencier ces classes. ImageNet comprend des images RVB

59
00:04:56,810 --> 00:05:03,830
mais la résolution des images est de 256 par 256. Il y a 3,2 millions d'images qui sont manuellement étiquetées 

60
00:05:03,830 --> 00:05:09,290
et il existe des milliers de catégories. L’histoire de la création d’ImageNet est très intéressante.

61
00:05:09,290 --> 00:05:15,290
Voici Fei Fei Li, qui est responsable d'ImageNet et

62
00:05:15,290 --> 00:05:18,950
il y a un lien ici vers l'histoire complète d'ImageNet. Je veux prendre

63
00:05:18,950 --> 00:05:23,390
du temps pour en parler car ImageNet est l'une des plus grandes contributions 

64
00:05:23,390 --> 00:05:27,710
qui a permis à l'apprentissage profond d’arriver là où il en est.

65
00:05:27,710 --> 00:05:32,000
Mais au début, personne n'a pris ImageNet au sérieux lorsque Fei Fei Li a proposé l'idée

66
00:05:32,000 --> 00:05:37,760
de la collecte de données pour ImageNet. Les gens se sont moqués d'elle en lui disant qu'il n'en était pas question,

67
00:05:37,760 --> 00:05:43,250
que ça n’allait fonctionner. Selon cette histoire, quand elle

68
00:05:43,250 --> 00:05:47,090
a demandé des subventions, elle était à l’Université de Princeton et on lui a dit son idée était une honte à Princeton,

69
00:05:47,090 --> 00:05:51,380
et que la seule raison pour laquelle sa proposition de subvention a été acceptée,

70
00:05:51,380 --> 00:05:55,790
c'était parce qu'elle était une femme.

71
00:05:55,790 --> 00:05:58,820
C'est vraiment incroyable qu’à l'époque, les gens se disaient qu’ils avaient déjà des ensembles de données

72
00:05:58,820 --> 00:06:03,110
et qu’ils n'avaient pas besoin d’ensembles de données plus grands. Mais son intuition était excellente,

73
00:06:03,110 --> 00:06:07,040
c’est que nous avions de très petits ensembles de données sur

74
00:06:07,040 --> 00:06:11,360
un petit nombre de catégories, mais nous avons besoin d'ensembles de données beaucoup plus importants pour pouvoir démontrer

75
00:06:11,360 --> 00:06:15,860
que l'apprentissage profond fonctionne. La première fois qu'ils ont fait la collecte de données pour ImageNet,

76
00:06:15,860 --> 00:06:19,790
elle n'a eu droit qu'à une séance d'affichage. Aujourd'hui, ImageNet est utilisé presque partout,

77
00:06:19,790 --> 00:06:26,510
presque tous les réseaux sont d'abord testés sur ImageNet, donc nous allons voir

78
00:06:26,510 --> 00:06:29,210
ImageNet en profondeur plus tard dans la journée et nous allons également examiner toutes les

79
00:06:29,210 --> 00:06:33,770
différentes architectures qui sont issues d'ImageNet.

80
00:06:33,770 --> 00:06:37,550
Le message à retenir est que ImageNet est un ensemble de données vraiment important et

81
00:06:37,550 --> 00:06:41,900
qu’il a révolutionné le domaine. Nous sommes passés de d’images de résolution 32 par 32

82
00:06:41,900 --> 00:06:45,080
à des millions et des millions d'images et des milliers et des milliers de catégories.

83
00:06:45,080 --> 00:06:49,830
Nous disposons maintenant d'ensembles de données sur lesquels nous pouvons entraîner

84
00:06:49,830 --> 00:06:56,940
des réseaux très profonds. Un autre ensemble de données intéressant est

85
00:06:56,940 --> 00:07:01,080
l'ensemble de données « common objects in context » (objets communs en contexte), aussi appelé l'ensemble de données COCO, qui a été publié par Microsoft.

86
00:07:01,080 --> 00:07:07,410
Celui-ci a beaucoup moins de catégories, donc ImageNet a dans les milliers de catégories,

87
00:07:07,410 --> 00:07:13,200
mais celui-ci ne compte que 91 catégories et 328 000 images.

88
00:07:13,200 --> 00:07:16,920
Ce qui est vraiment intéressant dans cet ensemble de données, c'est que les instances sont toutes

89
00:07:16,920 --> 00:07:22,830
étiquetées indépendamment. Avant la création des ensembles de données COCO,

90
00:07:22,830 --> 00:07:26,700
si vous vouliez faire la segmentation sémantique, que nous allons examiner de manière détaillée plus tard,

91
00:07:26,700 --> 00:07:31,950
si vous aviez plusieurs objets de la même classe dans une image, vous ne pouviez pas les distinguer.

92
00:07:31,950 --> 00:07:36,060
Dans le cas présent, nous avons beaucoup de moutons et votre réseau apprend

93
00:07:36,060 --> 00:07:39,870
qu'il y a beaucoup de moutons et les étiquettes indiqueraient

94
00:07:39,870 --> 00:07:43,380
qu’il y a de nombreux moutons sur cette image mais il n'était possible de distinguer les différents moutons dans l'image.

95
00:07:43,380 --> 00:07:47,040
Le réseau sait que ce pixel est un mouton, ce pixel n'est pas un mouton,

96
00:07:47,040 --> 00:07:53,010
ce pixel est un humain. L’ensemble de données COCO permet

97
00:07:53,010 --> 00:07:57,390
d’identifier chaque instance de cette image à un niveau de résolution par pixels.

98
00:07:57,390 --> 00:08:01,140
Vous avez des boîtes englobantes, mais vous avez aussi

99
00:08:01,140 --> 00:08:04,350
une résolution par pixels et vous avez ici une liste de tous ces différentes catégories.

100
00:08:04,350 --> 00:08:11,550
Ici, par exemple, pour vous montrer la richesse des détails,

101
00:08:11,550 --> 00:08:14,850
nous avons cette image ici et voici les différentes catégories dans l'image.

102
00:08:14,850 --> 00:08:18,540
Vous voyez les différentes personnes qui sont segmentées mais vous voyez aussi leurs cravates,

103
00:08:18,540 --> 00:08:23,340
ou des nœuds papillon dans ce cas, la batte de baseball, la balle de baseball que cette personne tient,

104
00:08:23,340 --> 00:08:27,780
donc vous avez des informations très riches. Encore une fois, si vous voulez

105
00:08:27,780 --> 00:08:31,710
faire de la détection d'objets dans les images, COCO est un bon point de départ.

106
00:08:31,710 --> 00:08:40,350
Il y a également un ensemble de données de détection de points clés,

107
00:08:40,350 --> 00:08:45,750
donc nous avons plus de 150 000 personnes et 1,7 million de points clés étiquetés.

108
00:08:45,750 --> 00:08:49,050
Comme nous avons vu avec les bonshommes allumettes, c'est un très bon ensemble de données

109
00:08:49,050 --> 00:08:51,690
si l'estimation de points clés vous intéresse parce que vous pouvez imaginer

110
00:08:51,690 --> 00:08:56,310
que l’entraînement d'un réseau qui apprend à reconnaître les personnes nécessite

111
00:08:56,310 --> 00:09:00,470
beaucoup de données d’entraînement.

112
00:09:01,800 --> 00:09:07,889
Je voudrais donc maintenant vous donner quelques conseils qui seront utiles pour la collecte de votre propre ensemble de données et

113
00:09:07,889 --> 00:09:12,600
même l'étiquetage de votre propre ensemble de données. L'étiquetage des ensembles de données peut être extrêmement coûteux

114
00:09:12,600 --> 00:09:17,879
car on fait généralement appel à des annotateurs humains. Par exemple, dans le cas d'ImageNet,

115
00:09:17,879 --> 00:09:23,009
ils utilisé Amazon Mechanical Turk pour l’externalisation ouverte, où tout le monde

116
00:09:23,009 --> 00:09:27,420
pouvait s'inscrire et recevoir quelques centimes à chaque fois qu'ils classaient une image.

117
00:09:27,420 --> 00:09:30,959
Vous pouvez maintenant imaginer que si vous faites cela, vous aurez toutes sortes de

118
00:09:30,959 --> 00:09:34,410
redondances parce que deux personnes peuvent être en désaccord et il faut donc

119
00:09:34,410 --> 00:09:40,019
des évaluateurs pour évaluer les mêmes images. Je recommande donc de commencer par

120
00:09:40,019 --> 00:09:44,819
la recherche d'ensembles de données similaires à la tâche que vous essayez d'accomplir.

121
00:09:44,819 --> 00:09:49,290
Il existe énormément d'ensembles de données, je n'en ai mentionné que quelques-uns

122
00:09:49,290 --> 00:09:54,239
qui sont utilisés relativement souvent dans la littérature mais il existe de nombreux ensembles de données sources ouvertes.

123
00:09:54,239 --> 00:09:58,769
Il faut donc d'abord rechercher des ensembles de données similaires et

124
00:09:58,769 --> 00:10:02,369
comprendre le type d'étiquettes dont vous avez besoin et comment vous voulez les représenter, quelle est la tâche que vous voulez faire,

125
00:10:02,369 --> 00:10:06,749
est-ce simplement la classification? Dans ce cas, l’étiquetage est relativement facile,

126
00:10:06,749 --> 00:10:11,009
car il n'y a qu'une seule étiquette. Si vous essayez de faire la détection d'objets,

127
00:10:11,009 --> 00:10:14,249
alors vous devez avoir des boîtes englobantes, alors comment allez-vous les représenter?

128
00:10:14,249 --> 00:10:17,910
Je vous recommande à nouveau de regarder comment d'autres personnes s'y sont pris et

129
00:10:17,910 --> 00:10:22,410
nous allons examiner cela plus tard.

130
00:10:22,410 --> 00:10:26,129
L'étiquetage peut être coûteux et inexact,

131
00:10:26,129 --> 00:10:30,929
donc si vous ne faites pas étiqueter vos données par des experts, si ce sont des ensembles de données

132
00:10:30,929 --> 00:10:35,670
qui portent sur les pathologies par exemple, je ne vous conseille pas d'aller en ligne et de faire de l'internalisation ouverte

133
00:10:35,670 --> 00:10:39,480
pour obtenir cette information. Il serait intéressant d’avoir des pathologistes qualifiés

134
00:10:39,480 --> 00:10:42,899
pour pouvoir identifier les structures. Il se pourrait aussi que ces pathologistes

135
00:10:42,899 --> 00:10:47,459
doivent effectuer des mesures en laboratoire pour obtenir ces résultats.

136
00:10:47,459 --> 00:10:52,139
Il existe des moyens de générer des données synthétiques,

137
00:10:52,139 --> 00:10:55,559
on peut penser à un simulateur, si vous essayez de construire une voiture sans conducteur,

138
00:10:55,559 --> 00:10:59,279
vous pouvez construire un environnement virtuel pour simuler la conduite d'une voiture

139
00:10:59,279 --> 00:11:04,290
dans lequel votre réseau neuronal peut apprendre de ce simulateur.

140
00:11:04,290 --> 00:11:07,860
Vous pouvez aussi utiliser les RAG pour générer des images. Nous avons vu que les RAG peuvent générer

141
00:11:07,860 --> 00:11:13,820
des images réalistes. Vous voulez peut-être entraîner les RAG à générer des données supplémentaires.

142
00:11:13,820 --> 00:11:18,470
Ça fonctionne pour tester des idées, mais pas pour généraliser.

143
00:11:18,470 --> 00:11:22,220
Supposons que vous faites l’apprentissage sur la base d'un environnement simulé.

144
00:11:22,220 --> 00:11:27,080
Le réseau peut repérer des indices dans le simulateur

145
00:11:27,080 --> 00:11:31,400
qui ne représentent pas nécessairement la vie réelle, alors soyez prudent lorsque

146
00:11:31,400 --> 00:11:36,170
vous utilisez des données synthétiques et assurez-vous de disposer de moyens pour valider que vos données synthétiques peuvent

147
00:11:36,170 --> 00:11:41,780
être bien traduits sur un ensemble d’évaluation bien défini. Ce qui nous mène au point suivant :

148
00:11:41,780 --> 00:11:47,150
assurez-vous d'avoir un ensemble d’évaluation robuste et bien gardé.

149
00:11:47,150 --> 00:11:53,900
Ne l’utilisez pas trop souvent, car à un moment donné, en tant qu'architecte de vos réseaux d'apprentissage profond,

150
00:11:53,900 --> 00:11:58,340
vous commencerez à faire du surapprentissage sur votre ensemble d'évaluation. Tout comme le réseau neuronal peut faire du surapprentissage

151
00:11:58,340 --> 00:12:03,800
sur votre ensemble d'entraînement, vous pouvez faire du surapprentissage sur votre ensemble d'entraînement

152
00:12:03,800 --> 00:12:07,130
parce que vous allez essayer des choses encore et encore et les évaluer lors de votre évaluation

153
00:12:07,130 --> 00:12:10,820
même si nous vous disons de ne pas le faire. Vous finirez par choisir l’architecture

154
00:12:10,820 --> 00:12:14,690
qui fonctionne le mieux sur votre ensemble d'évaluation,

155
00:12:14,690 --> 00:12:18,560
alors c'est vous qui commencez le surapprentissage de votre ensemble d'évaluation. Il est donc très important de le préserver.

156
00:12:18,560 --> 00:12:23,150
En fait, de nombreux concours en ligne ne publieront jamais l’ensemble d'évaluation,

157
00:12:23,150 --> 00:12:26,870
ils vous donnent des instructions sur la manière dont vous pouvez évaluer leur ensemble d'évaluation

158
00:12:26,870 --> 00:12:31,070
et ensuite vous recevrez peut-être deux ou trois soumissions d'évaluation et ils prendront

159
00:12:31,070 --> 00:12:36,230
le meilleur résultat en fonction de celles-ci. Le dernier point est de toujours remettre en cause la validité de vos données.

160
00:12:36,230 --> 00:12:41,480
Assurez-vous qu’elles proviennent d'une source fiable et assurez-vous qu’elles ont du sens

161
00:12:41,480 --> 00:12:44,990
lorsque vous les fournissez à votre réseau de neurones. Vous pouvez faire toutes sortes de

162
00:12:44,990 --> 00:12:49,040
transformations de vos données, il peut arriver quelque part dans le pipeline que

163
00:12:49,040 --> 00:12:54,800
vos données soient transformées d'une manière qui n'a pas de sens.

164
00:12:54,800 --> 00:12:58,220
Alors essayez de visualiser vos données autant que possible tout au long

165
00:12:58,220 --> 00:13:02,720
de votre pipeline. Voici une histoire vraiment intéressante que je vous conseille de lire,

166
00:13:02,720 --> 00:13:07,940
c’est à propos d'un des contributeurs à TensorFlow.

167
00:13:07,940 --> 00:13:11,390
Il passe en revue les détails de cette histoire d'horreur qui s'est produite où

168
00:13:11,390 --> 00:13:16,070
il a travaillé sur un modèle pendant des années et a perfectionné son modèle jusqu'à ce qu'il constate un problème,

169
00:13:16,070 --> 00:13:20,030
et c'est un peu plus compliqué que ce que je vais vous expliquer,

170
00:13:20,030 --> 00:13:24,830
mais il a dit que c'est comme si vous aviez les étiquettes dans votre nom de fichier et

171
00:13:24,830 --> 00:13:29,050
vous lisiez le nom du fichier pour construire votre algorithme de classification.

172
00:13:29,050 --> 00:13:32,530
Ça semble être une erreur banale, mais ça peut arriver très facilement et si votre réseau peut tricher,

173
00:13:32,530 --> 00:13:36,460
il trouvera un moyen de tricher. Alors remettez toujours en question

174
00:13:36,460 --> 00:13:40,720
la validité de vos données et assurez-vous toujours que vous avez des évaluations en place

175
00:13:40,720 --> 00:13:45,600
pour vous assurer que vos réseaux fonctionnent comme prévu.