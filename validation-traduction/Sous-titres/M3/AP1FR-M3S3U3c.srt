1
00:00:13,360 --> 00:00:19,099
La même année, nous avons GoogLeNet et, une fois de plus, vous pouvez voir

2
00:00:19,099 --> 00:00:23,599
que c'est vraiment comme ça qu'ils l'écrivent, donc c'est Goog-Le-Net.

3
00:00:23,599 --> 00:00:28,250
C'est encore un clin d'œil à LeNet, qui a été une source d'inspiration pour beaucoup de

4
00:00:28,250 --> 00:00:32,540
ces articles. Et ils ont publié un modèle encore plus profond avec encore moins de paramètres

5
00:00:32,540 --> 00:00:36,530
et une plus grande exactitude. C’était aussi en 2014 et ces deux modèles sont

6
00:00:36,530 --> 00:00:42,950
très important. Et les mèmes étaient toujours aussi populaires. Dans ce cas

7
00:00:42,950 --> 00:00:48,260
ils citent ce mème dans leur article. Si vous regardez les références,

8
00:00:48,260 --> 00:00:52,670
la première est le mème « nous devons aller plus en profondeur ». Ils y font référence et

9
00:00:52,670 --> 00:00:54,649
ils n'essaient pas de le cacher. Ils disent qu’ils ont donné le nom de code « Inception » à leur modèle

10
00:00:54,649 --> 00:00:59,660
basée sur ce mème. En 2014, les gens adoraient les mèmes,

11
00:00:59,660 --> 00:01:05,869
et j'ai trouvé que ce serait utile de le mentionner dans cette présentation.

12
00:01:05,869 --> 00:01:12,020
Examinons alors ce réseau. Il peut être un peu intimidant

13
00:01:12,020 --> 00:01:16,820
quand on le regarde, comme il est assez grand et il comprend plusieurs opérations :

14
00:01:16,820 --> 00:01:20,479
nous avons l'opération de convolution, et maintenant nous avons une opération de concaténation,

15
00:01:20,479 --> 00:01:25,159
qui consiste essentiellement à empiler les sorties.

16
00:01:25,159 --> 00:01:28,070
Donc c'est le concept de profondeur : si vous disposez de plusieurs carte de caractéristiques et vous les concaténez,

17
00:01:28,070 --> 00:01:32,390
vous ne faites qu'ajouter de la profondeur à votre réseau. Nous avons la mise en commun par maximum et

18
00:01:32,390 --> 00:01:36,950
nous avons cette opération softmax. Ce réseau peut sembler grand et intimidant,

19
00:01:36,950 --> 00:01:41,270
mais ce que vous remarquez en regardant de près,

20
00:01:41,270 --> 00:01:45,170
c'est que vous avez ces modules qui apparaissent et ce sont ce qu'ils appellent les

21
00:01:45,170 --> 00:01:50,899
modules de création. Gaétan a mentionné ces modules plus tôt,

22
00:01:50,899 --> 00:01:53,990
et c'est vraiment utile de pouvoir définir dans notre réseau des ensembles de modules qui peuvent être

23
00:01:53,990 --> 00:01:57,619
réutilisés. Dans ce cas, ce module apparaît à plusieurs reprises

24
00:01:57,619 --> 00:02:00,829
dans tout le réseau. En fait, si vous regardez de près, vous verrez que nous avons

25
00:02:00,829 --> 00:02:06,500
un total de neuf modules de création. Tout ça semble très compliqué,

26
00:02:06,500 --> 00:02:11,540
mais c’est le même module encore et encore qui est réutilisé. Ce qui est très intéressant, c'est que dans leur module de base,

27
00:02:11,540 --> 00:02:17,150
ils avaient des convolutions parallèles dans chaque couche.

28
00:02:17,150 --> 00:02:22,820
Alors examinons ce module un peu plus en profondeur :

29
00:02:22,820 --> 00:02:26,459
c'est de bas en haut, ce qui peut être un peu déroutant, et nous avons la couche précédente,

30
00:02:26,459 --> 00:02:30,690
notre entrée, et nous faisons ensuite en parallèle une série de différentes

31
00:02:30,690 --> 00:02:35,400
convolutions. Donc ils ajoutent ces convolutions 1 par 1 ici

32
00:02:35,400 --> 00:02:39,330
et nous avons parlé plus tôt aujourd'hui des convolutions 1 par 1.

33
00:02:39,330 --> 00:02:43,769
La motivation à concevoir les convolutions 1 par 1 était de réduire le nombre de paramètres

34
00:02:43,769 --> 00:02:47,160
dans le modèle. Nous verrons donc que ce modèle utilise en fait

35
00:02:47,160 --> 00:02:52,170
beaucoup moins de paramètres et cela était en partie à cause de la bonne décision

36
00:02:52,170 --> 00:02:55,950
de mettre les convolutions 1x1. Et ce qui est vraiment pratique,

37
00:02:55,950 --> 00:02:59,190
comme vous avez pu constater, c’est qu'ils utilisent une combinaison de 3 par 3

38
00:02:59,190 --> 00:03:04,170
et de 5 par 5 dans ce module ainsi qu’une mise en commun par maximum et

39
00:03:04,170 --> 00:03:08,190
des convolutions 1 par 1 et simplement quelques convolutions 1 par 1.

40
00:03:08,190 --> 00:03:12,599
La raison derrière cette décision était de laisser le réseau décider quelles caractéristiques

41
00:03:12,599 --> 00:03:15,959
étaient plus importantes à différents stades. Au lieu de dire qu’à un stade précis,

42
00:03:15,959 --> 00:03:20,430
vous utilisez seulement un filtrage 3 par 3 ou seulement un filtrage 5 par 5,

43
00:03:20,430 --> 00:03:23,790
ils voulaient laisser au réseau la possibilité de tous les choisir et de les combiner avec

44
00:03:23,790 --> 00:03:28,459
cette concaténation à la fin et puis transmettre cette information.

45
00:03:28,459 --> 00:03:33,120
Une autre raison d'utiliser ces convolutions 1 par 1, qu'ils ont mentionnée dans l’article,

46
00:03:33,120 --> 00:03:39,060
c’est qu’en plus d'être utilisées comme des réductions, vous pouvez également ajouter une activation ReLU

47
00:03:39,060 --> 00:03:43,319
pour en faire un double usage. Elles aident aussi votre réseau à devenir beaucoup

48
00:03:43,319 --> 00:03:47,730
plus puissant dans la mesure où vous disposez maintenant de ces activations non linéaires réparties

49
00:03:47,730 --> 00:03:54,389
dans votre réseau. GoogLeNet a donc réussi à comprimer plus de couches.

50
00:03:54,389 --> 00:03:59,549
Dans ce cas, GoogLeNet avait 22 couches et beaucoup moins de paramètres que VGG.

51
00:03:59,549 --> 00:04:07,200
Donc si nous regardons VGG, nous avons environ 144 millions de paramètres alors qu'avec

52
00:04:07,200 --> 00:04:11,700
GoogLeNet, nous avons beaucoup moins de paramètres. En fait, même moins de paramètres que AlexNet,

53
00:04:11,700 --> 00:04:17,400
avec beaucoup plus de couches. Donc vous pouvez déjà voir comment

54
00:04:17,400 --> 00:04:20,880
cette course aux armements a proliféré et il s'agissait de savoir comment obtenir des modèles plus profonds avec

55
00:04:20,880 --> 00:04:34,429
moins de paramètres et une plus grande exactitude.